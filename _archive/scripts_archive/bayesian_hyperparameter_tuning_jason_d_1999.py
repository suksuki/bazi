#!/usr/bin/env python3
"""
è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ– - Jason D 1999å¹´è¯¯å·®ä¿®æ­£
==========================================

é’ˆå¯¹ Jason D 1999 å¹´é¢„æµ‹è¯¯å·®ï¼ˆçœŸå®å€¼ 50.0ï¼Œé¢„æµ‹å€¼ -30.0ï¼Œè¯¯å·® 80.0ï¼‰è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–
è°ƒæ•´éçº¿æ€§æ¿€æ´»å‡½æ•°çš„å‚æ•°ï¼Œä½¿é¢„æµ‹æ›´å‡†ç¡®
"""

import sys
import json
import logging
from pathlib import Path
from typing import Dict, List, Any
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.bayesian_optimization import BayesianOptimizer, HyperparameterSensitivityAnalyzer
from core.engine_graph import GraphNetworkEngine
from core.config_schema import DEFAULT_FULL_ALGO_PARAMS
import copy

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class JasonD1999Optimizer:
    """
    Jason D 1999 å¹´è¯¯å·®ä¿®æ­£ä¼˜åŒ–å™¨
    ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–è°ƒæ•´éçº¿æ€§æ¿€æ´»å‡½æ•°å‚æ•°
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        # åŠ è½½ Jason D æ¡ˆä¾‹æ•°æ®
        case_file = project_root / "data" / "jason_d_case.json"
        with open(case_file, 'r', encoding='utf-8') as f:
            self.case_data = json.load(f)
        
        # 1999 å¹´çœŸå®å€¼
        self.target_year = 1999
        self.target_real_value = 50.0
        
        # è·å– 1999 å¹´çš„äº‹ä»¶ä¿¡æ¯
        event_1999 = next((e for e in self.case_data['timeline'] 
                          if e.get('year') == 1999), None)
        if event_1999:
            self.year_pillar = event_1999.get('ganzhi', 'å·±å¯')
            self.luck_pillar = event_1999.get('dayun', 'æˆŠæˆŒ')
        else:
            self.year_pillar = 'å·±å¯'
            self.luck_pillar = 'æˆŠæˆŒ'
        
        logger.info(f"âœ… åˆå§‹åŒ–ä¼˜åŒ–å™¨")
        logger.info(f"   ç›®æ ‡å¹´ä»½: {self.target_year}")
        logger.info(f"   çœŸå®å€¼: {self.target_real_value}")
        logger.info(f"   æµå¹´: {self.year_pillar}, å¤§è¿: {self.luck_pillar}")
    
    def create_objective_function(self) -> callable:
        """
        åˆ›å»ºç›®æ ‡å‡½æ•°
        
        Returns:
            ç›®æ ‡å‡½æ•°ï¼ˆæ¥å—å‚æ•°å­—å…¸ï¼Œè¿”å›æŸå¤±å€¼ï¼‰
        """
        def objective(params: Dict[str, float]) -> float:
            """
            ç›®æ ‡å‡½æ•°ï¼šè®¡ç®—é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„è¯¯å·®
            
            Args:
                params: å‚æ•°å­—å…¸ï¼ŒåŒ…å«ï¼š
                    - strength_beta: Softplus çš„ Î² å‚æ•°
                    - clash_k: Sigmoid çš„ k å‚æ•°
                    - trine_boost: ä¸‰åˆ‘å¢å¼ºç³»æ•°
                    - tunneling_factor: éš§ç©¿æ¦‚ç‡ç³»æ•°
                    
            Returns:
                æŸå¤±å€¼ï¼ˆè¯¯å·®çš„å¹³æ–¹ï¼‰
            """
            # åˆ›å»ºé…ç½®
            config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
            
            # æ›´æ–°éçº¿æ€§å‚æ•°
            if 'nonlinear' not in config:
                config['nonlinear'] = {}
            
            # [V10.1] æ˜ å°„å‚æ•°åç§°
            # strength_beta -> scale (Softplus çš„ç¼©æ”¾å› å­)
            # clash_k -> steepness (Sigmoid çš„é™¡å³­åº¦)
            config['nonlinear']['strength_beta'] = params.get('strength_beta', 10.0)
            config['nonlinear']['scale'] = params.get('strength_beta', 10.0)  # å…¼å®¹æ—§å‚æ•°å
            config['nonlinear']['clash_k'] = params.get('clash_k', 5.0)
            config['nonlinear']['steepness'] = params.get('clash_k', 5.0)  # å…¼å®¹æ—§å‚æ•°å
            config['nonlinear']['trine_boost'] = params.get('trine_boost', 0.3)
            config['nonlinear']['tunneling_factor'] = params.get('tunneling_factor', 0.1)
            
            # å¯ç”¨æ¦‚ç‡åˆ†å¸ƒï¼ˆç”¨äºä¸ç¡®å®šæ€§åˆ†æï¼‰
            config['probabilistic_energy'] = {'use_probabilistic_energy': True}
            
            # åˆ›å»ºå¼•æ“
            engine = GraphNetworkEngine(config=config)
            
            # è®¡ç®—é¢„æµ‹å€¼
            try:
                result = engine.calculate_wealth_index(
                    bazi=self.case_data['bazi'],
                    day_master=self.case_data['day_master'],
                    gender=self.case_data['gender'],
                    luck_pillar=self.luck_pillar,
                    year_pillar=self.year_pillar
                )
                
                if isinstance(result, dict):
                    predicted = result.get('wealth_index', 0.0)
                else:
                    predicted = float(result)
                
                # è®¡ç®—è¯¯å·®ï¼ˆä½¿ç”¨å¹³æ–¹è¯¯å·®ï¼‰
                error = (predicted - self.target_real_value) ** 2
                
                logger.debug(f"  å‚æ•°: {params} -> é¢„æµ‹: {predicted:.2f}, è¯¯å·®: {error:.2f}")
                
                return error
                
            except Exception as e:
                logger.error(f"è®¡ç®—å¤±è´¥: {e}")
                return 10000.0  # è¿”å›å¾ˆå¤§çš„æŸå¤±å€¼
        
        return objective
    
    def optimize(self, n_iterations: int = 50) -> Dict[str, float]:
        """
        æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–
        
        Args:
            n_iterations: ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
            
        Returns:
            æœ€ä¼˜å‚æ•°å­—å…¸
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ å¼€å§‹è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ– - Jason D 1999å¹´è¯¯å·®ä¿®æ­£")
        logger.info("="*80)
        
        # å®šä¹‰å‚æ•°è¾¹ç•Œ
        parameter_bounds = {
            'strength_beta': (5.0, 15.0),      # Softplus çš„ Î² å‚æ•°
            'clash_k': (3.0, 7.0),            # Sigmoid çš„ k å‚æ•°
            'trine_boost': (0.1, 0.5),        # ä¸‰åˆ‘å¢å¼ºç³»æ•°
            'tunneling_factor': (0.05, 0.2)   # éš§ç©¿æ¦‚ç‡ç³»æ•°
        }
        
        logger.info(f"å‚æ•°ç©ºé—´:")
        for name, (low, high) in parameter_bounds.items():
            logger.info(f"  {name}: [{low}, {high}]")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = BayesianOptimizer(
            parameter_bounds=parameter_bounds,
            acquisition_func='ei',  # æœŸæœ›æ”¹è¿›
            n_initial_samples=10
        )
        
        # åˆ›å»ºç›®æ ‡å‡½æ•°
        objective = self.create_objective_function()
        
        # æ‰§è¡Œä¼˜åŒ–
        optimal_params = optimizer.optimize(objective, n_iterations=n_iterations)
        
        # è·å–ä¼˜åŒ–å†å²
        params_history, loss_history = optimizer.get_optimization_history()
        
        # æ˜¾ç¤ºä¼˜åŒ–ç»“æœ
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š ä¼˜åŒ–ç»“æœ")
        logger.info("="*80)
        logger.info(f"æœ€ä¼˜å‚æ•°:")
        for name, value in optimal_params.items():
            logger.info(f"  {name}: {value:.4f}")
        logger.info(f"æœ€ä¼˜æŸå¤±: {optimizer.best_value:.4f}")
        logger.info(f"å¯¹åº”è¯¯å·®: {np.sqrt(optimizer.best_value):.2f}")
        
        # éªŒè¯æœ€ä¼˜å‚æ•°
        logger.info("\néªŒè¯æœ€ä¼˜å‚æ•°:")
        final_result = objective(optimal_params)
        logger.info(f"æœ€ç»ˆé¢„æµ‹å€¼: {self._get_prediction(optimal_params):.2f}")
        logger.info(f"çœŸå®å€¼: {self.target_real_value:.2f}")
        logger.info(f"æœ€ç»ˆè¯¯å·®: {abs(self._get_prediction(optimal_params) - self.target_real_value):.2f}")
        
        return optimal_params
    
    def _get_prediction(self, params: Dict[str, float]) -> float:
        """è·å–æŒ‡å®šå‚æ•°ä¸‹çš„é¢„æµ‹å€¼"""
        config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
        if 'nonlinear' not in config:
            config['nonlinear'] = {}
        config['nonlinear'].update(params)
        
        engine = GraphNetworkEngine(config=config)
        result = engine.calculate_wealth_index(
            bazi=self.case_data['bazi'],
            day_master=self.case_data['day_master'],
            gender=self.case_data['gender'],
            luck_pillar=self.luck_pillar,
            year_pillar=self.year_pillar
        )
        
        if isinstance(result, dict):
            return result.get('wealth_index', 0.0)
        return float(result)
    
    def sensitivity_analysis(self):
        """
        æ‰§è¡Œæ•æ„Ÿåº¦åˆ†æ
        åˆ†æå„ä¸ªå‚æ•°å¯¹é¢„æµ‹ç»“æœçš„å½±å“
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸ“ˆ è¶…å‚æ•°æ•æ„Ÿåº¦åˆ†æ")
        logger.info("="*80)
        
        # åŸºç¡€å‚æ•°ï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
        base_params = {
            'strength_beta': 10.0,
            'clash_k': 5.0,
            'trine_boost': 0.3,
            'tunneling_factor': 0.1
        }
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = HyperparameterSensitivityAnalyzer(base_params)
        
        # å®šä¹‰å‚æ•°èŒƒå›´
        parameter_ranges = {
            'strength_beta': np.linspace(5.0, 15.0, 20),
            'clash_k': np.linspace(3.0, 7.0, 20),
            'trine_boost': np.linspace(0.1, 0.5, 20),
            'tunneling_factor': np.linspace(0.05, 0.2, 20)
        }
        
        # åˆ›å»ºç›®æ ‡å‡½æ•°
        objective = self.create_objective_function()
        
        # åˆ†ææ‰€æœ‰å‚æ•°
        results = analyzer.analyze_all(objective, parameter_ranges)
        
        # æ˜¾ç¤ºç»“æœ
        for param_name, result in results.items():
            logger.info(f"\nå‚æ•°: {param_name}")
            logger.info(f"  æœ€ä¼˜å€¼: {result['optimal_value']:.4f}")
            logger.info(f"  æœ€ä¼˜æŸå¤±: {np.min(result['losses']):.4f}")
            logger.info(f"  æ•æ„Ÿåº¦èŒƒå›´: [{np.min(result['sensitivity']):.4f}, {np.max(result['sensitivity']):.4f}]")
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ– - Jason D 1999å¹´')
    parser.add_argument('--iterations', type=int, default=50,
                       help='ä¼˜åŒ–è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤: 50ï¼‰')
    parser.add_argument('--sensitivity', action='store_true',
                       help='æ‰§è¡Œæ•æ„Ÿåº¦åˆ†æ')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = JasonD1999Optimizer()
    
    # æ‰§è¡Œä¼˜åŒ–
    optimal_params = optimizer.optimize(n_iterations=args.iterations)
    
    # æ•æ„Ÿåº¦åˆ†æï¼ˆå¯é€‰ï¼‰
    if args.sensitivity:
        optimizer.sensitivity_analysis()
    
    # ä¿å­˜ç»“æœ
    if args.output:
        output_path = Path(args.output)
        result = {
            'target_year': 1999,
            'target_real_value': 50.0,
            'optimal_parameters': optimal_params,
            'final_error': abs(optimizer._get_prediction(optimal_params) - 50.0)
        }
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    else:
        # é»˜è®¤ä¿å­˜
        reports_dir = project_root / "reports"
        reports_dir.mkdir(exist_ok=True)
        output_path = reports_dir / "jason_d_1999_bayesian_optimization.json"
        result = {
            'target_year': 1999,
            'target_real_value': 50.0,
            'optimal_parameters': optimal_params,
            'final_error': abs(optimizer._get_prediction(optimal_params) - 50.0)
        }
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    print("\n" + "="*80)
    print("âœ… ä¼˜åŒ–å®Œæˆï¼")
    print("="*80)
    print(f"æœ€ä¼˜å‚æ•°: {optimal_params}")
    print(f"æœ€ç»ˆè¯¯å·®: {result['final_error']:.2f}")


if __name__ == '__main__':
    main()

