#!/usr/bin/env python3
"""
V10.0 å…¨é‡æ¨æ¼”ç³»ç»Ÿ - Jason D (è´¢åº“è¿å†²) æ¡ˆä¾‹
==============================================

æ•´åˆäº”å¤§æ¨¡å—è¿›è¡Œå®Œæ•´æ¨æ¼”ï¼š
1. GAT (Graph Attention Networks) - å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
2. éçº¿æ€§æ¿€æ´» (Non-linear Soft-thresholding) - ç›¸å˜ä»¿çœŸ
3. Transformer æ—¶åºå»ºæ¨¡ - é•¿ç¨‹ä¾èµ–æ•æ‰
4. è´å¶æ–¯æ¨ç† (Bayesian Inference) - æ¦‚ç‡åˆ†å¸ƒç”Ÿæˆ
5. RLHF åé¦ˆå¾ªç¯ - è‡ªé€‚åº”è°ƒä¼˜

ä½¿ç”¨æ–¹æ³•:
    python3 scripts/v10_full_inference_jason_d.py --case JASON_D_T1961_1010 --mode v10_full_inference --plot wealth_hologram
"""

import sys
import json
import argparse
import logging
import copy
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.engine_graph import GraphNetworkEngine
from core.config_schema import DEFAULT_FULL_ALGO_PARAMS
from core.bayesian_inference import BayesianInference
from core.bazi_profile import BaziProfile
from controllers.wealth_verification_controller import WealthVerificationController
from core.models.wealth_case_model import WealthCaseModel

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class V10FullInferenceEngine:
    """
    V10.0 å…¨é‡æ¨æ¼”å¼•æ“
    æ•´åˆäº”å¤§æ¨¡å—è¿›è¡Œå®Œæ•´æ¨æ¼”
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ– V10.0 æ¨æ¼”å¼•æ“
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        if config is None:
            config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
        
        # å¼ºåˆ¶å¯ç”¨æ‰€æœ‰ V10.0 æ¨¡å—
        config['use_gat'] = True
        config['use_transformer'] = True
        config['use_rlhf'] = True
        config['probabilistic_energy'] = {'use_probabilistic_energy': True}
        
        self.config = config
        self.engine = GraphNetworkEngine(config=config)
        logger.info("âœ… V10.0 å…¨é‡æ¨æ¼”å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - GAT: {config.get('use_gat', False)}")
        logger.info(f"   - Transformer: {config.get('use_transformer', False)}")
        logger.info(f"   - RLHF: {config.get('use_rlhf', False)}")
        logger.info(f"   - æ¦‚ç‡åˆ†å¸ƒ: {config.get('probabilistic_energy', {}).get('use_probabilistic_energy', False)}")
    
    def load_case_data(self, case_id: str) -> Dict[str, Any]:
        """
        åŠ è½½æ¡ˆä¾‹æ•°æ®
        
        Args:
            case_id: æ¡ˆä¾‹ID
            
        Returns:
            æ¡ˆä¾‹æ•°æ®å­—å…¸
        """
        # é¦–å…ˆå°è¯•ä» data/jason_d_case.json åŠ è½½
        jason_file = project_root / "data" / "jason_d_case.json"
        if jason_file.exists():
            with open(jason_file, 'r', encoding='utf-8') as f:
                case_data = json.load(f)
                if case_data.get('id') == case_id:
                    logger.info(f"âœ… ä» data/jason_d_case.json åŠ è½½æ¡ˆä¾‹: {case_data.get('name', case_id)}")
                    logger.info(f"   å…«å­—: {' '.join(case_data.get('bazi', []))}")
                    logger.info(f"   æ—¥ä¸»: {case_data.get('day_master', 'N/A')}")
                    return case_data
        
        # ä» calibration_cases.json åŠ è½½
        cases_file = project_root / "calibration_cases.json"
        if cases_file.exists():
            with open(cases_file, 'r', encoding='utf-8') as f:
                cases = json.load(f)
            
            # æŸ¥æ‰¾æŒ‡å®šæ¡ˆä¾‹
            case_data = None
            for case in cases:
                if case.get('id') == case_id:
                    case_data = case
                    break
            
            if case_data:
                logger.info(f"âœ… ä» calibration_cases.json åŠ è½½æ¡ˆä¾‹: {case_data.get('name', case_id)}")
                logger.info(f"   å…«å­—: {' '.join(case_data.get('bazi', []))}")
                logger.info(f"   æ—¥ä¸»: {case_data.get('day_master', 'N/A')}")
                return case_data
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨ Jason D çš„ç¡¬ç¼–ç æ•°æ®
        if case_id == 'JASON_D_T1961_1010':
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ¡ˆä¾‹æ–‡ä»¶ï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„ Jason D æ•°æ®")
            case_data = {
                "id": "JASON_D_T1961_1010",
                "name": "Jason D (è´¢åº“è¿å†²)",
                "bazi": ["è¾›ä¸‘", "ä¸é…‰", "åºšè¾°", "ä¸™æˆŒ"],
                "day_master": "åºš",
                "gender": "ç”·",
                "description": "æ¥æº: Internal_Mining_Protocol_V9.3, æ ‡ç­¾: èº«æ—ºç”¨å®˜, å¤šè´¢åº“, ä¸‘æœªæˆŒä¸‰åˆ‘",
                "timeline": [
                    {
                        "year": 1999,
                        "ganzhi": "å·±å¯",
                        "dayun": "æˆŠæˆŒ",
                        "type": "WEALTH",
                        "real_magnitude": 50.0,
                        "desc": "å…¬å¸ä¸šåŠ¡å¿«é€Ÿæ‰©å¼ ï¼Œè´¢å¯Œå¼€å§‹ç§¯ç´¯ã€‚"
                    },
                    {
                        "year": 2015,
                        "ganzhi": "ä¹™æœª",
                        "dayun": "å£¬è¾°",
                        "type": "WEALTH",
                        "real_magnitude": 100.0,
                        "desc": "é‡å¤§èµ„äº§é‡ç»„ï¼Œè´¢å¯Œæš´å¢ã€‚ç®—æ³•ç„¦ç‚¹ï¼šä¸‘æœªå†²è§¦å‘è´¢åº“å¼€å¯ (Open Vault)ã€‚"
                    },
                    {
                        "year": 2021,
                        "ganzhi": "è¾›ä¸‘",
                        "dayun": "å£¬è¾°",
                        "type": "WEALTH",
                        "real_magnitude": 100.0,
                        "desc": "æŠ•èµ„è·åˆ©ï¼Œè´¢å¯Œå†æ¬¡çˆ†å‘ã€‚ç®—æ³•ç„¦ç‚¹ï¼šéªŒè¯ä¸‘åœŸä¸æœªåœŸçš„è¿ç»­å†²åŠ¨æ•ˆåº”ã€‚"
                    }
                ]
            }
            logger.info(f"âœ… ä½¿ç”¨ç¡¬ç¼–ç æ•°æ®: {case_data.get('name', case_id)}")
            return case_data
        
        raise ValueError(f"æœªæ‰¾åˆ°æ¡ˆä¾‹: {case_id}")
    
    def step1_context_injection(self, case_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ­¥éª¤1: æ³¨å…¥"åœ°é¢çœŸå€¼"ä¸Šä¸‹æ–‡
        
        Args:
            case_data: æ¡ˆä¾‹æ•°æ®
            
        Returns:
            ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        logger.info("\n" + "="*60)
        logger.info("ğŸ“‚ æ­¥éª¤1: æ³¨å…¥åœ°é¢çœŸå€¼ä¸Šä¸‹æ–‡ (Context Injection)")
        logger.info("="*60)
        
        bazi = case_data.get('bazi', [])
        day_master = case_data.get('day_master', '')
        
        # ä½¿ç”¨ GAT ç½‘ç»œåˆ†æèŠ‚ç‚¹ç‰¹å¾
        analyze_result = self.engine.analyze(
            bazi=bazi,
            day_master=day_master,
            luck_pillar=None,
            year_pillar=None
        )
        
        # æå–å…³é”®ä¿¡æ¯
        context = {
            'bazi': bazi,
            'day_master': day_master,
            'strength_score': analyze_result.get('strength_score', 0.0),
            'strength_label': analyze_result.get('strength_label', 'Unknown'),
            'element_distribution': analyze_result.get('element_distribution', {}),
            'node_features': analyze_result.get('node_features', {}),
            'attention_weights': analyze_result.get('attention_weights', {})
        }
        
        # æ£€æµ‹è´¢åº“
        vaults = []
        for zhi in ['ä¸‘', 'è¾°', 'æœª', 'æˆŒ']:
            if any(zhi in pillar for pillar in bazi):
                vaults.append(zhi)
        
        context['wealth_vaults'] = vaults
        context['vault_count'] = len(vaults)
        
        logger.info(f"âœ… ä¸Šä¸‹æ–‡æ³¨å…¥å®Œæˆ")
        logger.info(f"   èº«å¼ºåˆ†æ•°: {context['strength_score']:.2f} ({context['strength_label']})")
        logger.info(f"   è´¢åº“æ•°é‡: {context['vault_count']} ({', '.join(vaults) if vaults else 'æ— '})")
        
        if context.get('attention_weights'):
            logger.info(f"   GAT æ³¨æ„åŠ›æƒé‡å·²è®¡ç®—")
        
        return context
    
    def step2_nonlinear_simulation(self, context: Dict[str, Any], 
                                   target_year: int, year_pillar: str, 
                                   luck_pillar: str) -> Dict[str, Any]:
        """
        æ­¥éª¤2: è§¦å‘éçº¿æ€§éš§ç©¿ä»¿çœŸ
        
        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            target_year: ç›®æ ‡å¹´ä»½
            year_pillar: æµå¹´å¹²æ”¯
            luck_pillar: å¤§è¿å¹²æ”¯
            
        Returns:
            éçº¿æ€§ä»¿çœŸç»“æœ
        """
        logger.info("\n" + "="*60)
        logger.info(f"âš¡ æ­¥éª¤2: éçº¿æ€§éš§ç©¿ä»¿çœŸ (Non-linear Simulation) - {target_year}å¹´")
        logger.info("="*60)
        
        bazi = context['bazi']
        day_master = context['day_master']
        
        # è®¡ç®—è´¢å¯ŒæŒ‡æ•°ï¼ˆä½¿ç”¨éçº¿æ€§æ¿€æ´»ï¼‰
        wealth_result = self.engine.calculate_wealth_index(
            bazi=bazi,
            day_master=day_master,
            gender='ç”·',  # Jason D æ˜¯ç”·æ€§
            luck_pillar=luck_pillar,
            year_pillar=year_pillar
        )
        
        if isinstance(wealth_result, dict):
            wealth_index = wealth_result.get('wealth_index', 0.0)
            details = wealth_result.get('details', [])
            opportunity = wealth_result.get('opportunity', 0.0)
            wealth_distribution = wealth_result.get('wealth_distribution')
            
            # æ£€æŸ¥å…³é”®æœºåˆ¶
            vault_opened = any('å†²å¼€è´¢åº“' in d or 'ğŸ†' in d for d in details)
            vault_collapsed = any('å†²æçº²' in d or 'ç¾éš¾' in d or 'ğŸ’€' in d for d in details)
            trine_effect = any('ä¸‰åˆ‘' in d for d in details)
            
            simulation_result = {
                'year': target_year,
                'year_pillar': year_pillar,
                'luck_pillar': luck_pillar,
                'wealth_index': wealth_index,
                'opportunity': opportunity,
                'details': details,
                'vault_opened': vault_opened,
                'vault_collapsed': vault_collapsed,
                'trine_effect': trine_effect,
                'wealth_distribution': wealth_distribution
            }
            
            logger.info(f"âœ… éçº¿æ€§ä»¿çœŸå®Œæˆ")
            logger.info(f"   è´¢å¯ŒæŒ‡æ•°: {wealth_index:.2f}")
            logger.info(f"   æœºä¼šèƒ½é‡: {opportunity:.2f}")
            logger.info(f"   è´¢åº“çŠ¶æ€: {'ğŸ† å·²å†²å¼€' if vault_opened else ('ğŸ’€ å·²åå¡Œ' if vault_collapsed else 'ğŸ”’ æœªå˜åŒ–')}")
            logger.info(f"   ä¸‰åˆ‘æ•ˆåº”: {'âœ… æ˜¯' if trine_effect else 'âŒ å¦'}")
            
            if wealth_distribution:
                mean = wealth_distribution.get('mean', wealth_index)
                std = wealth_distribution.get('std', 0.0)
                logger.info(f"   æ¦‚ç‡åˆ†å¸ƒ: {mean:.2f} Â± {std:.2f}")
            
            return simulation_result
        else:
            logger.warning(f"âš ï¸ è´¢å¯ŒæŒ‡æ•°è®¡ç®—è¿”å›éå­—å…¸ç±»å‹: {type(wealth_result)}")
            return {
                'year': target_year,
                'year_pillar': year_pillar,
                'luck_pillar': luck_pillar,
                'wealth_index': float(wealth_result) if wealth_result else 0.0,
                'details': [],
                'vault_opened': False,
                'vault_collapsed': False,
                'trine_effect': False
            }
    
    def step3_bayesian_probability(self, simulation_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ­¥éª¤3: ç”Ÿæˆè´å¶æ–¯æ¦‚ç‡åˆ†å¸ƒ
        
        Args:
            simulation_result: ä»¿çœŸç»“æœ
            
        Returns:
            è´å¶æ–¯æ¦‚ç‡åˆ†å¸ƒç»“æœ
        """
        logger.info("\n" + "="*60)
        logger.info("ğŸ² æ­¥éª¤3: ç”Ÿæˆè´å¶æ–¯æ¦‚ç‡åˆ†å¸ƒ (Probabilistic Output)")
        logger.info("="*60)
        
        wealth_index = simulation_result.get('wealth_index', 0.0)
        wealth_distribution = simulation_result.get('wealth_distribution')
        
        if wealth_distribution:
            mean = wealth_distribution.get('mean', wealth_index)
            std = wealth_distribution.get('std', 0.0)
            percentiles = wealth_distribution.get('percentiles', {})
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´
            confidence_interval = {
                'p25': percentiles.get('p25', mean - std),
                'p50': percentiles.get('p50', mean),
                'p75': percentiles.get('p75', mean + std)
            }
            
            # è®¡ç®—ä¸ç¡®å®šæ€§å› å­
            uncertainty_factors = BayesianInference.estimate_uncertainty_factors(
                strength_normalized=0.5,  # ç®€åŒ–ï¼Œå®é™…åº”ä»ä¸Šä¸‹æ–‡è·å–
                clash_intensity=1.0 if simulation_result.get('vault_opened') else 0.0,
                has_trine=simulation_result.get('trine_effect', False),
                has_mediation=False,
                has_help=False
            )
            
            probability_result = {
                'mean': mean,
                'std': std,
                'confidence_interval': confidence_interval,
                'uncertainty_factors': uncertainty_factors,
                'risk_level': 'high' if std > 20 else ('medium' if std > 10 else 'low')
            }
            
            logger.info(f"âœ… è´å¶æ–¯æ¦‚ç‡åˆ†å¸ƒç”Ÿæˆå®Œæˆ")
            logger.info(f"   å‡å€¼: {mean:.2f}")
            logger.info(f"   æ ‡å‡†å·®: {std:.2f}")
            logger.info(f"   ç½®ä¿¡åŒºé—´: [{confidence_interval['p25']:.2f}, {confidence_interval['p75']:.2f}]")
            logger.info(f"   é£é™©ç­‰çº§: {probability_result['risk_level']}")
            
            return probability_result
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ¦‚ç‡åˆ†å¸ƒæ•°æ®ï¼Œè·³è¿‡è´å¶æ–¯åˆ†æ")
            return {}
    
    def step4_rlhf_feedback(self, case_data: Dict[str, Any], 
                          simulation_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ­¥éª¤4: RLHF é—­ç¯è°ƒä¼˜
        
        Args:
            case_data: æ¡ˆä¾‹æ•°æ®
            simulation_results: æ‰€æœ‰ä»¿çœŸç»“æœ
            
        Returns:
            RLHF åé¦ˆç»“æœ
        """
        logger.info("\n" + "="*60)
        logger.info("ğŸ”„ æ­¥éª¤4: RLHF é—­ç¯è°ƒä¼˜ (Evolutionary Feedback)")
        logger.info("="*60)
        
        # è·å–çœŸå®äº‹ä»¶æ—¶é—´çº¿
        timeline = case_data.get('timeline', [])
        
        if not timeline:
            logger.warning("âš ï¸ æ¡ˆä¾‹æ— æ—¶é—´çº¿æ•°æ®ï¼Œè·³è¿‡ RLHF åé¦ˆ")
            return {}
        
        # æ¯”å¯¹é¢„æµ‹å€¼ä¸çœŸå®å€¼
        feedback_data = []
        for event in timeline:
            year = event.get('year')
            real_magnitude = event.get('real_magnitude', 0.0)
            
            # æŸ¥æ‰¾å¯¹åº”çš„ä»¿çœŸç»“æœ
            sim_result = next((r for r in simulation_results if r.get('year') == year), None)
            if sim_result:
                predicted = sim_result.get('wealth_index', 0.0)
                error = abs(predicted - real_magnitude)
                
                feedback_data.append({
                    'year': year,
                    'real': real_magnitude,
                    'predicted': predicted,
                    'error': error,
                    'is_correct': error <= 20.0
                })
        
        if not feedback_data:
            logger.warning("âš ï¸ æ— åŒ¹é…çš„åé¦ˆæ•°æ®")
            return {}
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_count = len(feedback_data)
        correct_count = sum(1 for f in feedback_data if f['is_correct'])
        avg_error = sum(f['error'] for f in feedback_data) / total_count
        hit_rate = (correct_count / total_count * 100) if total_count > 0 else 0.0
        
        rlhf_result = {
            'total_events': total_count,
            'correct_predictions': correct_count,
            'hit_rate': hit_rate,
            'avg_error': avg_error,
            'feedback_data': feedback_data,
            'recommendations': []
        }
        
        # ç”Ÿæˆè°ƒä¼˜å»ºè®®
        if avg_error > 20:
            rlhf_result['recommendations'].append("å»ºè®®è°ƒæ•´ breakPenalty å‚æ•°")
        if hit_rate < 50:
            rlhf_result['recommendations'].append("å»ºè®®ä¼˜åŒ– controlImpact å‚æ•°")
        
        logger.info(f"âœ… RLHF åé¦ˆåˆ†æå®Œæˆ")
        logger.info(f"   æ€»äº‹ä»¶æ•°: {total_count}")
        logger.info(f"   æ­£ç¡®é¢„æµ‹: {correct_count}")
        logger.info(f"   å‘½ä¸­ç‡: {hit_rate:.1f}%")
        logger.info(f"   å¹³å‡è¯¯å·®: {avg_error:.2f}")
        
        if rlhf_result['recommendations']:
            logger.info(f"   è°ƒä¼˜å»ºè®®: {', '.join(rlhf_result['recommendations'])}")
        
        return rlhf_result
    
    def run_full_inference(self, case_id: str, target_years: Optional[List[int]] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´æ¨æ¼”æµç¨‹
        
        Args:
            case_id: æ¡ˆä¾‹ID
            target_years: ç›®æ ‡å¹´ä»½åˆ—è¡¨ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨æ¡ˆä¾‹æ—¶é—´çº¿ä¸­çš„æ‰€æœ‰å¹´ä»½
            
        Returns:
            å®Œæ•´æ¨æ¼”ç»“æœ
        """
        logger.info("\n" + "="*80)
        logger.info("ğŸš€ å¼€å§‹ V10.0 å…¨é‡æ¨æ¼”")
        logger.info("="*80)
        
        # åŠ è½½æ¡ˆä¾‹æ•°æ®
        case_data = self.load_case_data(case_id)
        
        # æ­¥éª¤1: æ³¨å…¥ä¸Šä¸‹æ–‡
        context = self.step1_context_injection(case_data)
        
        # ç¡®å®šç›®æ ‡å¹´ä»½
        if target_years is None:
            timeline = case_data.get('timeline', [])
            target_years = [event.get('year') for event in timeline if event.get('year')]
        
        if not target_years:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡å¹´ä»½ï¼Œä½¿ç”¨é»˜è®¤å¹´ä»½")
            target_years = [2015]  # Jason D çš„å…³é”®å¹´ä»½
        
        # æ­¥éª¤2-3: å¯¹æ¯ä¸ªç›®æ ‡å¹´ä»½è¿›è¡Œéçº¿æ€§ä»¿çœŸå’Œè´å¶æ–¯åˆ†æ
        simulation_results = []
        probability_results = []
        
        for year in target_years:
            # æŸ¥æ‰¾è¯¥å¹´çš„äº‹ä»¶ä¿¡æ¯
            event = next((e for e in case_data.get('timeline', []) if e.get('year') == year), None)
            if event:
                year_pillar = event.get('ganzhi', '')
                luck_pillar = event.get('dayun', '')
            else:
                # å¦‚æœæ²¡æœ‰äº‹ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
                logger.warning(f"âš ï¸ {year}å¹´æ— äº‹ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å¹²æ”¯")
                year_pillar = ''
                luck_pillar = ''
            
            # æ­¥éª¤2: éçº¿æ€§ä»¿çœŸ
            sim_result = self.step2_nonlinear_simulation(context, year, year_pillar, luck_pillar)
            simulation_results.append(sim_result)
            
            # æ­¥éª¤3: è´å¶æ–¯æ¦‚ç‡åˆ†å¸ƒ
            prob_result = self.step3_bayesian_probability(sim_result)
            if prob_result:
                probability_results.append({
                    'year': year,
                    **prob_result
                })
        
        # æ­¥éª¤4: RLHF åé¦ˆ
        rlhf_result = self.step4_rlhf_feedback(case_data, simulation_results)
        
        # æ±‡æ€»ç»“æœ
        full_result = {
            'case_id': case_id,
            'case_name': case_data.get('name', ''),
            'context': context,
            'simulation_results': simulation_results,
            'probability_results': probability_results,
            'rlhf_feedback': rlhf_result,
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info("\n" + "="*80)
        logger.info("âœ… V10.0 å…¨é‡æ¨æ¼”å®Œæˆ")
        logger.info("="*80)
        
        return full_result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='V10.0 å…¨é‡æ¨æ¼”ç³»ç»Ÿ')
    parser.add_argument('--case', type=str, default='JASON_D_T1961_1010',
                       help='æ¡ˆä¾‹ID (é»˜è®¤: JASON_D_T1961_1010)')
    parser.add_argument('--mode', type=str, default='v10_full_inference',
                       choices=['v10_full_inference'],
                       help='æ¨æ¼”æ¨¡å¼')
    parser.add_argument('--plot', type=str, default='wealth_hologram',
                       choices=['wealth_hologram', 'none'],
                       help='å¯è§†åŒ–ç±»å‹')
    parser.add_argument('--years', type=str, default=None,
                       help='ç›®æ ‡å¹´ä»½åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš” (ä¾‹å¦‚: 1999,2015,2021)')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (JSONæ ¼å¼)')
    
    args = parser.parse_args()
    
    # è§£æç›®æ ‡å¹´ä»½
    target_years = None
    if args.years:
        target_years = [int(y.strip()) for y in args.years.split(',')]
    
    # åˆå§‹åŒ–æ¨æ¼”å¼•æ“
    engine = V10FullInferenceEngine()
    
    # æ‰§è¡Œæ¨æ¼”
    result = engine.run_full_inference(args.case, target_years)
    
    # ä¿å­˜ç»“æœ
    if args.output:
        output_path = Path(args.output)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    else:
        # é»˜è®¤ä¿å­˜åˆ° reports ç›®å½•
        reports_dir = project_root / "reports"
        reports_dir.mkdir(exist_ok=True)
        output_path = reports_dir / f"v10_inference_{args.case}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    # æ‰“å°å…³é”®ç»“æœæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“Š æ¨æ¼”ç»“æœæ‘˜è¦")
    print("="*80)
    print(f"æ¡ˆä¾‹: {result['case_name']}")
    print(f"æ¨æ¼”å¹´ä»½æ•°: {len(result['simulation_results'])}")
    
    if result['rlhf_feedback']:
        rlhf = result['rlhf_feedback']
        print(f"å‘½ä¸­ç‡: {rlhf['hit_rate']:.1f}%")
        print(f"å¹³å‡è¯¯å·®: {rlhf['avg_error']:.2f}")
    
    print("\nå…³é”®å¹´ä»½æ¨æ¼”ç»“æœ:")
    for sim in result['simulation_results']:
        year = sim.get('year', 'N/A')
        wealth = sim.get('wealth_index', 0.0)
        vault_status = 'ğŸ†' if sim.get('vault_opened') else ('ğŸ’€' if sim.get('vault_collapsed') else 'ğŸ”’')
        print(f"  {year}å¹´: è´¢å¯ŒæŒ‡æ•°={wealth:.2f} {vault_status}")
    
    print("\n" + "="*80)
    print("âœ… æ¨æ¼”å®Œæˆï¼è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶ã€‚")
    print("="*80)


if __name__ == '__main__':
    import copy
    main()

