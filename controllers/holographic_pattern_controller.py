"""
å…¨æ¯æ ¼å±€æ§åˆ¶å™¨ (Holographic Pattern Controller)
MVC Controller Layer - è´Ÿè´£å…¨æ¯æ ¼å±€çš„ä¸šåŠ¡é€»è¾‘

ä¸¥æ ¼éµå¾ªMVCæ¶æ„åŸåˆ™ï¼š
- Viewå±‚ï¼ˆholographic_pattern.pyï¼‰åªè´Ÿè´£UIå±•ç¤ºå’Œç”¨æˆ·äº¤äº’
- Controllerå±‚å°è£…æ‰€æœ‰ç®—æ³•é€»è¾‘ï¼Œåè°ƒEngineå’ŒModel
- Engineå±‚è´Ÿè´£æ ¸å¿ƒè®¡ç®—

æ³¨æ„ï¼šè¿™æ˜¯å…¨æ–°çš„"å¼ é‡å…¨æ¯æ ¼å±€"ç³»ç»Ÿï¼Œä¸ä¾èµ–ç°æœ‰çš„ç‰©ç†æ¨¡å‹ä»¿çœŸæ³¨å†Œè¡¨
"""

import logging
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import json

from core.trinity.core.unified_arbitrator_master import QuantumUniversalFramework
from core.trinity.core.engines.synthetic_bazi_engine import SyntheticBaziEngine
from core.trinity.core.nexus.definitions import BaziParticleNexus
from core.engine_graph.constants import TWELVE_LIFE_STAGES
from core.trinity.core.intelligence.symbolic_stars import SymbolicStarsEngine

logger = logging.getLogger(__name__)


class HolographicPatternController:
    """
    å…¨æ¯æ ¼å±€æ§åˆ¶å™¨
    
    èŒè´£ï¼š
    - å°è£…å…¨æ¯æ ¼å±€ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
    - åè°ƒæ ¼å±€æ³¨å†Œè¡¨çš„åŠ è½½å’ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨æ–°çš„"å¼ é‡å…¨æ¯æ ¼å±€"æ³¨å†Œè¡¨ï¼‰
    - å¤„ç†äº”ç»´å¼ é‡æŠ•å½±è®¡ç®—
    - æä¾›ç»Ÿä¸€çš„æ•°æ®æ¥å£ç»™Viewå±‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ§åˆ¶å™¨"""
        # ä½¿ç”¨æ–°çš„"å¼ é‡å…¨æ¯æ ¼å±€"æ³¨å†Œè¡¨è·¯å¾„
        self.registry_path = Path(__file__).parent.parent / "core" / "subjects" / "holographic_pattern" / "registry.json"
        self.registry = None
        self.framework = QuantumUniversalFramework()
        logger.info("HolographicPatternController initialized (å…¨æ–°å¼ é‡å…¨æ¯æ ¼å±€ç³»ç»Ÿ)")
    
    def load_registry(self) -> Dict:
        """
        åŠ è½½æ ¼å±€æ³¨å†Œè¡¨
        
        Returns:
            æ³¨å†Œè¡¨å­—å…¸
        """
        if self.registry is None:
            try:
                with open(self.registry_path, 'r', encoding='utf-8') as f:
                    self.registry = json.load(f)
                logger.info(f"âœ… å·²åŠ è½½æ³¨å†Œè¡¨: {len(self.registry.get('patterns', {}))} ä¸ªæ ¼å±€")
            except Exception as e:
                logger.error(f"åŠ è½½æ³¨å†Œè¡¨å¤±è´¥: {e}")
                self.registry = {"patterns": {}, "metadata": {}}
        
        return self.registry
    
    def get_all_patterns(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ ¼å±€åˆ—è¡¨ï¼ˆæŒ‰QGA-HR V1.0å±‚çº§å‘½åè§„èŒƒï¼‰
        æ”¯æŒä¸»æ ¼å±€å’Œå­æ ¼å±€çš„å±‚çº§å…³ç³»
        
        Returns:
            æ ¼å±€åˆ—è¡¨ï¼ŒæŒ‰Categoryå’ŒSubject IDæ’åºï¼Œå­æ ¼å±€è·Ÿéšä¸»æ ¼å±€
        """
        registry = self.load_registry()
        patterns = registry.get('patterns', {})
        
        # åˆ†ç¦»ä¸»æ ¼å±€å’Œå­æ ¼å±€
        main_patterns = []
        sub_patterns = []
        
        for pattern_id, pattern_data in patterns.items():
            # æå–å±‚çº§ä¿¡æ¯
            category = pattern_data.get('category', '')
            subject_id = pattern_data.get('subject_id', pattern_id)
            parent_pattern = pattern_data.get('parent_pattern')
            
            pattern_info = {
                'id': pattern_id,
                'category': category,
                'subject_id': subject_id,
                'name': pattern_data.get('name', pattern_id),
                'name_cn': pattern_data.get('name_cn', ''),
                'icon': pattern_data.get('icon', 'ğŸ§¬'),
                'description': pattern_data.get('description', ''),
                'version': pattern_data.get('version', 'N/A'),
                'active': pattern_data.get('active', False),
                'semantic_seed': pattern_data.get('semantic_seed', {}),
                'tensor_operator': pattern_data.get('tensor_operator', {}),
                'parent_pattern': parent_pattern,
                'is_sub_pattern': parent_pattern is not None
            }
            
            if parent_pattern:
                sub_patterns.append(pattern_info)
            else:
                main_patterns.append(pattern_info)
        
        # ä¸»æ ¼å±€æŒ‰Categoryå’ŒSubject IDæ’åº
        main_patterns.sort(key=lambda x: (x.get('category', ''), x.get('subject_id', '')))
        
        # å­æ ¼å±€æŒ‰çˆ¶æ ¼å±€åˆ†ç»„ï¼Œç„¶åæŒ‰Subject IDæ’åº
        sub_patterns_by_parent = {}
        for sub_pattern in sub_patterns:
            parent_id = sub_pattern['parent_pattern']
            if parent_id not in sub_patterns_by_parent:
                sub_patterns_by_parent[parent_id] = []
            sub_patterns_by_parent[parent_id].append(sub_pattern)
        
        # å¯¹æ¯ä¸ªçˆ¶æ ¼å±€çš„å­æ ¼å±€æ’åº
        for parent_id in sub_patterns_by_parent:
            sub_patterns_by_parent[parent_id].sort(key=lambda x: x.get('subject_id', ''))
        
        # æ„å»ºå±‚çº§ç»“æœï¼šä¸»æ ¼å±€ + å…¶å­æ ¼å±€
        result = []
        for main_pattern in main_patterns:
            # æ·»åŠ ä¸»æ ¼å±€
            result.append(main_pattern)
            
            # æ·»åŠ è¯¥ä¸»æ ¼å±€çš„å­æ ¼å±€
            main_id = main_pattern['id']
            if main_id in sub_patterns_by_parent:
                for sub_pattern in sub_patterns_by_parent[main_id]:
                    result.append(sub_pattern)
        
        # å¤„ç†æ²¡æœ‰çˆ¶æ ¼å±€çš„å­æ ¼å±€ï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼Œä½†ä¸ºäº†å¥å£®æ€§ï¼‰
        for sub_pattern in sub_patterns:
            if sub_pattern['parent_pattern'] not in [p['id'] for p in main_patterns]:
                result.append(sub_pattern)
        
        return result
    
    def get_pattern_hierarchy(self) -> Dict[str, Dict]:
        """
        è·å–æ ¼å±€å±‚çº§ç»“æ„ï¼ˆä¸»æ ¼å±€ -> å­æ ¼å±€ï¼‰
        
        Returns:
            å­—å…¸ï¼š{ä¸»æ ¼å±€ID: {'main': ä¸»æ ¼å±€ä¿¡æ¯, 'subs': [å­æ ¼å±€åˆ—è¡¨]}}
        """
        registry = self.load_registry()
        patterns = registry.get('patterns', {})
        
        hierarchy = {}
        
        # å…ˆæ‰¾å‡ºæ‰€æœ‰ä¸»æ ¼å±€
        for pattern_id, pattern_data in patterns.items():
            parent_pattern = pattern_data.get('parent_pattern')
            if not parent_pattern:  # ä¸»æ ¼å±€
                category = pattern_data.get('category', '')
                subject_id = pattern_data.get('subject_id', pattern_id)
                
                hierarchy[pattern_id] = {
                    'main': {
                        'id': pattern_id,
                        'category': category,
                        'subject_id': subject_id,
                        'name': pattern_data.get('name', pattern_id),
                        'name_cn': pattern_data.get('name_cn', ''),
                        'icon': pattern_data.get('icon', 'ğŸ§¬'),
                        'description': pattern_data.get('description', ''),
                        'version': pattern_data.get('version', 'N/A'),
                        'active': pattern_data.get('active', False)
                    },
                    'subs': []
                }
        
        # å†æ‰¾å‡ºæ‰€æœ‰å­æ ¼å±€å¹¶å½’ç±»
        for pattern_id, pattern_data in patterns.items():
            parent_pattern = pattern_data.get('parent_pattern')
            if parent_pattern and parent_pattern in hierarchy:
                category = pattern_data.get('category', '')
                subject_id = pattern_data.get('subject_id', pattern_id)
                
                hierarchy[parent_pattern]['subs'].append({
                    'id': pattern_id,
                    'category': category,
                    'subject_id': subject_id,
                    'name': pattern_data.get('name', pattern_id),
                    'name_cn': pattern_data.get('name_cn', ''),
                    'icon': pattern_data.get('icon', 'ğŸ§¬'),
                    'description': pattern_data.get('description', ''),
                    'version': pattern_data.get('version', 'N/A'),
                    'active': pattern_data.get('active', False)
                })
        
        # å¯¹æ¯ä¸ªä¸»æ ¼å±€çš„å­æ ¼å±€æ’åº
        for parent_id in hierarchy:
            hierarchy[parent_id]['subs'].sort(key=lambda x: x.get('subject_id', ''))
        
        return hierarchy
    
    def get_pattern_by_id(self, pattern_id: str) -> Optional[Dict]:
        """
        æ ¹æ®IDè·å–æ ¼å±€è¯¦æƒ…
        
        Args:
            pattern_id: æ ¼å±€ID
            
        Returns:
            æ ¼å±€è¯¦æƒ…å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        registry = self.load_registry()
        patterns = registry.get('patterns', {})
        
        if pattern_id in patterns:
            return patterns[pattern_id]
        
        return None
    
    def calculate_tensor_projection(self, pattern_id: str, chart: List[str], 
                                   day_master: str, context: Optional[Dict] = None) -> Dict:
        """
        è®¡ç®—äº”ç»´å¼ é‡æŠ•å½±ï¼ˆåŸºäºFDS-V1.1è§„èŒƒï¼‰
        
        Args:
            pattern_id: æ ¼å±€ID
            chart: å…«å­—åŸå±€
            day_master: æ—¥ä¸»
            context: ä¸Šä¸‹æ–‡ï¼ˆå¤§è¿ã€æµå¹´ç­‰ï¼‰
            
        Returns:
            äº”ç»´å¼ é‡æŠ•å½±ç»“æœ
        """
        # è·å–æ ¼å±€ä¿¡æ¯
        pattern = self.get_pattern_by_id(pattern_id)
        if not pattern:
            return {'error': f'æ ¼å±€ {pattern_id} ä¸å­˜åœ¨'}
        
        # è·å–å¼ é‡æŠ•å½±ç®—å­ï¼ˆæ¨¡å—IIï¼‰
        tensor_operator = pattern.get('tensor_operator', {})
        weights = tensor_operator.get('weights', {})
        
        # å¦‚æœæ²¡æœ‰æƒé‡ï¼Œè¿”å›é”™è¯¯ï¼ˆå¿…é¡»é€šè¿‡FDS-V1.1 Step 1æ³¨å†Œï¼‰
        if not weights:
            return {
                'error': f'æ ¼å±€ {pattern_id} å°šæœªå®ŒæˆFDS-V1.1 Step 1æ³¨å†Œï¼ˆç¼ºå°‘å¼ é‡æŠ•å½±ç®—å­ï¼‰',
                'pattern_id': pattern_id,
                'pattern_name': pattern.get('name', pattern_id)
            }
        
        # éªŒè¯æƒé‡å½’ä¸€åŒ–ï¼ˆå•ä½å‘é‡çº¦æŸï¼‰
        if not tensor_operator.get('normalized', False):
            weights = self.normalize_weights(weights)
            logger.warning(f"æ ¼å±€ {pattern_id} æƒé‡æœªå½’ä¸€åŒ–ï¼Œå·²è‡ªåŠ¨å½’ä¸€åŒ–")
        
        # è®¡ç®—SAIï¼ˆç³»ç»Ÿå¯¹é½æŒ‡æ•°ï¼‰
        try:
            binfo = {'day_master': day_master}
            if context:
                ctx = {
                    'luck_pillar': context.get('luck_pillar'),
                    'annual_pillar': context.get('annual_pillar'),
                    'scenario': context.get('scenario', 'default')
                }
            else:
                ctx = {'scenario': 'default'}
            
            result = self.framework.arbitrate_bazi(chart, binfo, ctx)
            
            # SAIåœ¨result['physics']['stress']['SAI']ä¸­
            physics = result.get('physics', {})
            stress = physics.get('stress', {})
            sai = stress.get('SAI', 0.0)
            
            # å¦‚æœSAIä¸º0ï¼Œè®°å½•è­¦å‘Š
            if sai == 0.0:
                logger.warning(f"SAIè®¡ç®—ç»“æœä¸º0.0ï¼Œå¯èƒ½çš„åŸå› ï¼š1) å…«å­—ä¸åŒ¹é…è¯¥æ ¼å±€ 2) è®¡ç®—å¼‚å¸¸ 3) ç»“æ„è¿‡äºç¨³å®š")
        except Exception as e:
            logger.error(f"è®¡ç®—SAIå¤±è´¥: {e}", exc_info=True)
            sai = 0.0
        
        # è®¡ç®—äº”ç»´æŠ•å½±ï¼ˆSAI Ã— æƒé‡ï¼‰
        projection = {
            'E': sai * weights.get('E', 0.0),  # èƒ½çº§è½´
            'O': sai * weights.get('O', 0.0),  # ç§©åºè½´
            'M': sai * weights.get('M', 0.0),  # ç‰©è´¨è½´
            'S': sai * weights.get('S', 0.0),  # åº”åŠ›è½´
            'R': sai * weights.get('R', 0.0)   # å…³è”è½´
        }
        
        # è·å–è¯­ä¹‰æ„è±¡ï¼ˆæ¨¡å—Iï¼‰
        semantic_seed = pattern.get('semantic_seed', {})
        
        return {
            'pattern_id': pattern_id,
            'pattern_name': pattern.get('name', pattern_id),
            'sai': sai,
            'projection': projection,
            'weights': weights,
            'semantic_seed': semantic_seed.get('description', ''),
            'tensor_operator': tensor_operator
        }
    
    def normalize_weights(self, weights: Dict[str, float]) -> Dict[str, float]:
        """
        æƒé‡å½’ä¸€åŒ–ï¼ˆå•ä½å‘é‡çº¦æŸï¼‰
        
        Args:
            weights: æƒé‡å­—å…¸
            
        Returns:
            å½’ä¸€åŒ–åçš„æƒé‡å­—å…¸
        """
        total = sum(abs(v) for v in weights.values())
        if total == 0:
            return weights
        
        return {k: round(v / total, 4) for k, v in weights.items()}
    
    def _check_strong_root(self, stem: str, branch: str) -> bool:
        """
        æ£€æŸ¥å¤©å¹²æ˜¯å¦åå¼ºæ ¹ï¼ˆç®€åŒ–ç‰ˆï¼šæ£€æŸ¥åœ°æ”¯æœ¬æ°”æ˜¯å¦ä¸ºå¤©å¹²çš„åŒç±»äº”è¡Œï¼‰
        
        Args:
            stem: å¤©å¹²
            branch: åœ°æ”¯
            
        Returns:
            æ˜¯å¦åå¼ºæ ¹
        """
        # å¤©å¹²äº”è¡Œ
        stem_wuxing = {
            'ç”²': 'æœ¨', 'ä¹™': 'æœ¨',
            'ä¸™': 'ç«', 'ä¸': 'ç«',
            'æˆŠ': 'åœŸ', 'å·±': 'åœŸ',
            'åºš': 'é‡‘', 'è¾›': 'é‡‘',
            'å£¬': 'æ°´', 'ç™¸': 'æ°´'
        }
        
        # åœ°æ”¯æœ¬æ°”äº”è¡Œ
        branch_wuxing = {
            'å­': 'æ°´', 'ä¸‘': 'åœŸ', 'å¯…': 'æœ¨', 'å¯': 'æœ¨',
            'è¾°': 'åœŸ', 'å·³': 'ç«', 'åˆ': 'ç«', 'æœª': 'åœŸ',
            'ç”³': 'é‡‘', 'é…‰': 'é‡‘', 'æˆŒ': 'åœŸ', 'äº¥': 'æ°´'
        }
        
        stem_wx = stem_wuxing.get(stem, '')
        branch_wx = branch_wuxing.get(branch, '')
        
        # å¼ºæ ¹ï¼šåœ°æ”¯æœ¬æ°”ä¸å¤©å¹²åŒäº”è¡Œ
        if stem_wx == branch_wx:
            return True
        
        # æ£€æŸ¥åœ°æ”¯è—å¹²ï¼ˆç®€åŒ–ï¼šåªæ£€æŸ¥ä¸»è¦è—å¹²ï¼‰
        # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´è¯¦ç»†çš„è—å¹²æ£€æŸ¥
        return False
    
    def _calculate_purity_score(self, sample: Dict, day_master: str) -> float:
        """
        è®¡ç®—æ ·æœ¬çº¯åº¦å¾—åˆ†ï¼ˆåŸºäºAIåˆ†æå¸ˆæœ€æ–°è§„èŒƒï¼‰
        
        Args:
            sample: æ ·æœ¬å­—å…¸
            day_master: æ—¥ä¸»
            
        Returns:
            çº¯åº¦å¾—åˆ†ï¼ˆè¶Šé«˜è¶Šçº¯å‡€ï¼‰
        """
        chart = sample['chart']
        stems = [p[0] for p in chart]
        branches = [p[1] for p in chart]
        ten_gods = sample['ten_gods']
        
        # åŸºç¡€åˆ†
        score = 100.0
        
        # åŠ åˆ†é¡¹
        # +20åˆ†ï¼šä¸ƒæ€åå¼ºæ ¹ï¼ˆå¦‚åºšç”³ï¼‰
        qi_sha_stems = sample.get('qi_sha_stems', [])
        for qi_sha_stem in qi_sha_stems:
            # æ‰¾åˆ°ä¸ƒæ€æ‰€åœ¨ä½ç½®
            for i, s in enumerate(stems):
                if s == qi_sha_stem:
                    # æ£€æŸ¥å¯¹åº”çš„åœ°æ”¯æ˜¯å¦å¼ºæ ¹
                    if self._check_strong_root(qi_sha_stem, branches[i]):
                        score += 20
                        break  # åªåŠ ä¸€æ¬¡åˆ†
        
        # +10åˆ†ï¼šå°æ˜Ÿè´´èº«ï¼ˆæœ‰é€šå…³å†·å´ï¼‰
        yin_count = ten_gods.count('æ­£å°') + ten_gods.count('åå°')
        if yin_count > 0:
            score += yin_count * 10
        
        # å‡åˆ†é¡¹
        # -15åˆ†ï¼šé£Ÿä¼¤æ··æ‚ï¼ˆåˆ¶æ€å¤ªè¿‡æˆ–å¹²æ‰°ç£åœºï¼‰
        shi_shen_count = ten_gods.count('é£Ÿç¥') + ten_gods.count('ä¼¤å®˜')
        if shi_shen_count > 0:
            score -= shi_shen_count * 15
        
        # -15åˆ†ï¼šè´¢æ˜Ÿå…šæ€ï¼ˆå¢åŠ åº”åŠ›é£é™©ï¼‰
        cai_count = ten_gods.count('æ­£è´¢') + ten_gods.count('åè´¢')
        if cai_count > 0:
            score -= cai_count * 15
        
        # -10åˆ†ï¼šåœ°æ”¯æœ‰åˆ‘/å†²/ç©¿ï¼ˆç»“æ„ä¸ç¨³ï¼‰
        clash_pairs = [('å­', 'åˆ'), ('ä¸‘', 'æœª'), ('å¯…', 'ç”³'), ('å¯', 'é…‰'), 
                      ('è¾°', 'æˆŒ'), ('å·³', 'äº¥')]
        harm_pairs = [('å­', 'æœª'), ('ä¸‘', 'åˆ'), ('å¯…', 'å·³'), ('å¯', 'è¾°'),
                     ('ç”³', 'äº¥'), ('é…‰', 'æˆŒ')]
        
        has_clash = False
        has_harm = False
        for i, b1 in enumerate(branches):
            for j, b2 in enumerate(branches[i+1:], i+1):
                if (b1, b2) in clash_pairs or (b2, b1) in clash_pairs:
                    has_clash = True
                if (b1, b2) in harm_pairs or (b2, b1) in harm_pairs:
                    has_harm = True
        
        if has_clash or has_harm:
            score -= 10
        
        return score
    
    def _detect_singularity(self, sample: Dict, day_master: str) -> Tuple[bool, str]:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºå¥‡ç‚¹æ ·æœ¬ï¼ˆåŸºäºAIåˆ†æå¸ˆæœ€æ–°è§„èŒƒï¼‰
        
        Args:
            sample: æ ·æœ¬å­—å…¸
            day_master: æ—¥ä¸»
            
        Returns:
            (æ˜¯å¦ä¸ºå¥‡ç‚¹, å¥‡ç‚¹ç±»å‹)
        """
        chart = sample['chart']
        stems = [p[0] for p in chart]
        branches = [p[1] for p in chart]
        ten_gods = sample['ten_gods']
        
        # è·å–ç¾Šåˆƒåœ°æ”¯
        yang_ren_map = SymbolicStarsEngine.YANG_REN_MAP
        yang_ren_branch = yang_ren_map.get(day_master)
        
        # 1. èƒ½é‡æº¢å‡ºï¼šåœ°æ”¯ç¾Šåˆƒæ•°é‡ >= 3ï¼ˆå¦‚ï¼šåœ°æ”¯ä¸‰å¯ï¼‰
        yang_ren_count = branches.count(yang_ren_branch) if yang_ren_branch else 0
        if yang_ren_count >= 3:
            return True, "X1-èšå˜ä¸´ç•Œå‹ï¼ˆåœ°æ”¯ä¸‰åˆƒï¼‰"
        
        # 2. é«˜å‹ä¸´ç•Œï¼šå¤©å¹²é€å‡º2ä¸ªæˆ–ä»¥ä¸Šä¸ƒæ€ï¼Œä¸”å››æŸ±æ— é£Ÿç¥ï¼ˆåˆ¶ï¼‰æ— å°æ˜Ÿï¼ˆåŒ–ï¼‰ï¼Œçº¯ç²¹æ”»èº«
        qi_sha_count = ten_gods.count('ä¸ƒæ€')
        yin_count = ten_gods.count('æ­£å°') + ten_gods.count('åå°')
        shi_shen_count = ten_gods.count('é£Ÿç¥') + ten_gods.count('ä¼¤å®˜')
        
        if qi_sha_count >= 2 and yin_count == 0 and shi_shen_count == 0:
            return True, "X2-ç»“æ„é«˜å‹å‹ï¼ˆä¼—æ€æ”»èº«æ— åˆ¶ï¼‰"
        
        return False, ""
    
    def select_samples(self, pattern_id: str, target_count: int = 500, 
                      progress_callback: Optional[callable] = None,
                      output_dir: Optional[Path] = None) -> Dict[str, Any]:
        """
        æŒ‰ç…§FDS-V1.1 Step 2çš„æ•°æ®é€‰æ‹©æ ‡å‡†è¿›è¡Œæ ·æœ¬æµ·é€‰ï¼ˆå‡çº§ç‰ˆï¼šçº¯åº¦æ’åº+å¥‡ç‚¹æ•è·ï¼‰
        
        Args:
            pattern_id: æ ¼å±€ID
            target_count: ç›®æ ‡æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤500ï¼Œç”¨äºTier Aæ ‡å‡†é›†ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current, total, stats)
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¦‚æœæä¾›ï¼Œå°†ä¿å­˜ä¸¤ä¸ªJSONæ–‡ä»¶ï¼‰
            
        Returns:
            åŒ…å«standard_setå’Œsingularitiesçš„å­—å…¸
        """
        # è·å–æ ¼å±€ä¿¡æ¯
        pattern = self.get_pattern_by_id(pattern_id)
        if not pattern:
            logger.error(f"æ ¼å±€ {pattern_id} ä¸å­˜åœ¨")
            return []
        
        # è·å–æ•°æ®é€‰æ‹©æ ‡å‡†
        data_criteria = pattern.get('audit_trail', {}).get('data_selection_criteria', {})
        if not data_criteria:
            logger.error(f"æ ¼å±€ {pattern_id} ç¼ºå°‘æ•°æ®é€‰æ‹©æ ‡å‡†")
            return []
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        engine = SyntheticBaziEngine()
        bazi_gen = engine.generate_all_bazi()
        
        candidates = []
        total_scanned = 0
        stats = {
            'scanned': 0,
            'matched': 0,
            'rejected_month_lock': 0,
            'rejected_stem_reveal': 0,
            'rejected_purity': 0
        }
        
        logger.info(f"å¼€å§‹æ ·æœ¬æµ·é€‰ï¼šæ ¼å±€={pattern_id}ï¼Œç›®æ ‡={target_count}ä¾‹ï¼Œå…¨é‡æ‰«æ518,400ä¸ªæ ·æœ¬")
        
        # ä¸¥æ ¼å…¨é‡æ‰«æï¼šå¿…é¡»æ‰«ææ‰€æœ‰518,400ä¸ªæ ·æœ¬
        for chart in bazi_gen:
            total_scanned += 1
            stats['scanned'] = total_scanned
            
            # è¿›åº¦å›è°ƒï¼ˆæ¯10,000ä¸ªæ ·æœ¬æˆ–æ¯5%è¿›åº¦ï¼‰
            if progress_callback and (total_scanned % 10000 == 0 or total_scanned % 25920 == 0):
                progress_callback(total_scanned, 518400, stats)
            
            # æ³¨æ„ï¼šä¸æå‰é€€å‡ºï¼Œå¿…é¡»æ‰«æå…¨éƒ¨518,400ä¸ªæ ·æœ¬
            
            # æå–åŸºæœ¬ä¿¡æ¯
            year_pillar, month_pillar, day_pillar, hour_pillar = chart
            day_master = day_pillar[0]
            month_branch = month_pillar[1]
            
            # 1. æœˆä»¤é”ï¼šæœˆæ”¯æœ¬æ°”å¿…é¡»ä¸ºæ—¥ä¸»ä¹‹å¸æ—ºï¼ˆå³ç¾Šåˆƒï¼‰
            life_stage = TWELVE_LIFE_STAGES.get((day_master, month_branch))
            if life_stage != 'å¸æ—º':
                stats['rejected_month_lock'] += 1
                continue
            
            # 2. å¤©å¹²é€æ€ï¼šå¤©å¹²å¿…é¡»é€å‡ºä¸ƒæ€ï¼Œä¸”ä¸ƒæ€å¿…é¡»æœ‰æ ¹
            stems = [year_pillar[0], month_pillar[0], day_pillar[0], hour_pillar[0]]
            branches = [year_pillar[1], month_pillar[1], day_pillar[1], hour_pillar[1]]
            
            # æ£€æŸ¥å¤©å¹²æ˜¯å¦æœ‰ä¸ƒæ€
            qi_sha_stems = []
            for i, stem in enumerate(stems):
                if i == 2:  # è·³è¿‡æ—¥ä¸»
                    continue
                ten_god = BaziParticleNexus.get_shi_shen(stem, day_master)
                if ten_god == 'ä¸ƒæ€':
                    qi_sha_stems.append((i, stem))
            
            if not qi_sha_stems:
                stats['rejected_stem_reveal'] += 1
                continue
            
            # æ£€æŸ¥ä¸ƒæ€æ˜¯å¦æœ‰æ ¹
            has_root = False
            for _, qi_sha_stem in qi_sha_stems:
                # æ£€æŸ¥è‡ªå
                pillar_idx = qi_sha_stems[0][0]
                if pillar_idx < len(branches):
                    branch = branches[pillar_idx]
                    hidden_stems = BaziParticleNexus.get_branch_weights(branch)
                    for hidden_stem, weight in hidden_stems:
                        if hidden_stem == qi_sha_stem and weight >= 5:  # ä¸»æ°”æˆ–ä¸­æ°”
                            has_root = True
                            break
                
                # æ£€æŸ¥å…¶ä»–åœ°æ”¯
                if not has_root:
                    for branch in branches:
                        hidden_stems = BaziParticleNexus.get_branch_weights(branch)
                        for hidden_stem, weight in hidden_stems:
                            if hidden_stem == qi_sha_stem and weight >= 5:
                                has_root = True
                                break
                        if has_root:
                            break
                
                if has_root:
                    break
            
            if not has_root:
                stats['rejected_stem_reveal'] += 1
                continue
            
            # 3. æ¸…çº¯åº¦è¿‡æ»¤ï¼šå‰”é™¤é‡é£Ÿä¼¤åˆ¶æ€ã€é‡è´¢å…šæ€
            ten_gods = [BaziParticleNexus.get_shi_shen(s, day_master) for s in stems]
            
            # ç»Ÿè®¡é£Ÿä¼¤å’Œè´¢æ˜Ÿæ•°é‡
            shi_shen_count = ten_gods.count('é£Ÿç¥') + ten_gods.count('ä¼¤å®˜')
            cai_count = ten_gods.count('æ­£è´¢') + ten_gods.count('åè´¢')
            qi_sha_count = ten_gods.count('ä¸ƒæ€')
            
            # å‰”é™¤é‡é£Ÿä¼¤åˆ¶æ€ï¼ˆè¿™ä¼šå˜æˆA-02é£Ÿç¥åˆ¶æ€ï¼‰
            if shi_shen_count >= 2 and qi_sha_count >= 1:
                stats['rejected_purity'] += 1
                continue
            
            # å‰”é™¤é‡è´¢å…šæ€ï¼ˆè¿™ä¼šå¯¼è‡´åº”åŠ›è½´Sçˆ†è¡¨ï¼‰
            if cai_count >= 2 and qi_sha_count >= 1:
                stats['rejected_purity'] += 1
                continue
            
            # é€šè¿‡æ‰€æœ‰ç­›é€‰æ¡ä»¶
            candidates.append({
                'chart': chart,
                'day_master': day_master,
                'month_branch': month_branch,
                'qi_sha_stems': [s for _, s in qi_sha_stems],
                'ten_gods': ten_gods
            })
            stats['matched'] += 1
        
        # éªŒè¯æ˜¯å¦æ‰«æäº†å…¨éƒ¨æ ·æœ¬
        if total_scanned < 518400:
            logger.warning(f"âš ï¸ åªæ‰«æäº† {total_scanned} ä¸ªæ ·æœ¬ï¼Œæœªè¾¾åˆ°å…¨é‡518,400ä¸ª")
        else:
            logger.info(f"âœ… å·²æ‰«æå…¨éƒ¨518,400ä¸ªæ ·æœ¬")
        
        logger.info(f"Step Aå®Œæˆï¼šæ‰«æ={total_scanned}ï¼ŒåŒ¹é…={len(candidates)}ï¼Œç›®æ ‡={target_count}")
        logger.info(f"ç»Ÿè®¡ï¼šæœˆä»¤é”æ‹’ç»={stats['rejected_month_lock']}ï¼Œé€æ€æ‹’ç»={stats['rejected_stem_reveal']}ï¼Œçº¯åº¦æ‹’ç»={stats['rejected_purity']}")
        
        # ========== Step B: å¥‡ç‚¹æ•è· (Tier X) ==========
        logger.info("=" * 70)
        logger.info("Step B: å¥‡ç‚¹æ•è· (Tier X)")
        logger.info("=" * 70)
        
        singularities = []
        standard_candidates = []
        
        for sample in candidates:
            day_master = sample['day_master']
            is_singularity, singularity_type = self._detect_singularity(sample, day_master)
            
            if is_singularity:
                sample['singularity_type'] = singularity_type
                sample['purity_score'] = self._calculate_purity_score(sample, day_master)
                singularities.append(sample)
            else:
                standard_candidates.append(sample)
        
        logger.info(f"âœ… å‘ç°å¥‡ç‚¹æ ·æœ¬ {len(singularities)} ä¸ªï¼Œå·²éš”ç¦»")
        logger.info(f"âœ… æ ‡å‡†å€™é€‰æ ·æœ¬ {len(standard_candidates)} ä¸ª")
        
        # ========== Step C: æ ‡å‡†é›†ä¼˜é€‰ (Tier A) ==========
        logger.info("=" * 70)
        logger.info("Step C: æ ‡å‡†é›†ä¼˜é€‰ (Tier A) - çº¯åº¦åŠ æƒæ’åº")
        logger.info("=" * 70)
        
        # è®¡ç®—çº¯åº¦å¾—åˆ†å¹¶æ’åº
        for sample in standard_candidates:
            day_master = sample['day_master']
            sample['purity_score'] = self._calculate_purity_score(sample, day_master)
        
        # æŒ‰çº¯åº¦å¾—åˆ†é™åºæ’åº
        standard_candidates.sort(key=lambda x: x['purity_score'], reverse=True)
        
        # æˆªå–å‰target_countä¸ªä½œä¸ºTier Aæ ‡å‡†é›†
        if len(standard_candidates) > target_count:
            standard_set = standard_candidates[:target_count]
            logger.info(f"âœ… ä» {len(standard_candidates)} ä¸ªå€™é€‰æ ·æœ¬ä¸­ï¼ŒæŒ‰çº¯åº¦æ’åºé€‰å–å‰ {target_count} ä¸ªä½œä¸ºTier Aæ ‡å‡†é›†")
        else:
            standard_set = standard_candidates
            logger.info(f"âœ… å€™é€‰æ ·æœ¬ {len(standard_candidates)} ä¸ªï¼ˆå°‘äºç›®æ ‡ {target_count}ï¼‰ï¼Œå…¨éƒ¨ä½œä¸ºTier Aæ ‡å‡†é›†")
        
        # è¾“å‡ºç»Ÿè®¡
        if standard_set:
            avg_purity = sum(s['purity_score'] for s in standard_set) / len(standard_set)
            max_purity = max(s['purity_score'] for s in standard_set)
            min_purity = min(s['purity_score'] for s in standard_set)
            logger.info(f"Tier Açº¯åº¦ç»Ÿè®¡ï¼šå¹³å‡={avg_purity:.2f}ï¼Œæœ€é«˜={max_purity:.2f}ï¼Œæœ€ä½={min_purity:.2f}")
        
        # ========== ä¿å­˜ç»“æœ ==========
        result = {
            'pattern_id': pattern_id,
            'pattern_name': pattern.get('name_cn', pattern_id),
            'total_scanned': total_scanned,
            'tier_a': {
                'count': len(standard_set),
                'samples': standard_set
            },
            'tier_x': {
                'count': len(singularities),
                'samples': singularities
            },
            'stats': stats
        }
        
        # å¦‚æœæä¾›äº†è¾“å‡ºç›®å½•ï¼Œä¿å­˜æ–‡ä»¶
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜Tier Aæ ‡å‡†é›†
            standard_file = output_dir / f"QGA_{pattern_id}_TierA_Standard.json"
            with open(standard_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'pattern_id': pattern_id,
                    'pattern_name': pattern.get('name_cn', pattern_id),
                    'tier': 'A',
                    'description': 'æ ‡å‡†çº¯å‡€é›†ï¼ˆTier Aï¼‰- æœ€æ•™ç§‘ä¹¦çº§çš„æ ·æœ¬',
                    'count': len(standard_set),
                    'samples': standard_set
                }, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… Tier Aæ ‡å‡†é›†å·²ä¿å­˜: {standard_file}")
            
            # ä¿å­˜Tier Xå¥‡ç‚¹é›†
            if singularities:
                singularity_file = output_dir / f"QGA_{pattern_id}_TierX_Singularity.json"
                with open(singularity_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'pattern_id': pattern_id,
                        'pattern_name': pattern.get('name_cn', pattern_id),
                        'tier': 'X',
                        'description': 'å¥‡ç‚¹é›†ï¼ˆTier Xï¼‰- æç«¯æ ·æœ¬ï¼Œè•´å«æ–°çš„ç‰©ç†å®šå¾‹',
                        'count': len(singularities),
                        'samples': singularities
                    }, f, ensure_ascii=False, indent=2)
                logger.info(f"âœ… Tier Xå¥‡ç‚¹é›†å·²ä¿å­˜: {singularity_file}")
        
        logger.info("=" * 70)
        logger.info(f"âœ… æ ·æœ¬æµ·é€‰å®Œæˆï¼šTier A={len(standard_set)}ä¸ªï¼ŒTier X={len(singularities)}ä¸ª")
        logger.info("=" * 70)
        
        return result

