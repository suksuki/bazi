"""
å…¨æ¯æ ¼å±€æ§åˆ¶å™¨ (Holographic Pattern Controller)
MVC Controller Layer - è´Ÿè´£å…¨æ¯æ ¼å±€çš„ä¸šåŠ¡é€»è¾‘

ä¸¥æ ¼éµå¾ªMVCæ¶æ„åŸåˆ™ï¼š
- Viewå±‚ï¼ˆholographic_pattern.pyï¼‰åªè´Ÿè´£UIå±•ç¤ºå’Œç”¨æˆ·äº¤äº’
- Controllerå±‚å°è£…æ‰€æœ‰ç®—æ³•é€»è¾‘ï¼Œåè°ƒEngineå’ŒModel
- Engineå±‚è´Ÿè´£æ ¸å¿ƒè®¡ç®—

æ³¨æ„ï¼šè¿™æ˜¯å…¨æ–°çš„"å¼ é‡å…¨æ¯æ ¼å±€"ç³»ç»Ÿï¼Œä¸ä¾èµ–ç°æœ‰çš„ç‰©ç†æ¨¡å‹ä»¿çœŸæ³¨å†Œè¡¨
"""

import logging
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import json

from core.trinity.core.unified_arbitrator_master import QuantumUniversalFramework
from core.trinity.core.engines.synthetic_bazi_engine import SyntheticBaziEngine
from core.trinity.core.nexus.definitions import BaziParticleNexus
from core.engine_graph.constants import TWELVE_LIFE_STAGES
from core.trinity.core.intelligence.symbolic_stars import SymbolicStarsEngine

logger = logging.getLogger(__name__)


class HolographicPatternController:
    """
    å…¨æ¯æ ¼å±€æ§åˆ¶å™¨
    
    èŒè´£ï¼š
    - å°è£…å…¨æ¯æ ¼å±€ç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
    - åè°ƒæ ¼å±€æ³¨å†Œè¡¨çš„åŠ è½½å’ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨æ–°çš„"å¼ é‡å…¨æ¯æ ¼å±€"æ³¨å†Œè¡¨ï¼‰
    - å¤„ç†äº”ç»´å¼ é‡æŠ•å½±è®¡ç®—
    - æä¾›ç»Ÿä¸€çš„æ•°æ®æ¥å£ç»™Viewå±‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ§åˆ¶å™¨"""
        # ä½¿ç”¨æ–°çš„"å¼ é‡å…¨æ¯æ ¼å±€"æ³¨å†Œè¡¨è·¯å¾„
        self.registry_path = Path(__file__).parent.parent / "core" / "subjects" / "holographic_pattern" / "registry.json"
        self.registry = None
        self.framework = QuantumUniversalFramework()
        # åˆå§‹åŒ–RegistryLoaderç”¨äºV2.1+ç‰ˆæœ¬çš„è®¡ç®—
        from core.registry_loader import RegistryLoader
        self.registry_loader = RegistryLoader()
        logger.info("HolographicPatternController initialized (å…¨æ–°å¼ é‡å…¨æ¯æ ¼å±€ç³»ç»Ÿ)")
    
    def load_registry(self) -> Dict:
        """
        åŠ è½½æ ¼å±€æ³¨å†Œè¡¨
        
        Returns:
            æ³¨å†Œè¡¨å­—å…¸
        """
        if self.registry is None:
            try:
                with open(self.registry_path, 'r', encoding='utf-8') as f:
                    self.registry = json.load(f)
                logger.info(f"âœ… å·²åŠ è½½æ³¨å†Œè¡¨: {len(self.registry.get('patterns', {}))} ä¸ªæ ¼å±€")
            except Exception as e:
                logger.error(f"åŠ è½½æ³¨å†Œè¡¨å¤±è´¥: {e}")
                self.registry = {"patterns": {}, "metadata": {}}
        
        return self.registry
    
    def _get_display_name_cn(self, pattern_data: Dict, pattern_id: str) -> str:
        """Helper to extract display name in Chinese."""
        if pattern_data.get('name_cn'):
            return pattern_data['name_cn']
        
        # Try meta_info Chinese Name (Primary source after normalization)
        if 'meta_info' in pattern_data and pattern_data['meta_info'].get('chinese_name'):
            return pattern_data['meta_info']['chinese_name']
            
        # Try meta_info Display Name but mark as English
        if 'meta_info' in pattern_data and pattern_data['meta_info'].get('name'):
            return pattern_data['meta_info']['name']
            
        # Try Regex from name if format is 'Name (ChineseName)'
        name = pattern_data.get('name', '')
        if '(' in name and ')' in name:
            import re
            match = re.search(r'[\(ï¼ˆ](.*?)[\)ï¼‰]', name)
            if match:
                return match.group(1)
                
        return name if name else pattern_id

    def get_all_patterns(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ ¼å±€åˆ—è¡¨ï¼ˆæŒ‰QGA-HR V1.0å±‚çº§å‘½åè§„èŒƒï¼‰
        æ”¯æŒä¸»æ ¼å±€å’Œå­æ ¼å±€çš„å±‚çº§å…³ç³»
        
        Returns:
            æ ¼å±€åˆ—è¡¨ï¼ŒæŒ‰Categoryå’ŒSubject IDæ’åºï¼Œå­æ ¼å±€è·Ÿéšä¸»æ ¼å±€
        """
        registry = self.load_registry()
        patterns = registry.get('patterns', {})
        
        # åˆ†ç¦»ä¸»æ ¼å±€å’Œå­æ ¼å±€
        main_patterns = []
        sub_patterns = []
        
        for pattern_id, pattern_data in patterns.items():
            # æå–å±‚çº§ä¿¡æ¯
            category = pattern_data.get('category', '')
            subject_id = pattern_data.get('subject_id', pattern_id)
            parent_pattern = pattern_data.get('parent_pattern')
            
            p_info = {
                'id': pattern_id,
                'category': category,
                'subject_id': subject_id,
                'name': pattern_data.get('name', pattern_id),
                'name_cn': self._get_display_name_cn(pattern_data, pattern_id),
                'icon': pattern_data.get('icon', 'ğŸ§¬'),
                'description': pattern_data.get('description', ''),
                'version': pattern_data.get('version', 'N/A'),
                'active': pattern_data.get('active', True),
                'parent_pattern': parent_pattern,
                'is_sub_pattern': parent_pattern is not None
            }
            
            if parent_pattern:
                sub_patterns.append(p_info)
            else:
                main_patterns.append(p_info)
                # [V2.5] å‘ç°åµŒå¥—å­æ ¼å±€
                # [V2.5] å‘ç°åµŒå¥—å­æ ¼å±€ (æ”¯æŒ sub_patterns_registry å’Œ sub_patterns)
                sub_patterns_data = pattern_data.get('sub_patterns_registry') or pattern_data.get('sub_patterns') or []
                if sub_patterns_data:
                    for sub_data in sub_patterns_data:
                        sub_info = {
                            'id': sub_data.get('id'),
                            'category': category,
                            'subject_id': sub_data.get('subject_id', sub_data.get('id')),
                            'name': sub_data.get('name'),
                            'name_cn': self._get_display_name_cn(sub_data, sub_data.get('id')),
                            'icon': sub_data.get('icon', p_info['icon']),
                            'description': sub_data.get('description'),
                            'version': p_info['version'],
                            'active': True,
                            'parent_pattern': pattern_id,
                            'is_sub_pattern': True
                        }
                        sub_patterns.append(sub_info)
        
        # ä¸»æ ¼å±€æŒ‰Categoryå’ŒSubject IDæ’åº
        main_patterns.sort(key=lambda x: (x.get('category', ''), x.get('subject_id', '')))
        
        # å­æ ¼å±€æŒ‰çˆ¶æ ¼å±€åˆ†ç»„ï¼Œç„¶åæŒ‰Subject IDæ’åº
        sub_patterns_by_parent = {}
        for sub_pattern in sub_patterns:
            parent_id = sub_pattern['parent_pattern']
            if parent_id not in sub_patterns_by_parent:
                sub_patterns_by_parent[parent_id] = []
            sub_patterns_by_parent[parent_id].append(sub_pattern)
        
        # å¯¹æ¯ä¸ªçˆ¶æ ¼å±€çš„å­æ ¼å±€æ’åº
        for parent_id in sub_patterns_by_parent:
            sub_patterns_by_parent[parent_id].sort(key=lambda x: x.get('subject_id', ''))
        
        # æ„å»ºå±‚çº§ç»“æœï¼šä¸»æ ¼å±€ + å…¶å­æ ¼å±€
        result = []
        for main_pattern in main_patterns:
            # æ·»åŠ ä¸»æ ¼å±€
            result.append(main_pattern)
            
            # æ·»åŠ è¯¥ä¸»æ ¼å±€çš„å­æ ¼å±€
            main_id = main_pattern['id']
            if main_id in sub_patterns_by_parent:
                for sub_pattern in sub_patterns_by_parent[main_id]:
                    result.append(sub_pattern)
        
        # å¤„ç†æ²¡æœ‰çˆ¶æ ¼å±€çš„å­æ ¼å±€ï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼Œä½†ä¸ºäº†å¥å£®æ€§ï¼‰
        for sub_pattern in sub_patterns:
            if sub_pattern['parent_pattern'] not in [p['id'] for p in main_patterns]:
                result.append(sub_pattern)
        
        return result
    
    def get_pattern_hierarchy(self) -> Dict[str, Dict]:
        """
        è·å–æ ¼å±€å±‚çº§ç»“æ„ï¼ˆä¸»æ ¼å±€ -> å­æ ¼å±€ï¼‰
        
        Returns:
            å­—å…¸ï¼š{ä¸»æ ¼å±€ID: {'main': ä¸»æ ¼å±€ä¿¡æ¯, 'subs': [å­æ ¼å±€åˆ—è¡¨]}}
        """
        registry = self.load_registry()
        patterns = registry.get('patterns', {})
        
        hierarchy = {}
        
        # å…ˆæ‰¾å‡ºæ‰€æœ‰ä¸»æ ¼å±€
        for pattern_id, pattern_data in patterns.items():
            parent_pattern = pattern_data.get('parent_pattern')
            if not parent_pattern:  # ä¸»æ ¼å±€
                category = pattern_data.get('category', '')
                subject_id = pattern_data.get('subject_id', pattern_id)
                
                hierarchy[pattern_id] = {
                    'main': {
                        'id': pattern_id,
                        'category': category,
                        'subject_id': subject_id,
                        'name': pattern_data.get('name', pattern_id),
                        'name_cn': self._get_display_name_cn(pattern_data, pattern_id),
                        'icon': pattern_data.get('icon', 'ğŸ§¬'),
                        'description': pattern_data.get('description', ''),
                        'version': pattern_data.get('version', 'N/A'),
                        'active': pattern_data.get('active', False)
                    },
                    'subs': []
                }
        
        # å†æ‰¾å‡ºæ‰€æœ‰å­æ ¼å±€å¹¶å½’ç±»
        for pattern_id, pattern_data in patterns.items():
            parent_pattern = pattern_data.get('parent_pattern')
            if parent_pattern and parent_pattern in hierarchy:
                # ... (existing flat logic)
                pass # Already handled by flat structure
            
            # [V2.5] å‘ç°åµŒå¥—å­æ ¼å±€ (æ”¯æŒ sub_patterns_registry å’Œ sub_patterns)
            sub_patterns_list = pattern_data.get('sub_patterns_registry') or pattern_data.get('sub_patterns') or []
            if sub_patterns_list and pattern_id in hierarchy:
                for sub_data in sub_patterns_list:
                    # ä½¿ç”¨ helper è·å–ä¸­æ–‡å
                    name_cn = self._get_display_name_cn(sub_data, sub_data.get('id'))
                            
                    hierarchy[pattern_id]['subs'].append({
                        'id': sub_data.get('id'),
                        'category': hierarchy[pattern_id]['main']['category'],
                        'subject_id': sub_data.get('subject_id', sub_data.get('id')),
                        'name': sub_data.get('name'),
                        'name_cn': name_cn,
                        'icon': sub_data.get('icon', hierarchy[pattern_id]['main']['icon']), # Inherit icon if missing
                        'description': sub_data.get('description'),
                        'version': hierarchy[pattern_id]['main']['version'],
                        'active': True
                    })
        
        # å¯¹æ¯ä¸ªä¸»æ ¼å±€çš„å­æ ¼å±€æ’åº
        for parent_id in hierarchy:
            hierarchy[parent_id]['subs'].sort(key=lambda x: x.get('subject_id', ''))
        
        return hierarchy
    
    def calculate_evolution(
        self,
        pattern_id: str,
        chart: List[str],
        day_master: str,
        year: int,
        geo_city: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """
        è®¡ç®—åŠ¨æ€æ¼”åŒ–çŠ¶æ€ï¼ˆåŸºäºFDS-V1.1 Step 6ï¼‰
        
        Args:
            pattern_id: æ ¼å±€ID
            chart: å››æŸ±å…«å­—
            day_master: æ—¥ä¸»
            year: æ¼”åŒ–å¹´ä»½
            geo_city: åœ°ç†åŸå¸‚ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ¼”åŒ–ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - base_tensor: åŸå±€åŸºæ€å¼ é‡
            - luck_tensor: å¤§è¿æ³¨å…¥åçš„å¼ é‡
            - year_tensor: æµå¹´æ³¨å…¥åçš„å¼ é‡
            - final_tensor: åœ°ç†ä¿®æ­£åçš„æœ€ç»ˆå¼ é‡
            - status: è¾“å‡ºçŠ¶æ€ï¼ˆSTABLE, CRITICAL, FRACTURED, MUTATEDï¼‰
            - deformation_type: å½¢å˜ç±»å‹ï¼ˆELASTIC, PLASTIC, FRACTUREï¼‰
        """
        try:
            # 1. è®¡ç®—åŸå±€åŸºæ€
            base_result = self.calculate_tensor_projection(pattern_id, chart, day_master)
            if 'error' in base_result:
                return {'error': base_result['error']}
            
            base_tensor = base_result['projection']
            
            # 2. è·å–å¤§è¿å’Œæµå¹´ï¼ˆç®€åŒ–ï¼šä½¿ç”¨æ¡†æ¶è®¡ç®—ï¼‰
            # è¿™é‡Œéœ€è¦ä»BaziProfileè·å–ï¼Œæš‚æ—¶ç®€åŒ–å¤„ç†
            from core.bazi_profile import BaziProfile
            from datetime import datetime
            
            # åˆ›å»ºä¸´æ—¶BaziProfileç”¨äºè®¡ç®—å¤§è¿æµå¹´
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®Œæ•´çš„å‡ºç”Ÿä¿¡æ¯ï¼Œæš‚æ—¶ä½¿ç”¨ç®€åŒ–æ–¹æ³•
            # Controllerä¸åº”è¯¥ç›´æ¥è®¿é—®session_stateï¼Œåº”è¯¥é€šè¿‡å‚æ•°ä¼ å…¥
            luck_pillar = "ç”²å­"  # é»˜è®¤å€¼ï¼Œå®é™…åº”è¯¥ä»contextä¼ å…¥
            year_pillar = "ç”²å­"  # é»˜è®¤å€¼ï¼Œå®é™…åº”è¯¥ä»contextä¼ å…¥
            
            # 3. è®¡ç®—å¤§è¿æ³¨å…¥ï¼ˆç®€åŒ–ï¼šä½¿ç”¨å›ºå®šç³»æ•°ï¼‰
            luck_tensor = base_tensor.copy()
            # è¿™é‡Œåº”è¯¥æ ¹æ®å¤§è¿å¹²æ”¯è®¡ç®—å½±å“ï¼Œæš‚æ—¶ç®€åŒ–
            luck_effect = 1.0  # é»˜è®¤æ— å½±å“
            
            # 4. è®¡ç®—æµå¹´æ³¨å…¥ï¼ˆä¸»è¦å½±å“Sè½´ï¼‰
            year_tensor = luck_tensor.copy()
            # ç®€åŒ–ï¼šæµå¹´ä¸»è¦å½±å“åº”åŠ›è½´
            year_impulse = 0.0  # é»˜è®¤æ— è„‰å†²
            
            # 5. åœ°ç†ä¿®æ­£ï¼ˆå¦‚æœæœ‰ï¼‰
            final_tensor = year_tensor.copy()
            if geo_city:
                from ui.pages.quantum_lab import GEO_CITY_MAP
                if geo_city in GEO_CITY_MAP:
                    geo_factor, geo_element = GEO_CITY_MAP[geo_city]
                    # æ ¹æ®äº”è¡Œåå‘ä¿®æ­£å¯¹åº”è½´
                    element_axis_map = {
                        'Fire': 'E',
                        'Earth': 'M',
                        'Metal': 'O',
                        'Water': 'R',
                        'Wood': 'S'
                    }
                    target_axis = element_axis_map.get(geo_element, 'E')
                    final_tensor[target_axis] = final_tensor.get(target_axis, 0) * geo_factor
            
            # 6. è·å–æ–­è£‚é˜ˆå€¼ï¼ˆä»æ³¨å†Œè¡¨ï¼‰
            pattern = self.get_pattern_by_id(pattern_id)
            fracture_threshold = 50.0  # é»˜è®¤å€¼
            if pattern:
                dynamic_sim = pattern.get('kinetic_evolution', {}).get('dynamic_simulation', {})
                fracture_threshold = dynamic_sim.get('fracture_threshold', 50.0)
            
            # 7. åˆ¤å®šè¾“å‡ºçŠ¶æ€
            # æ³¨æ„ï¼šfinal_tensorçš„å€¼æ˜¯æŠ•å½±å€¼ï¼ˆå·²ç»ä¹˜ä»¥SAIï¼‰ï¼Œéœ€è¦è½¬æ¢ä¸ºåº”åŠ›ç™¾åˆ†æ¯”
            # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨Sè½´çš„æŠ•å½±å€¼ä½œä¸ºåº”åŠ›æŒ‡æ ‡
            s_projection = final_tensor.get('S', 0)
            # å°†æŠ•å½±å€¼è½¬æ¢ä¸ºåº”åŠ›ç™¾åˆ†æ¯”ï¼ˆå‡è®¾SAI=1.0æ—¶ï¼ŒSæŠ•å½±å€¼=æƒé‡ï¼Œéœ€è¦æ”¾å¤§ï¼‰
            # è¿™é‡Œç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨SæŠ•å½±å€¼ï¼Œå¦‚æœSAI>0åˆ™ç”¨SAIå½’ä¸€åŒ–
            base_sai = base_result.get('sai', 1.0)
            if base_sai > 0:
                s_value = (s_projection / base_sai) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            else:
                s_value = s_projection * 100  # å¦‚æœSAIä¸º0ï¼Œç›´æ¥ä½¿ç”¨æŠ•å½±å€¼
            
            if s_value < 0.6 * fracture_threshold:
                status = 'STABLE'
                deformation_type = 'ELASTIC'
            elif s_value < fracture_threshold:
                status = 'CRITICAL'
                deformation_type = 'PLASTIC'
            else:
                status = 'FRACTURED'
                deformation_type = 'FRACTURE'
            
            # 8. ç”Ÿæˆæè¿°
            description = f"åœ¨{year}å¹´ï¼Œç³»ç»Ÿå¤„äº{status}çŠ¶æ€"
            if geo_city:
                description += f"ï¼Œåœ°ç†ç¯å¢ƒï¼š{geo_city}"
            
            return {
                'base_tensor': base_tensor,
                'luck_tensor': luck_tensor,
                'year_tensor': year_tensor,
                'final_tensor': final_tensor,
                'status': status,
                'deformation_type': deformation_type,
                'description': description,
                'year': year,
                'geo_city': geo_city
            }
            
        except Exception as e:
            logger.error(f"è®¡ç®—åŠ¨æ€æ¼”åŒ–å¤±è´¥: {e}", exc_info=True)
            return {'error': str(e)}
    
    def get_pattern_by_id(self, pattern_id: str) -> Optional[Dict]:
        """
        æ ¹æ®IDè·å–æ ¼å±€è¯¦æƒ…
        æ”¯æŒåœ¨ä¸»æ ¼å±€å’ŒåµŒå¥—å­æ ¼å±€ä¸­æŸ¥æ‰¾
        """
        registry = self.load_registry()
        patterns = registry.get('patterns', {})
        
        # 1. æ£€æŸ¥ä¸»æ ¼å±€
        if pattern_id in patterns:
            return patterns[pattern_id]
        
        # 2. æ£€æŸ¥åµŒå¥—å­æ ¼å±€
        for pid, data in patterns.items():
            if 'sub_patterns_registry' in data:
                for sub in data['sub_patterns_registry']:
                    if sub.get('id') == pattern_id:
                        # [V2.5] è‡ªåŠ¨åˆå¹¶ä¸»æ ¼å±€çš„å†…æ ¸é…ç½®ä»¥æ”¯æŒè®¡ç®—
                        combined = sub.copy()
                        combined['physics_kernel'] = sub.get('physics_kernel', data.get('physics_kernel'))
                        combined['version'] = sub.get('version', data.get('version', '2.5'))
                        return combined
        
        return None
    
    def calculate_tensor_projection(self, pattern_id: str, chart: List[str], 
                                   day_master: str, context: Optional[Dict] = None) -> Dict:
        """
        è®¡ç®—äº”ç»´å¼ é‡æŠ•å½±ï¼ˆæ”¯æŒFDS-V1.1å’ŒFDS-V1.4 V2.1ï¼‰
        
        Args:
            pattern_id: æ ¼å±€ID
            chart: å…«å­—åŸå±€
            day_master: æ—¥ä¸»
            context: ä¸Šä¸‹æ–‡ï¼ˆå¤§è¿ã€æµå¹´ç­‰ï¼‰
            
        Returns:
            äº”ç»´å¼ é‡æŠ•å½±ç»“æœ
        """
        # è·å–æ ¼å±€ä¿¡æ¯
        pattern = self.get_pattern_by_id(pattern_id)
        if not pattern:
            return {'error': f'æ ¼å±€ {pattern_id} ä¸å­˜åœ¨'}
        
        # [V2.5 Update] Detect Matrix Protocol by kernel signature or version string
        version = str(pattern.get('version', '1.0'))
        physics_kernel = pattern.get('physics_kernel', {})
        is_matrix_protocol = (
            str(version) >= '1.5' or 
            physics_kernel.get('transfer_matrix') is not None
        )
        
        logger.debug(f"æ ¼å±€ {pattern_id} æ ¸éªŒ: version={version!r}, is_matrix_protocol={is_matrix_protocol}")
        
        # V1.5+/V2.1+: ä½¿ç”¨RegistryLoaderçš„çŸ©é˜µæŠ•å½±æ–¹æ³•
        if is_matrix_protocol:
            logger.info(f"âœ… æ£€æµ‹åˆ°çŸ©é˜µåè®®æ ¼å±€ {pattern_id}ï¼Œä½¿ç”¨transfer_matrixè®¡ç®—")
            try:
                if not hasattr(self, 'registry_loader') or self.registry_loader is None:
                    logger.error("RegistryLoaderæœªåˆå§‹åŒ–ï¼")
                    return {'error': 'RegistryLoaderæœªåˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨V2.1çŸ©é˜µè®¡ç®—'}
                
                result = self.registry_loader.calculate_tensor_projection_from_registry(
                    pattern_id=pattern_id,
                    chart=chart,
                    day_master=day_master,
                    context=context
                )
                
                logger.info(f"V2.1è®¡ç®—ç»“æœ: sai={result.get('sai', 'N/A')}, projection={result.get('projection', {})}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                if 'error' in result:
                    logger.error(f"V2.1è®¡ç®—è¿”å›é”™è¯¯: {result['error']}")
                    return result
                
                # æ£€æŸ¥SAIæ˜¯å¦ä¸º0
                if result.get('sai', 0) == 0:
                    logger.warning(f"âš ï¸ V2.1è®¡ç®—è¿”å›SAI=0ï¼Œæ£€æŸ¥è®¡ç®—é€»è¾‘")
                    # æ£€æŸ¥æ˜¯å¦æœ‰raw_projection
                    raw_projection = result.get('raw_projection', {})
                    if raw_projection:
                        logger.warning(f"raw_projection: {raw_projection}")
                    # æ£€æŸ¥frequency_vector
                    frequency_vector = result.get('frequency_vector', {})
                    if frequency_vector:
                        logger.warning(f"frequency_vector: {frequency_vector}")
                
                # ç¡®ä¿è¿”å›æ ¼å¼ä¸æ—§ç‰ˆæœ¬å…¼å®¹
                # æ·»åŠ pattern_nameç­‰å­—æ®µä»¥ä¿æŒå…¼å®¹æ€§
                if 'pattern_name' not in result:
                    result['pattern_name'] = pattern.get('name', pattern_id)
                # æ·»åŠ semantic_seed
                semantic_seed = pattern.get('semantic_seed', {})
                if 'semantic_seed' not in result:
                    result['semantic_seed'] = semantic_seed.get('description', '')
                # æ·»åŠ tensor_operatorï¼ˆç”¨äºUIæ˜¾ç¤ºï¼‰
                tensor_operator = pattern.get('tensor_operator', {})
                if 'tensor_operator' not in result:
                    result['tensor_operator'] = tensor_operator
                
                # ç¡®ä¿weightså­—æ®µå­˜åœ¨ï¼ˆç”¨äºUIå…¼å®¹ï¼‰
                if 'weights' not in result:
                    # ä»tensor_operatorè·å–weightsä½œä¸ºfallback
                    weights = tensor_operator.get('weights', {})
                    result['weights'] = weights
                
                logger.info(f"âœ… V2.1è®¡ç®—æˆåŠŸ: sai={result.get('sai', 0):.4f}")
                return result
            except Exception as e:
                logger.error(f"âŒ V2.1çŸ©é˜µè®¡ç®—å¤±è´¥: {e}", exc_info=True)
                # ä¸é™é»˜å›é€€ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                return {
                    'error': f'V2.1çŸ©é˜µè®¡ç®—å¤±è´¥: {str(e)}',
                    'pattern_id': pattern_id,
                    'pattern_name': pattern.get('name', pattern_id),
                    'sai': 0,
                    'projection': {'E': 0, 'O': 0, 'M': 0, 'S': 0, 'R': 0},
                    'sai_warning': f'V2.1è®¡ç®—å¼‚å¸¸: {str(e)}'
                }
        
        # V1.0/V2.0: ä½¿ç”¨æ—§çš„tensor_operatoré€»è¾‘
        # è·å–å¼ é‡æŠ•å½±ç®—å­ï¼ˆæ¨¡å—IIï¼‰
        tensor_operator = pattern.get('tensor_operator', {})
        weights = tensor_operator.get('weights', {})
        
        # å¦‚æœæ²¡æœ‰æƒé‡ï¼Œè¿”å›é”™è¯¯ï¼ˆå¿…é¡»é€šè¿‡FDS-V1.1 Step 1æ³¨å†Œï¼‰
        if not weights:
            return {
                'error': f'æ ¼å±€ {pattern_id} å°šæœªå®ŒæˆFDS-V1.1 Step 1æ³¨å†Œï¼ˆç¼ºå°‘å¼ é‡æŠ•å½±ç®—å­ï¼‰',
                'pattern_id': pattern_id,
                'pattern_name': pattern.get('name', pattern_id)
            }
        
        # éªŒè¯æƒé‡å½’ä¸€åŒ–ï¼ˆå•ä½å‘é‡çº¦æŸï¼‰
        if not tensor_operator.get('normalized', False):
            weights = self.normalize_weights(weights)
            logger.warning(f"æ ¼å±€ {pattern_id} æƒé‡æœªå½’ä¸€åŒ–ï¼Œå·²è‡ªåŠ¨å½’ä¸€åŒ–")
        
        # è®¡ç®—SAIï¼ˆç³»ç»Ÿå¯¹é½æŒ‡æ•°ï¼‰
        sai = 0.0
        sai_error = None
        try:
            binfo = {'day_master': day_master}
            if context:
                ctx = {
                    'luck_pillar': context.get('luck_pillar'),
                    'annual_pillar': context.get('annual_pillar'),
                    'scenario': context.get('scenario', 'default')
                }
            else:
                ctx = {'scenario': 'default'}
            
            result = self.framework.arbitrate_bazi(chart, binfo, ctx)
            
            # SAIåœ¨result['physics']['stress']['SAI']ä¸­
            physics = result.get('physics', {})
            stress = physics.get('stress', {})
            sai = stress.get('SAI', 0.0)
            
            # å¦‚æœSAIä¸º0ï¼Œè®°å½•è­¦å‘Šå¹¶å°è¯•è¯Šæ–­
            if sai == 0.0:
                # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯ç”¨çš„åº”åŠ›æŒ‡æ ‡
                if stress:
                    # å°è¯•ä»å…¶ä»–å­—æ®µè·å–SAI
                    for key in ['sai', 'SAI', 'stress_index', 'system_alignment']:
                        if key in stress and stress[key] != 0.0:
                            sai = stress[key]
                            logger.info(f"ä»å­—æ®µ {key} è·å–SAIå€¼: {sai}")
                            break
                
                if sai == 0.0:
                    # è¯Šæ–­ä¿¡æ¯
                    diagnostic = {
                        'chart': chart,
                        'day_master': day_master,
                        'pattern_id': pattern_id,
                        'physics_keys': list(physics.keys()) if physics else [],
                        'stress_keys': list(stress.keys()) if stress else [],
                        'result_structure': list(result.keys()) if isinstance(result, dict) else 'not_dict'
                    }
                    logger.warning(
                        f"SAIè®¡ç®—ç»“æœä¸º0.0ï¼Œè¯Šæ–­ä¿¡æ¯: {diagnostic}\n"
                        f"å¯èƒ½çš„åŸå› ï¼š1) å…«å­—ä¸åŒ¹é…è¯¥æ ¼å±€ 2) è®¡ç®—å¼‚å¸¸ 3) ç»“æ„è¿‡äºç¨³å®š 4) æ¡†æ¶è¿”å›æ ¼å¼å¼‚å¸¸"
                    )
                    sai_error = "SAIè®¡ç®—ä¸º0ï¼Œå¯èƒ½æ˜¯æ ¼å±€ä¸åŒ¹é…æˆ–è®¡ç®—æ¡†æ¶å¼‚å¸¸"
        except Exception as e:
            logger.error(f"è®¡ç®—SAIå¤±è´¥: {e}", exc_info=True)
            sai_error = f"SAIè®¡ç®—å¼‚å¸¸: {str(e)}"
            sai = 0.0
        
        # è®¡ç®—äº”ç»´æŠ•å½±ï¼ˆSAI Ã— æƒé‡ï¼‰
        projection = {
            'E': sai * weights.get('E', 0.0),  # èƒ½çº§è½´
            'O': sai * weights.get('O', 0.0),  # ç§©åºè½´
            'M': sai * weights.get('M', 0.0),  # ç‰©è´¨è½´
            'S': sai * weights.get('S', 0.0),  # åº”åŠ›è½´
            'R': sai * weights.get('R', 0.0)   # å…³è”è½´
        }
        
        # è·å–è¯­ä¹‰æ„è±¡ï¼ˆæ¨¡å—Iï¼‰
        semantic_seed = pattern.get('semantic_seed', {})
        
        result_dict = {
            'pattern_id': pattern_id,
            'pattern_name': pattern.get('name', pattern_id),
            'sai': sai,
            'projection': projection,
            'weights': weights,
            'semantic_seed': semantic_seed.get('description', ''),
            'tensor_operator': tensor_operator
        }
        
        # å¦‚æœSAIä¸º0ä¸”æœ‰é”™è¯¯ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if sai == 0.0 and sai_error:
            result_dict['sai_warning'] = sai_error
        
        return result_dict
    
    def normalize_weights(self, weights: Dict[str, float]) -> Dict[str, float]:
        """
        æƒé‡å½’ä¸€åŒ–ï¼ˆå•ä½å‘é‡çº¦æŸï¼‰
        
        Args:
            weights: æƒé‡å­—å…¸
            
        Returns:
            å½’ä¸€åŒ–åçš„æƒé‡å­—å…¸
        """
        total = sum(abs(v) for v in weights.values())
        if total == 0:
            return weights
        
        return {k: round(v / total, 4) for k, v in weights.items()}
    
    def _check_strong_root(self, stem: str, branch: str) -> bool:
        """
        æ£€æŸ¥å¤©å¹²æ˜¯å¦åå¼ºæ ¹ï¼ˆç®€åŒ–ç‰ˆï¼šæ£€æŸ¥åœ°æ”¯æœ¬æ°”æ˜¯å¦ä¸ºå¤©å¹²çš„åŒç±»äº”è¡Œï¼‰
        
        Args:
            stem: å¤©å¹²
            branch: åœ°æ”¯
            
        Returns:
            æ˜¯å¦åå¼ºæ ¹
        """
        # å¤©å¹²äº”è¡Œ
        stem_wuxing = {
            'ç”²': 'æœ¨', 'ä¹™': 'æœ¨',
            'ä¸™': 'ç«', 'ä¸': 'ç«',
            'æˆŠ': 'åœŸ', 'å·±': 'åœŸ',
            'åºš': 'é‡‘', 'è¾›': 'é‡‘',
            'å£¬': 'æ°´', 'ç™¸': 'æ°´'
        }
        
        # åœ°æ”¯æœ¬æ°”äº”è¡Œ
        branch_wuxing = {
            'å­': 'æ°´', 'ä¸‘': 'åœŸ', 'å¯…': 'æœ¨', 'å¯': 'æœ¨',
            'è¾°': 'åœŸ', 'å·³': 'ç«', 'åˆ': 'ç«', 'æœª': 'åœŸ',
            'ç”³': 'é‡‘', 'é…‰': 'é‡‘', 'æˆŒ': 'åœŸ', 'äº¥': 'æ°´'
        }
        
        stem_wx = stem_wuxing.get(stem, '')
        branch_wx = branch_wuxing.get(branch, '')
        
        # å¼ºæ ¹ï¼šåœ°æ”¯æœ¬æ°”ä¸å¤©å¹²åŒäº”è¡Œ
        if stem_wx == branch_wx:
            return True
        
        # æ£€æŸ¥åœ°æ”¯è—å¹²ï¼ˆç®€åŒ–ï¼šåªæ£€æŸ¥ä¸»è¦è—å¹²ï¼‰
        # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´è¯¦ç»†çš„è—å¹²æ£€æŸ¥
        return False
    
    def _calculate_purity_score(self, sample: Dict, day_master: str) -> float:
        """
        è®¡ç®—æ ·æœ¬çº¯åº¦å¾—åˆ†ï¼ˆåŸºäºAIåˆ†æå¸ˆæœ€æ–°è§„èŒƒï¼‰
        
        Args:
            sample: æ ·æœ¬å­—å…¸
            day_master: æ—¥ä¸»
            
        Returns:
            çº¯åº¦å¾—åˆ†ï¼ˆè¶Šé«˜è¶Šçº¯å‡€ï¼‰
        """
        chart = sample['chart']
        stems = [p[0] for p in chart]
        branches = [p[1] for p in chart]
        ten_gods = sample['ten_gods']
        
        # åŸºç¡€åˆ†
        score = 100.0
        
        # åŠ åˆ†é¡¹
        # +20åˆ†ï¼šä¸ƒæ€åå¼ºæ ¹ï¼ˆå¦‚åºšç”³ï¼‰
        qi_sha_stems = sample.get('qi_sha_stems', [])
        for qi_sha_stem in qi_sha_stems:
            # æ‰¾åˆ°ä¸ƒæ€æ‰€åœ¨ä½ç½®
            for i, s in enumerate(stems):
                if s == qi_sha_stem:
                    # æ£€æŸ¥å¯¹åº”çš„åœ°æ”¯æ˜¯å¦å¼ºæ ¹
                    if self._check_strong_root(qi_sha_stem, branches[i]):
                        score += 20
                        break  # åªåŠ ä¸€æ¬¡åˆ†
        
        # +10åˆ†ï¼šå°æ˜Ÿè´´èº«ï¼ˆæœ‰é€šå…³å†·å´ï¼‰
        yin_count = ten_gods.count('æ­£å°') + ten_gods.count('åå°')
        if yin_count > 0:
            score += yin_count * 10
        
        # å‡åˆ†é¡¹
        # -15åˆ†ï¼šé£Ÿä¼¤æ··æ‚ï¼ˆåˆ¶æ€å¤ªè¿‡æˆ–å¹²æ‰°ç£åœºï¼‰
        shi_shen_count = ten_gods.count('é£Ÿç¥') + ten_gods.count('ä¼¤å®˜')
        if shi_shen_count > 0:
            score -= shi_shen_count * 15
        
        # -15åˆ†ï¼šè´¢æ˜Ÿå…šæ€ï¼ˆå¢åŠ åº”åŠ›é£é™©ï¼‰
        cai_count = ten_gods.count('æ­£è´¢') + ten_gods.count('åè´¢')
        if cai_count > 0:
            score -= cai_count * 15
        
        # -10åˆ†ï¼šåœ°æ”¯æœ‰åˆ‘/å†²/ç©¿ï¼ˆç»“æ„ä¸ç¨³ï¼‰
        clash_pairs = [('å­', 'åˆ'), ('ä¸‘', 'æœª'), ('å¯…', 'ç”³'), ('å¯', 'é…‰'), 
                      ('è¾°', 'æˆŒ'), ('å·³', 'äº¥')]
        harm_pairs = [('å­', 'æœª'), ('ä¸‘', 'åˆ'), ('å¯…', 'å·³'), ('å¯', 'è¾°'),
                     ('ç”³', 'äº¥'), ('é…‰', 'æˆŒ')]
        
        has_clash = False
        has_harm = False
        for i, b1 in enumerate(branches):
            for j, b2 in enumerate(branches[i+1:], i+1):
                if (b1, b2) in clash_pairs or (b2, b1) in clash_pairs:
                    has_clash = True
                if (b1, b2) in harm_pairs or (b2, b1) in harm_pairs:
                    has_harm = True
        
        if has_clash or has_harm:
            score -= 10
        
        return score
    
    def _detect_singularity(self, sample: Dict, day_master: str) -> Tuple[bool, str]:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºå¥‡ç‚¹æ ·æœ¬ï¼ˆåŸºäºAIåˆ†æå¸ˆæœ€æ–°è§„èŒƒï¼‰
        
        Args:
            sample: æ ·æœ¬å­—å…¸
            day_master: æ—¥ä¸»
            
        Returns:
            (æ˜¯å¦ä¸ºå¥‡ç‚¹, å¥‡ç‚¹ç±»å‹)
        """
        chart = sample['chart']
        stems = [p[0] for p in chart]
        branches = [p[1] for p in chart]
        ten_gods = sample['ten_gods']
        
        # è·å–ç¾Šåˆƒåœ°æ”¯
        yang_ren_map = SymbolicStarsEngine.YANG_REN_MAP
        yang_ren_branch = yang_ren_map.get(day_master)
        
        # 1. èƒ½é‡æº¢å‡ºï¼šåœ°æ”¯ç¾Šåˆƒæ•°é‡ >= 3ï¼ˆå¦‚ï¼šåœ°æ”¯ä¸‰å¯ï¼‰
        yang_ren_count = branches.count(yang_ren_branch) if yang_ren_branch else 0
        if yang_ren_count >= 3:
            return True, "X1-èšå˜ä¸´ç•Œå‹ï¼ˆåœ°æ”¯ä¸‰åˆƒï¼‰"
        
        # 2. é«˜å‹ä¸´ç•Œï¼šå¤©å¹²é€å‡º2ä¸ªæˆ–ä»¥ä¸Šä¸ƒæ€ï¼Œä¸”å››æŸ±æ— é£Ÿç¥ï¼ˆåˆ¶ï¼‰æ— å°æ˜Ÿï¼ˆåŒ–ï¼‰ï¼Œçº¯ç²¹æ”»èº«
        qi_sha_count = ten_gods.count('ä¸ƒæ€')
        yin_count = ten_gods.count('æ­£å°') + ten_gods.count('åå°')
        shi_shen_count = ten_gods.count('é£Ÿç¥') + ten_gods.count('ä¼¤å®˜')
        
        if qi_sha_count >= 2 and yin_count == 0 and shi_shen_count == 0:
            return True, "X2-ç»“æ„é«˜å‹å‹ï¼ˆä¼—æ€æ”»èº«æ— åˆ¶ï¼‰"
        
        return False, ""
    
    def select_samples(self, pattern_id: str, target_count: int = 500, 
                      progress_callback: Optional[callable] = None,
                      output_dir: Optional[Path] = None) -> Dict[str, Any]:
        """
        æŒ‰ç…§FDS-V1.1 Step 2çš„æ•°æ®é€‰æ‹©æ ‡å‡†è¿›è¡Œæ ·æœ¬æµ·é€‰ï¼ˆå‡çº§ç‰ˆï¼šçº¯åº¦æ’åº+å¥‡ç‚¹æ•è·ï¼‰
        
        Args:
            pattern_id: æ ¼å±€ID
            target_count: ç›®æ ‡æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤500ï¼Œç”¨äºTier Aæ ‡å‡†é›†ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current, total, stats)
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¦‚æœæä¾›ï¼Œå°†ä¿å­˜ä¸¤ä¸ªJSONæ–‡ä»¶ï¼‰
            
        Returns:
            åŒ…å«standard_setå’Œsingularitiesçš„å­—å…¸
        """
        # è·å–æ ¼å±€ä¿¡æ¯
        pattern = self.get_pattern_by_id(pattern_id)
        if not pattern:
            logger.error(f"æ ¼å±€ {pattern_id} ä¸å­˜åœ¨")
            return []
        
        # è·å–æ•°æ®é€‰æ‹©æ ‡å‡†
        data_criteria = pattern.get('audit_trail', {}).get('data_selection_criteria', {})
        if not data_criteria:
            logger.error(f"æ ¼å±€ {pattern_id} ç¼ºå°‘æ•°æ®é€‰æ‹©æ ‡å‡†")
            return []
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        engine = SyntheticBaziEngine()
        bazi_gen = engine.generate_all_bazi()
        
        candidates = []
        total_scanned = 0
        stats = {
            'scanned': 0,
            'matched': 0,
            'rejected_month_lock': 0,
            'rejected_stem_reveal': 0,
            'rejected_purity': 0
        }
        
        logger.info(f"å¼€å§‹æ ·æœ¬æµ·é€‰ï¼šæ ¼å±€={pattern_id}ï¼Œç›®æ ‡={target_count}ä¾‹ï¼Œå…¨é‡æ‰«æ518,400ä¸ªæ ·æœ¬")
        
        # ä¸¥æ ¼å…¨é‡æ‰«æï¼šå¿…é¡»æ‰«ææ‰€æœ‰518,400ä¸ªæ ·æœ¬
        for chart in bazi_gen:
            total_scanned += 1
            stats['scanned'] = total_scanned
            
            # è¿›åº¦å›è°ƒï¼ˆæ¯10,000ä¸ªæ ·æœ¬æˆ–æ¯5%è¿›åº¦ï¼‰
            if progress_callback and (total_scanned % 10000 == 0 or total_scanned % 25920 == 0):
                progress_callback(total_scanned, 518400, stats)
            
            # æ³¨æ„ï¼šä¸æå‰é€€å‡ºï¼Œå¿…é¡»æ‰«æå…¨éƒ¨518,400ä¸ªæ ·æœ¬
            
            # æå–åŸºæœ¬ä¿¡æ¯
            year_pillar, month_pillar, day_pillar, hour_pillar = chart
            day_master = day_pillar[0]
            month_branch = month_pillar[1]
            
            # 1. æœˆä»¤é”ï¼šæœˆæ”¯æœ¬æ°”å¿…é¡»ä¸ºæ—¥ä¸»ä¹‹å¸æ—ºï¼ˆå³ç¾Šåˆƒï¼‰
            life_stage = TWELVE_LIFE_STAGES.get((day_master, month_branch))
            if life_stage != 'å¸æ—º':
                stats['rejected_month_lock'] += 1
                continue
            
            # 2. å¤©å¹²é€æ€ï¼šå¤©å¹²å¿…é¡»é€å‡ºä¸ƒæ€ï¼Œä¸”ä¸ƒæ€å¿…é¡»æœ‰æ ¹
            stems = [year_pillar[0], month_pillar[0], day_pillar[0], hour_pillar[0]]
            branches = [year_pillar[1], month_pillar[1], day_pillar[1], hour_pillar[1]]
            
            # æ£€æŸ¥å¤©å¹²æ˜¯å¦æœ‰ä¸ƒæ€
            qi_sha_stems = []
            for i, stem in enumerate(stems):
                if i == 2:  # è·³è¿‡æ—¥ä¸»
                    continue
                ten_god = BaziParticleNexus.get_shi_shen(stem, day_master)
                if ten_god == 'ä¸ƒæ€':
                    qi_sha_stems.append((i, stem))
            
            if not qi_sha_stems:
                stats['rejected_stem_reveal'] += 1
                continue
            
            # æ£€æŸ¥ä¸ƒæ€æ˜¯å¦æœ‰æ ¹
            has_root = False
            for _, qi_sha_stem in qi_sha_stems:
                # æ£€æŸ¥è‡ªå
                pillar_idx = qi_sha_stems[0][0]
                if pillar_idx < len(branches):
                    branch = branches[pillar_idx]
                    hidden_stems = BaziParticleNexus.get_branch_weights(branch)
                    for hidden_stem, weight in hidden_stems:
                        if hidden_stem == qi_sha_stem and weight >= 5:  # ä¸»æ°”æˆ–ä¸­æ°”
                            has_root = True
                            break
                
                # æ£€æŸ¥å…¶ä»–åœ°æ”¯
                if not has_root:
                    for branch in branches:
                        hidden_stems = BaziParticleNexus.get_branch_weights(branch)
                        for hidden_stem, weight in hidden_stems:
                            if hidden_stem == qi_sha_stem and weight >= 5:
                                has_root = True
                                break
                        if has_root:
                            break
                
                if has_root:
                    break
            
            if not has_root:
                stats['rejected_stem_reveal'] += 1
                continue
            
            # 3. æ¸…çº¯åº¦è¿‡æ»¤ï¼šå‰”é™¤é‡é£Ÿä¼¤åˆ¶æ€ã€é‡è´¢å…šæ€
            ten_gods = [BaziParticleNexus.get_shi_shen(s, day_master) for s in stems]
            
            # ç»Ÿè®¡é£Ÿä¼¤å’Œè´¢æ˜Ÿæ•°é‡
            shi_shen_count = ten_gods.count('é£Ÿç¥') + ten_gods.count('ä¼¤å®˜')
            cai_count = ten_gods.count('æ­£è´¢') + ten_gods.count('åè´¢')
            qi_sha_count = ten_gods.count('ä¸ƒæ€')
            
            # å‰”é™¤é‡é£Ÿä¼¤åˆ¶æ€ï¼ˆè¿™ä¼šå˜æˆA-02é£Ÿç¥åˆ¶æ€ï¼‰
            if shi_shen_count >= 2 and qi_sha_count >= 1:
                stats['rejected_purity'] += 1
                continue
            
            # å‰”é™¤é‡è´¢å…šæ€ï¼ˆè¿™ä¼šå¯¼è‡´åº”åŠ›è½´Sçˆ†è¡¨ï¼‰
            if cai_count >= 2 and qi_sha_count >= 1:
                stats['rejected_purity'] += 1
                continue
            
            # é€šè¿‡æ‰€æœ‰ç­›é€‰æ¡ä»¶
            candidates.append({
                'chart': chart,
                'day_master': day_master,
                'month_branch': month_branch,
                'qi_sha_stems': [s for _, s in qi_sha_stems],
                'ten_gods': ten_gods
            })
            stats['matched'] += 1
        
        # éªŒè¯æ˜¯å¦æ‰«æäº†å…¨éƒ¨æ ·æœ¬
        if total_scanned < 518400:
            logger.warning(f"âš ï¸ åªæ‰«æäº† {total_scanned} ä¸ªæ ·æœ¬ï¼Œæœªè¾¾åˆ°å…¨é‡518,400ä¸ª")
        else:
            logger.info(f"âœ… å·²æ‰«æå…¨éƒ¨518,400ä¸ªæ ·æœ¬")
        
        logger.info(f"Step Aå®Œæˆï¼šæ‰«æ={total_scanned}ï¼ŒåŒ¹é…={len(candidates)}ï¼Œç›®æ ‡={target_count}")
        logger.info(f"ç»Ÿè®¡ï¼šæœˆä»¤é”æ‹’ç»={stats['rejected_month_lock']}ï¼Œé€æ€æ‹’ç»={stats['rejected_stem_reveal']}ï¼Œçº¯åº¦æ‹’ç»={stats['rejected_purity']}")
        
        # ========== Step B: å¥‡ç‚¹æ•è· (Tier X) ==========
        logger.info("=" * 70)
        logger.info("Step B: å¥‡ç‚¹æ•è· (Tier X)")
        logger.info("=" * 70)
        
        singularities = []
        standard_candidates = []
        
        for sample in candidates:
            day_master = sample['day_master']
            is_singularity, singularity_type = self._detect_singularity(sample, day_master)
            
            if is_singularity:
                sample['singularity_type'] = singularity_type
                sample['purity_score'] = self._calculate_purity_score(sample, day_master)
                singularities.append(sample)
            else:
                standard_candidates.append(sample)
        
        logger.info(f"âœ… å‘ç°å¥‡ç‚¹æ ·æœ¬ {len(singularities)} ä¸ªï¼Œå·²éš”ç¦»")
        logger.info(f"âœ… æ ‡å‡†å€™é€‰æ ·æœ¬ {len(standard_candidates)} ä¸ª")
        
        # ========== Step C: æ ‡å‡†é›†ä¼˜é€‰ (Tier A) ==========
        logger.info("=" * 70)
        logger.info("Step C: æ ‡å‡†é›†ä¼˜é€‰ (Tier A) - çº¯åº¦åŠ æƒæ’åº")
        logger.info("=" * 70)
        
        # è®¡ç®—çº¯åº¦å¾—åˆ†å¹¶æ’åº
        for sample in standard_candidates:
            day_master = sample['day_master']
            sample['purity_score'] = self._calculate_purity_score(sample, day_master)
        
        # æŒ‰çº¯åº¦å¾—åˆ†é™åºæ’åº
        standard_candidates.sort(key=lambda x: x['purity_score'], reverse=True)
        
        # æˆªå–å‰target_countä¸ªä½œä¸ºTier Aæ ‡å‡†é›†
        if len(standard_candidates) > target_count:
            standard_set = standard_candidates[:target_count]
            logger.info(f"âœ… ä» {len(standard_candidates)} ä¸ªå€™é€‰æ ·æœ¬ä¸­ï¼ŒæŒ‰çº¯åº¦æ’åºé€‰å–å‰ {target_count} ä¸ªä½œä¸ºTier Aæ ‡å‡†é›†")
        else:
            standard_set = standard_candidates
            logger.info(f"âœ… å€™é€‰æ ·æœ¬ {len(standard_candidates)} ä¸ªï¼ˆå°‘äºç›®æ ‡ {target_count}ï¼‰ï¼Œå…¨éƒ¨ä½œä¸ºTier Aæ ‡å‡†é›†")
        
        # è¾“å‡ºç»Ÿè®¡
        if standard_set:
            avg_purity = sum(s['purity_score'] for s in standard_set) / len(standard_set)
            max_purity = max(s['purity_score'] for s in standard_set)
            min_purity = min(s['purity_score'] for s in standard_set)
            logger.info(f"Tier Açº¯åº¦ç»Ÿè®¡ï¼šå¹³å‡={avg_purity:.2f}ï¼Œæœ€é«˜={max_purity:.2f}ï¼Œæœ€ä½={min_purity:.2f}")
        
        # ========== ä¿å­˜ç»“æœ ==========
        result = {
            'pattern_id': pattern_id,
            'pattern_name': pattern.get('name_cn', pattern_id),
            'total_scanned': total_scanned,
            'tier_a': {
                'count': len(standard_set),
                'samples': standard_set
            },
            'tier_x': {
                'count': len(singularities),
                'samples': singularities
            },
            'stats': stats
        }
        
        # å¦‚æœæä¾›äº†è¾“å‡ºç›®å½•ï¼Œä¿å­˜æ–‡ä»¶
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜Tier Aæ ‡å‡†é›†
            standard_file = output_dir / f"QGA_{pattern_id}_TierA_Standard.json"
            with open(standard_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'pattern_id': pattern_id,
                    'pattern_name': pattern.get('name_cn', pattern_id),
                    'tier': 'A',
                    'description': 'æ ‡å‡†çº¯å‡€é›†ï¼ˆTier Aï¼‰- æœ€æ•™ç§‘ä¹¦çº§çš„æ ·æœ¬',
                    'count': len(standard_set),
                    'samples': standard_set
                }, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… Tier Aæ ‡å‡†é›†å·²ä¿å­˜: {standard_file}")
            
            # ä¿å­˜Tier Xå¥‡ç‚¹é›†
            if singularities:
                singularity_file = output_dir / f"QGA_{pattern_id}_TierX_Singularity.json"
                with open(singularity_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'pattern_id': pattern_id,
                        'pattern_name': pattern.get('name_cn', pattern_id),
                        'tier': 'X',
                        'description': 'å¥‡ç‚¹é›†ï¼ˆTier Xï¼‰- æç«¯æ ·æœ¬ï¼Œè•´å«æ–°çš„ç‰©ç†å®šå¾‹',
                        'count': len(singularities),
                        'samples': singularities
                    }, f, ensure_ascii=False, indent=2)
                logger.info(f"âœ… Tier Xå¥‡ç‚¹é›†å·²ä¿å­˜: {singularity_file}")
        
        logger.info("=" * 70)
        logger.info(f"âœ… æ ·æœ¬æµ·é€‰å®Œæˆï¼šTier A={len(standard_set)}ä¸ªï¼ŒTier X={len(singularities)}ä¸ª")
        logger.info("=" * 70)
        
        return result

