#!/usr/bin/env python3
"""
AI Trainer for Antigravity Graph Engine (V44.1)
================================================

ä½¿ç”¨ Optuna è´å¶æ–¯ä¼˜åŒ–æ¡†æ¶è¿›è¡Œåˆ†å±‚è¶…å‚æ•°è°ƒä¼˜ã€‚
é‡‡ç”¨"åˆ†å—åæ ‡ä¸‹é™ (Block Coordinate Descent)"ç­–ç•¥ï¼Œåˆ†ä¸‰ä¸ªé˜¶æ®µä¸²è¡Œä¼˜åŒ–ã€‚

ç‰ˆæœ¬: V53.0 Step 1 (Foundation Locking Tuning - Physics/Structure ONLY)
ä½œè€…: Antigravity Team
æ—¥æœŸ: 2025-01-16

V53.0 Step 1: åˆ†å±‚é”å®šç­–ç•¥
- Step 1: ä»…ä¼˜åŒ–åŸºç¡€ç‰©ç†å±‚ (Group 1: Foundation)
- Group 2 (Flow/Dynamics) å’Œ Group 3 (Interactions) å…¨éƒ¨é”æ­»
- ä» config/parameters.json è¯»å–å›ºå®šå€¼ï¼Œä¸å…è®¸ä¼˜åŒ–
"""

import json
import sys
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Set, Tuple
import copy
import optuna
from optuna.trial import TrialState

# V53.0: ç¦ç”¨ Optuna çš„è¯¦ç»†æ—¥å¿—è¾“å‡ºï¼Œå‡å°‘æ—¥å¿—å†—ä½™
optuna.logging.set_verbosity(optuna.logging.WARNING)  # åªæ˜¾ç¤ºè­¦å‘Šå’Œé”™è¯¯

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.engine_graph import GraphNetworkEngine
from core.config_schema import DEFAULT_FULL_ALGO_PARAMS


def load_golden_cases(data_path: Path = None) -> List[Dict[str, Any]]:
    """åŠ è½½æµ‹è¯•æ¡ˆä¾‹"""
    if data_path is None:
        data_path = project_root / "data" / "golden_cases.json"
    
    if data_path.exists():
        with open(data_path, 'r', encoding='utf-8') as f:
            cases = json.load(f)
            return cases
    return []


def predict_strength(strength_score: float, 
                     strong_threshold: float = 60.0,
                     weak_threshold: float = 40.0) -> str:
    """æ ¹æ®å æ¯”åˆ†æ•°é¢„æµ‹èº«å¼ºèº«å¼±"""
    if strength_score >= strong_threshold:
        return "Strong"
    elif strength_score >= weak_threshold:
        return "Balanced"
    else:
        return "Weak"


def calculate_accuracy(engine: GraphNetworkEngine, cases: List[Dict[str, Any]], 
                       config: Dict) -> Dict[str, float]:
    """
    è®¡ç®—å‡†ç¡®ç‡ã€‚
    
    Args:
        engine: GraphNetworkEngine å®ä¾‹
        cases: æµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨
        config: å½“å‰é…ç½®
    
    Returns:
        åŒ…å«å„æ ‡ç­¾å‡†ç¡®ç‡çš„å­—å…¸: {"Strong": 90.9, "Balanced": 54.5, "Weak": 72.7, "Total": 72.7}
    """
    correct_count = 0
    total_count = 0
    label_stats = {"Strong": {"correct": 0, "total": 0}, 
                   "Balanced": {"correct": 0, "total": 0},
                   "Weak": {"correct": 0, "total": 0}}
    
    for case in cases:
        true_label = case.get('true_label')
        if not true_label:
            continue
        
        try:
            result = engine.analyze(
                bazi=case['bazi'],
                day_master=case['day_master'],
                luck_pillar=None,
                year_pillar=None,
                geo_modifiers=None
            )
            
            strength_score = result.get('strength_score', 0.0)
            strength_label = result.get('strength_label', 'Unknown')
            
            # ä½¿ç”¨å¼•æ“è¿”å›çš„æ ‡ç­¾
            if strength_label in ["Strong", "Balanced", "Weak", "Special_Strong"]:
                pred_label = strength_label
            else:
                grading_config = config.get('grading', {})
                strong_threshold = grading_config.get('strong_threshold', 60.0)
                weak_threshold = grading_config.get('weak_threshold', 40.0)
                pred_label = predict_strength(strength_score, strong_threshold, weak_threshold)
            
            # ç‰¹æ®Šæ ¼å±€ä¾‹å¤–å¤„ç†
            is_correct = (pred_label == true_label)
            if not is_correct:
                if pred_label == "Special_Strong" and true_label in ["Balanced", "Strong"]:
                    is_correct = True
            
            total_count += 1
            if is_correct:
                correct_count += 1
            
            if true_label in label_stats:
                label_stats[true_label]["total"] += 1
                if is_correct:
                    label_stats[true_label]["correct"] += 1
        
        except Exception as e:
            # é”™è¯¯æ¡ˆä¾‹ä¸è®¡å…¥ç»Ÿè®¡
            pass
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracies = {"Strong": 0.0, "Balanced": 0.0, "Weak": 0.0, "Total": 0.0}
    
    if total_count > 0:
        accuracies["Total"] = (correct_count / total_count * 100)
    
    for label, stats in label_stats.items():
        if stats["total"] > 0:
            accuracies[label] = (stats["correct"] / stats["total"] * 100)
    
    return accuracies


def calculate_weighted_loss(engine: GraphNetworkEngine, cases: List[Dict[str, Any]], 
                           config: Dict, step: int = 0) -> float:
    """
    è®¡ç®—åŠ æƒæŸå¤±å‡½æ•°ã€‚
    
    Args:
        engine: GraphNetworkEngine å®ä¾‹
        cases: æµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨
        config: å½“å‰é…ç½®
        step: è®­ç»ƒé˜¶æ®µ (0=å…¨é˜¶æ®µ, 1=Foundation, 2=Dynamics)
    
    Returns:
        æ€»æŸå¤±å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    """
    total_loss = 0.0
    count = 0
    
    # æƒé‡æ˜ å°„ï¼šæ ¹æ®è®­ç»ƒé˜¶æ®µè°ƒæ•´
    # V53.1: Step 2 (Dynamics) æ—¶ï¼Œå¤§å¹…æé«˜ Balanced æƒé‡ï¼Œå› ä¸ºåŠ¨åŠ›å±‚å‚æ•°ä¸»è¦å½±å“ Balanced
    if step == 2:
        weight_map = {'Strong': 20.0, 'Weak': 20.0, 'Balanced': 20.0}  # é‡ç‚¹çªç ´ Balanced
    else:
        weight_map = {'Strong': 20.0, 'Weak': 20.0, 'Balanced': 20.0}
    
    # ç›®æ ‡åˆ†æ•°
    target_scores = {"Strong": 85.0, "Weak": 20.0, "Balanced": 50.0}
    
    for case in cases:
        true_label = case.get('true_label')
        if not true_label:
            continue
        
        try:
            result = engine.analyze(
                bazi=case['bazi'],
                day_master=case['day_master'],
                luck_pillar=None,
                year_pillar=None,
                geo_modifiers=None
            )
            
            strength_score = result.get('strength_score', 0.0)
            strength_label = result.get('strength_label', 'Unknown')
            
            # ä½¿ç”¨å¼•æ“è¿”å›çš„æ ‡ç­¾ï¼ˆå¯èƒ½åŒ…å«Special_Strongï¼‰
            if strength_label in ["Strong", "Balanced", "Weak", "Special_Strong"]:
                pred_label = strength_label
            else:
                # å¦‚æœå¼•æ“æ²¡æœ‰è¿”å›æœ‰æ•ˆæ ‡ç­¾ï¼Œä½¿ç”¨é˜ˆå€¼åˆ¤æ–­
                grading_config = config.get('grading', {})
                strong_threshold = grading_config.get('strong_threshold', 60.0)
                weak_threshold = grading_config.get('weak_threshold', 40.0)
                pred_label = predict_strength(strength_score, strong_threshold, weak_threshold)
            
            # ç‰¹æ®Šæ ¼å±€ä¾‹å¤–å¤„ç†
            is_correct = (pred_label == true_label)
            if not is_correct:
                if pred_label == "Special_Strong" and true_label in ["Balanced", "Strong"]:
                    is_correct = True
            
            # è®¡ç®—æŸå¤±
            weight = weight_map.get(true_label, 1.0)
            target_score = target_scores.get(true_label, 50.0)
            
            if is_correct:
                # é¢„æµ‹æ­£ç¡®ï¼Œä½†åˆ†æ•°å¯èƒ½ä¸å¤Ÿç†æƒ³ï¼ˆå°æƒ©ç½šï¼‰
                score_error = abs(strength_score - target_score)
                loss = score_error * 0.1 * weight
            else:
                # é¢„æµ‹é”™è¯¯ï¼šé«˜æƒ©ç½š
                score_error = abs(strength_score - target_score)
                loss = (100.0 + score_error) * weight
            
            total_loss += loss
            count += 1
        
        except Exception as e:
            # é”™è¯¯æ¡ˆä¾‹ï¼šæé«˜æƒ©ç½š
            total_loss += 1000.0 * weight_map.get(true_label, 1.0)
            count += 1
    
    # V47.0: ç§»é™¤ L2 æ­£åˆ™åŒ–ï¼Œç›¸ä¿¡ç‰©ç†è§„å¾‹
    # å¦‚æœå‚æ•°éœ€è¦å¾ˆå¤§ï¼ˆå¦‚æ¶¦å±€ç³»æ•°ï¼‰ï¼Œé‚£å°±è®©å®ƒå¤§ï¼Œä¸è¦ä¸ºäº†æ•°å­¦ä¸Šçš„"ç¾è§‚"å»æƒ©ç½šå®ƒ
    return total_loss / max(count, 1)  # çº¯ç‰©ç†æŸå¤±ï¼Œæ— æ­£åˆ™åŒ–


# ===========================================
# å‚æ•°åˆ†ç»„å®šä¹‰
# ===========================================

# Group 1: Foundation (åœ°åŸºå±‚)
GROUP_1_FOUNDATION = [
    'physics.pillarWeights.month',
    'physics.pillarWeights.year',
    'physics.pillarWeights.day',
    'physics.pillarWeights.hour',
    'structure.rootingWeight',
]

# Group 2: Dynamics (åŠ¨åŠ›å±‚)
# V53.0 Step 2: ä»…å¼€æ”¾åŠ¨åŠ›å±‚å‚æ•°ï¼Œé”æ­»åœ°åŸºä¸äº¤äº’
GROUP_2_DYNAMICS = [
    'flow.generationEfficiency',      # gen_eff
    'flow.controlImpact',             # ctl_imp
    'flow.dampingFactor',             # damping
    'flow.outputDrainPenalty',        # drain_rate
    'flow.globalEntropy',             # entropy
]

# Group 3: Interactions (äº¤äº’å±‚)
GROUP_3_INTERACTIONS = [
    'flow.earthMetalMoistureBoost',
    'interactions.stemFiveCombination.bonus',
    'interactions.branchEvents.clashDamping',
]

# V53.0: é»„é‡‘å‚æ•°å¸¸é‡ï¼ˆæ¶æ„å¸ˆæµ‹ç®—å€¼ï¼‰- åŸºäº V52.0 åŸºç¡€å‚æ•°é‡ç½®
# æ³¨æ„ï¼šè¿™äº›å€¼ä½œä¸º"ä¸­è½´"ï¼Œå…è®¸ Â±20%~30% çš„å¾®è°ƒ
GOLDEN_CONSTANTS = {
    'structure.rootingWeight': 4.25,
    'flow.controlImpact': -2.618,  # V52.0: æ³¨æ„æ˜¯è´Ÿå€¼ï¼
    'flow.outputDrainPenalty': 2.80,
    'flow.generationEfficiency': 0.25,
    'flow.dampingFactor': 0.33,
    'physics.pillarWeights.month': 1.88,
    'physics.pillarWeights.day': 1.62,
    'physics.pillarWeights.year': 0.82,
    'physics.pillarWeights.hour': 0.95,
}
# V53.0: Controlled Float - å…è®¸ Â±20%~30% çš„å¾®è°ƒï¼ˆä¸å†æ˜¯é”æ­»ï¼‰
FLOAT_TOLERANCE = 0.25  # 25% æµ®åŠ¨èŒƒå›´ï¼ˆÂ±20%~30%ï¼‰


def create_objective_for_group(
    group_params: List[str],
    locked_params: Dict[str, float],
    cases: List[Dict[str, Any]],
    base_config: Dict,
    step: int = 0
):
    """
    ä¸ºç‰¹å®šå‚æ•°ç»„åˆ›å»ºç›®æ ‡å‡½æ•°ã€‚
    
    Args:
        group_params: å½“å‰é˜¶æ®µè¦ä¼˜åŒ–çš„å‚æ•°åˆ—è¡¨
        locked_params: å·²é”å®šçš„å‚æ•°ï¼ˆæ¥è‡ªå‰åºé˜¶æ®µï¼‰
        cases: æµ‹è¯•æ¡ˆä¾‹
        base_config: åŸºç¡€é…ç½®
        step: è®­ç»ƒé˜¶æ®µ (0=å…¨é˜¶æ®µ, 1=Foundation, 2=Dynamics)
    
    Returns:
        objective å‡½æ•°
    """
    def objective(trial: optuna.Trial) -> float:
        # åŠ è½½åŸºç¡€é…ç½®
        config = copy.deepcopy(base_config)
        
        # åº”ç”¨å·²é”å®šçš„å‚æ•°
        for param_path, value in locked_params.items():
            set_nested_param(config, param_path, value)
        
        # ===========================================
        # å®šä¹‰å½“å‰ç»„çš„æœç´¢ç©ºé—´
        # ===========================================
        
        # Group 1: Foundation (V53.0: Controlled Float - ä»¥é»„é‡‘å€¼ä¸ºä¸­è½´ï¼Œå…è®¸Â±20%~30%å¾®è°ƒ)
        if 'physics.pillarWeights.month' in group_params:
            if 'physics.pillarWeights.month' in GOLDEN_CONSTANTS:
                golden_value = GOLDEN_CONSTANTS['physics.pillarWeights.month']
                min_val = golden_value * (1 - FLOAT_TOLERANCE)  # 1.88 * 0.75 = 1.41
                max_val = golden_value * (1 + FLOAT_TOLERANCE)  # 1.88 * 1.25 = 2.35
                config['physics']['pillarWeights']['month'] = trial.suggest_float(
                    'physics.pillarWeights.month', min_val, max_val, step=0.05  # ä¸­å¿ƒå€¼ 1.88ï¼ŒèŒƒå›´ [1.41, 2.35]
                )
            else:
                config['physics']['pillarWeights']['month'] = trial.suggest_float(
                    'physics.pillarWeights.month', 1.5, 2.2, step=0.05
                )
        if 'physics.pillarWeights.year' in group_params:
            if 'physics.pillarWeights.year' in GOLDEN_CONSTANTS:
                golden_value = GOLDEN_CONSTANTS['physics.pillarWeights.year']
                min_val = golden_value * (1 - FLOAT_TOLERANCE)  # 0.82 * 0.75 = 0.615
                max_val = golden_value * (1 + FLOAT_TOLERANCE)  # 0.82 * 1.25 = 1.025
                config['physics']['pillarWeights']['year'] = trial.suggest_float(
                    'physics.pillarWeights.year', min_val, max_val, step=0.05  # ä¸­å¿ƒå€¼ 0.82ï¼ŒèŒƒå›´ [0.615, 1.025]
                )
            else:
                config['physics']['pillarWeights']['year'] = trial.suggest_float(
                    'physics.pillarWeights.year', min_val, max_val, step=0.05  # ä¸­å¿ƒå€¼ 0.82ï¼ŒèŒƒå›´ [0.615, 1.025]
                )
        if 'physics.pillarWeights.day' in group_params:
            if 'physics.pillarWeights.day' in GOLDEN_CONSTANTS:
                golden_value = GOLDEN_CONSTANTS['physics.pillarWeights.day']
                min_val = golden_value * (1 - FLOAT_TOLERANCE)  # 1.62 * 0.75 = 1.215
                max_val = golden_value * (1 + FLOAT_TOLERANCE)  # 1.62 * 1.25 = 2.025
                config['physics']['pillarWeights']['day'] = trial.suggest_float(
                    'physics.pillarWeights.day', min_val, max_val, step=0.05  # ä¸­å¿ƒå€¼ 1.62ï¼ŒèŒƒå›´ [1.215, 2.025]
                )
            else:
                config['physics']['pillarWeights']['day'] = trial.suggest_float(
                    'physics.pillarWeights.day', 1.2, 1.8, step=0.05
                )
        if 'physics.pillarWeights.hour' in group_params:
            if 'physics.pillarWeights.hour' in GOLDEN_CONSTANTS:
                golden_value = GOLDEN_CONSTANTS['physics.pillarWeights.hour']
                min_val = golden_value * (1 - FLOAT_TOLERANCE)  # 0.95 * 0.75 = 0.7125
                max_val = golden_value * (1 + FLOAT_TOLERANCE)  # 0.95 * 1.25 = 1.1875
                config['physics']['pillarWeights']['hour'] = trial.suggest_float(
                    'physics.pillarWeights.hour', min_val, max_val, step=0.05  # ä¸­å¿ƒå€¼ 0.95ï¼ŒèŒƒå›´ [0.7125, 1.1875]
                )
            else:
                config['physics']['pillarWeights']['hour'] = trial.suggest_float(
                    'physics.pillarWeights.hour', min_val, max_val, step=0.05  # ä¸­å¿ƒå€¼ 0.95ï¼ŒèŒƒå›´ [0.7125, 1.1875]
                )
        if 'structure.rootingWeight' in group_params:
            # V53.0: Controlled Float - ä»¥é»„é‡‘å€¼ä¸ºä¸­è½´ï¼Œå…è®¸Â±20%~30%å¾®è°ƒ
            if 'structure.rootingWeight' in GOLDEN_CONSTANTS:
                golden_value = GOLDEN_CONSTANTS['structure.rootingWeight']
                min_val = golden_value * (1 - FLOAT_TOLERANCE)  # 4.25 * 0.75 = 3.1875
                max_val = golden_value * (1 + FLOAT_TOLERANCE)  # 4.25 * 1.25 = 5.3125
                config['structure']['rootingWeight'] = trial.suggest_float(
                    'structure.rootingWeight', min_val, max_val, step=0.1  # ä¸­å¿ƒå€¼ 4.25ï¼ŒèŒƒå›´ [3.1875, 5.3125]
                )
            else:
                config['structure']['rootingWeight'] = trial.suggest_float(
                    'structure.rootingWeight', 3.0, 5.5, step=0.1
                )
        
        # ===========================================
        # V53.0 Step 1: Foundation Locking Tuning
        # å¯¹äº Group 2 å’Œ Group 3 çš„å‚æ•°ï¼Œå¼ºåˆ¶ä» base_config è¯»å–ï¼ˆé”æ­»ï¼‰
        # ===========================================
        # å¦‚æœå½“å‰æ˜¯ Step 1ï¼ˆåªä¼˜åŒ– Foundationï¼‰ï¼Œåˆ™å¼ºåˆ¶é”æ­» Group 2 å’Œ Group 3
        is_step1_foundation_only = (group_params == GROUP_1_FOUNDATION)
        
        # Group 2: Dynamics (V53.0 Step 2: ä»…åœ¨ä¼˜åŒ– Group 2 æ—¶æ‰å…è®¸è°ƒæ•´)
        # å¦‚æœå½“å‰æ˜¯ Step 1ï¼ˆåªä¼˜åŒ– Foundationï¼‰ï¼Œåˆ™è·³è¿‡æ‰€æœ‰ Group 2 å’Œ Group 3 çš„å‚æ•°ä¼˜åŒ–
        if not is_step1_foundation_only and 'flow.generationEfficiency' in group_params:
            gen_eff = trial.suggest_float('gen_eff', 0.1, 0.4, step=0.01)  # [0.1, 0.4]
            set_nested_param(config, 'flow.generationEfficiency', gen_eff)
        if not is_step1_foundation_only and 'flow.controlImpact' in group_params:
            ctl_imp = trial.suggest_float('ctl_imp', -4.0, -1.5, step=0.05)  # [-4.0, -1.5]
            set_nested_param(config, 'flow.controlImpact', ctl_imp)
        if not is_step1_foundation_only and 'flow.dampingFactor' in group_params:
            damping = trial.suggest_float('damping', 0.2, 0.7, step=0.01)  # [0.2, 0.7]
            set_nested_param(config, 'flow.dampingFactor', damping)
        if not is_step1_foundation_only and 'flow.outputDrainPenalty' in group_params:
            drain_rate = trial.suggest_float('drain_rate', 1.5, 5.0, step=0.1)  # [1.5, 5.0]
            # drain_rate â†’ outputDrainPenalty
            set_nested_param(config, 'flow.outputDrainPenalty', drain_rate)
        if not is_step1_foundation_only and 'flow.globalEntropy' in group_params:
            entropy = trial.suggest_float('entropy', 0.05, 0.25, step=0.01)  # [0.05, 0.25]
            set_nested_param(config, 'flow.globalEntropy', entropy)
        
        # Group 3: Interactions (V53.0 Step 1: ä»…åœ¨ä¼˜åŒ– Group 3 æ—¶æ‰å…è®¸è°ƒæ•´)
        if not is_step1_foundation_only and 'flow.earthMetalMoistureBoost' in group_params:
            config['flow']['earthMetalMoistureBoost'] = trial.suggest_float(
                'flow.earthMetalMoistureBoost', 5.0, 15.0, step=0.5  # V47.0: ä¿æŒé«˜æ¶¦å±€ç³»æ•°
            )
        if not is_step1_foundation_only and 'interactions.stemFiveCombination.bonus' in group_params:
            config['interactions']['stemFiveCombination']['bonus'] = trial.suggest_float(
                'interactions.stemFiveCombination.bonus', 1.2, 2.5, step=0.1
            )
        if not is_step1_foundation_only and 'interactions.branchEvents.clashDamping' in group_params:
            config['interactions']['branchEvents']['clashDamping'] = trial.suggest_float(
                'interactions.branchEvents.clashDamping', 0.2, 0.8, step=0.1  # V45.0: è°ƒæ•´èŒƒå›´
            )
        
        # ===========================================
        # è¿è¡Œæ¨¡æ‹Ÿå¹¶è®¡ç®—æŸå¤±
        # ===========================================
        
        if not cases:
            return float('inf')
        
        try:
            engine = GraphNetworkEngine(config=config)
        except Exception as e:
            return float('inf')
        
        loss = calculate_weighted_loss(engine, cases, config, step=step)
        return loss
    
    return objective


def set_nested_param(config: Dict, param_path: str, value: float):
    """
    è®¾ç½®åµŒå¥—å‚æ•°å€¼ã€‚
    
    Args:
        config: é…ç½®å­—å…¸
        param_path: å‚æ•°è·¯å¾„ï¼Œå¦‚ 'flow.generationEfficiency'
        value: å‚æ•°å€¼
    """
    keys = param_path.split('.')
    current = config
    for key in keys[:-1]:
        if key not in current:
            current[key] = {}
        current = current[key]
    current[keys[-1]] = value


def get_nested_param(config: Dict, param_path: str) -> Optional[float]:
    """
    è·å–åµŒå¥—å‚æ•°å€¼ã€‚
    
    Args:
        config: é…ç½®å­—å…¸
        param_path: å‚æ•°è·¯å¾„
    
    Returns:
        å‚æ•°å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
    """
    keys = param_path.split('.')
    current = config
    try:
        for key in keys[:-1]:
            current = current[key]
        return current[keys[-1]]
    except (KeyError, TypeError):
        return None


# ===========================================
# Unified Optimization (single study, CMA-ES)
# ===========================================

def _relative_bounds(current: float, tol: float = 0.3, min_clip: float = None, max_clip: float = None) -> Tuple[float, float]:
    """ç”Ÿæˆç›¸å¯¹èŒƒå›´ï¼Œé»˜è®¤ Â±30%."""
    if current is None:
        current = 1.0
    low = current * (1 - tol)
    high = current * (1 + tol)
    if low > high:
        low, high = high, low
    if min_clip is not None:
        low = max(low, min_clip)
    if max_clip is not None:
        high = min(high, max_clip)
    # é¿å…ä½é«˜ç›¸åŒ
    if abs(high - low) < 1e-6:
        high = low + 1e-3
    return low, high


def run_unified_optimization(
    cases: List[Dict[str, Any]],
    base_config: Dict,
    n_trials: int = 400,
    max_loops: int = 0,
    patience: int = 2,
    min_improve: float = 1e-3
) -> Dict[str, float]:
    """
    å•ä¸€ study è”åˆè°ƒå‚ï¼ˆFoundation + Dynamics + Interactionsï¼‰ï¼Œä½¿ç”¨ CMA-ESã€‚
    æœç´¢èŒƒå›´å›´ç»•å½“å‰å‚æ•° Â±30%ï¼Œä¿è¯ä¸ä¼šå›é€€åˆ°æ— æ„ä¹‰çš„å¤§èŒƒå›´ã€‚
    """
    print("=" * 80)
    print("ğŸ”„ Unified Optimization (CMA-ES, balanced-focused)")
    print("   - å•ä¸€ study è”åˆæœç´¢ Foundation + Dynamics + Interactions")
    print("   - èŒƒå›´: ä»¥å½“å‰å‚æ•°ä¸ºä¸­å¿ƒ Â±30% ç›¸å¯¹æ‰°åŠ¨")
    print("   - ç›®æ ‡: åŠ æƒæŸå¤±ï¼ˆStep=2ï¼ŒBalanced æƒé‡æ›´é«˜ï¼‰")
    print("=" * 80)
    print()

    # å½“å‰é…ç½®ç”¨äºè®¾å®šç›¸å¯¹èŒƒå›´
    current_cfg = copy.deepcopy(base_config)

    param_specs = [
        ("structure.rootingWeight", 0.3, 0.1, 50.0),
        ("physics.pillarWeights.month", 0.3, 0.1, 5.0),
        ("physics.pillarWeights.year", 0.3, 0.1, 5.0),
        ("physics.pillarWeights.day", 0.3, 0.1, 5.0),
        ("physics.pillarWeights.hour", 0.3, 0.05, 5.0),
        ("flow.controlImpact", 0.3, None, None),
        ("flow.generationEfficiency", 0.3, 0.01, 2.0),
        ("flow.dampingFactor", 0.3, 0.01, 2.0),
        ("flow.outputDrainPenalty", 0.3, 0.1, 8.0),
        ("flow.globalEntropy", 0.3, 0.0, 0.6),
        ("flow.earthMetalMoistureBoost", 0.3, 0.1, 30.0),
        ("interactions.branchEvents.clashDamping", 0.3, 0.0, 1.5),
        ("interactions.stemFiveCombination.bonus", 0.3, 0.5, 3.5),
    ]
    
    # ä¿å­˜åˆå§‹å‚æ•°å€¼ï¼ˆç”¨äºå¯¹æ¯”æ˜¾ç¤ºï¼‰
    initial_params = {}
    for path, _, _, _ in param_specs:
        val = get_nested_param(current_cfg, path)
        if val is not None:
            initial_params[path] = val

    # ä¼˜å…ˆä½¿ç”¨ CMA-ESï¼Œå¦‚ç¼ºå¤± cmaes åº“åˆ™å›é€€åˆ° TPE
    try:
        import importlib
        importlib.import_module("cmaes")
        sampler = optuna.samplers.CmaEsSampler(seed=42)
    except Exception:
        print("âš ï¸ æœªå®‰è£… cmaesï¼Œå›é€€åˆ° TPE sampler")
        sampler = optuna.samplers.TPESampler(seed=42)
    study = optuna.create_study(direction="minimize", sampler=sampler)

    def objective(trial: optuna.Trial) -> float:
        cfg = copy.deepcopy(base_config)
        for path, tol, min_clip, max_clip in param_specs:
            current_val = get_nested_param(current_cfg, path)
            low, high = _relative_bounds(current_val, tol=tol, min_clip=min_clip, max_clip=max_clip)
            val = trial.suggest_float(path, low, high)
            set_nested_param(cfg, path, val)

        try:
            engine = GraphNetworkEngine(config=cfg)
        except Exception:
            return float("inf")
        loss = calculate_weighted_loss(engine, cases, cfg, step=2)
        return loss

    best_params = {}
    best_loss = float("inf")
    no_improve = 0
    loop = 0
    
    # æ‰“å°åˆå§‹å‚æ•°å€¼
    print("ğŸ“‹ åˆå§‹å‚æ•°å€¼ï¼ˆè°ƒä¼˜åŸºå‡†ï¼‰:")
    for path, _, _, _ in param_specs:
        val = initial_params.get(path)
        if val is not None:
            print(f"   {path:40s}: {val:8.4f}")
    print()
    
    # è®¡ç®—åˆå§‹å‡†ç¡®ç‡
    try:
        engine_init = GraphNetworkEngine(config=current_cfg)
        acc_init = calculate_accuracy(engine_init, cases, current_cfg)
        print(f"ğŸ“Š åˆå§‹å‡†ç¡®ç‡: æ€»={acc_init['Total']:.1f}% | Strong={acc_init['Strong']:.1f}% | Balanced={acc_init['Balanced']:.1f}% | Weak={acc_init['Weak']:.1f}%")
        print()
    except Exception:
        pass
    
    while True:
        loop += 1
        print(f"\nğŸ” Unified Loop {loop} / {('âˆ' if max_loops == 0 else max_loops)}")
        print(f"ğŸ“Š è¯•éªŒæ¬¡æ•°: {n_trials} (CMA-ES/TPE)")
        if loop == 1:
            print(f"ğŸ”§ æ­£åœ¨è°ƒä¼˜ {len(param_specs)} ä¸ªå‚æ•°: {', '.join([p[0] for p in param_specs[:5]])}...")

        study.optimize(objective, n_trials=n_trials, show_progress_bar=False, n_jobs=1)
        trial = study.best_trial
        if trial.value < best_loss - min_improve:
            best_loss = trial.value
            best_params = trial.params
            no_improve = 0
            print(f"ğŸ¯ æ–°æœ€ä½³ loss: {best_loss:.4f}")
            
            # æ‰“å°å‚æ•°å˜åŒ–è¯¦æƒ…
            print("ğŸ“ å‚æ•°è°ƒä¼˜è¯¦æƒ…:")
            changed_params = []
            for path, _, _, _ in param_specs:
                if path in best_params:
                    new_val = best_params[path]
                    old_val = initial_params.get(path)
                    if old_val is not None:
                        change = new_val - old_val
                        change_pct = (change / abs(old_val) * 100) if old_val != 0 else 0.0
                        if abs(change) > 1e-6:  # åªæ˜¾ç¤ºæœ‰æ˜¾è‘—å˜åŒ–çš„å‚æ•°
                            changed_params.append((path, old_val, new_val, change, change_pct))
            
            if changed_params:
                # æŒ‰å˜åŒ–å¹…åº¦æ’åºï¼ˆç»å¯¹å€¼ï¼‰
                changed_params.sort(key=lambda x: abs(x[3]), reverse=True)
                for path, old_val, new_val, change, change_pct in changed_params[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªå˜åŒ–æœ€å¤§çš„
                    sign = "â†‘" if change > 0 else "â†“"
                    print(f"   {path:40s}: {old_val:8.4f} â†’ {new_val:8.4f} ({change:+.4f}, {change_pct:+.1f}%) {sign}")
                if len(changed_params) > 10:
                    print(f"   ... è¿˜æœ‰ {len(changed_params) - 10} ä¸ªå‚æ•°æœ‰å˜åŒ–")
            else:
                print("   (æ‰€æœ‰å‚æ•°å˜åŒ–å¾ˆå°ï¼Œ< 0.000001)")
            
            # è®¡ç®—å¹¶æ‰“å°å‡†ç¡®ç‡
            cfg = copy.deepcopy(base_config)
            for path, val in best_params.items():
                set_nested_param(cfg, path, val)
            try:
                engine = GraphNetworkEngine(config=cfg)
                acc = calculate_accuracy(engine, cases, cfg)
                print(f"ğŸ“ˆ å‡†ç¡®ç‡: æ€»={acc['Total']:.1f}% | Strong={acc['Strong']:.1f}% | Balanced={acc['Balanced']:.1f}% | Weak={acc['Weak']:.1f}%")
            except Exception as e:
                print(f"âš ï¸ è®¡ç®—å‡†ç¡®ç‡å¤±è´¥: {e}")
            
            # æ›´æ–°åˆå§‹å‚æ•°ä¸ºå½“å‰æœ€ä½³ï¼ˆç”¨äºä¸‹ä¸€è½®å¯¹æ¯”ï¼‰
            initial_params.update(best_params)
            
            save_best_params(best_params)
        else:
            no_improve += 1
            print(f"âš ï¸ æ— æ˜¾è‘—æ”¹è¿› (best={best_loss:.4f}, this={trial.value:.4f}, è¿ç»­æ— æ”¹è¿› {no_improve}/{patience})")

        if max_loops > 0 and loop >= max_loops:
            print("ğŸ›‘ è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œåœæ­¢ã€‚")
            break
        if no_improve >= patience:
            print("ğŸ›‘ è¾¾åˆ°æ— æ”¹è¿›è€å¿ƒé˜ˆå€¼ï¼Œåœæ­¢ã€‚")
            break

    # ä¿å­˜æœ€ç»ˆæœ€ä½³
    if best_params:
        save_best_params(best_params)
        print(f"ğŸ¯ æœ€ä½³ loss: {best_loss:.4f}")
        
        # æ‰“å°æœ€ç»ˆå‡†ç¡®ç‡
        cfg_final = copy.deepcopy(base_config)
        for path, val in best_params.items():
            set_nested_param(cfg_final, path, val)
        try:
            engine_final = GraphNetworkEngine(config=cfg_final)
            acc_final = calculate_accuracy(engine_final, cases, cfg_final)
            print(f"ğŸ“ˆ æœ€ç»ˆå‡†ç¡®ç‡: æ€»={acc_final['Total']:.1f}% | Strong={acc_final['Strong']:.1f}% | Balanced={acc_final['Balanced']:.1f}% | Weak={acc_final['Weak']:.1f}%")
        except Exception as e:
            print(f"âš ï¸ è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡å¤±è´¥: {e}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°ï¼Œè¿”å›ç©ºç»“æœ")
    return best_params


def save_best_params(best_params: Dict[str, float], output_path: Path = None):
    """
    ä¿å­˜æœ€ä½³å‚æ•°åˆ°é…ç½®æ–‡ä»¶ã€‚
    
    Args:
        best_params: Optuna è¿”å›çš„æœ€ä½³å‚æ•°å­—å…¸
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    if output_path is None:
        output_path = project_root / "config" / "parameters.json"
    
    # åŠ è½½ç°æœ‰é…ç½®
    config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
    
    # å¦‚æœå­˜åœ¨ç°æœ‰é…ç½®æ–‡ä»¶ï¼Œå…ˆåŠ è½½å®ƒ
    if output_path.exists():
        with open(output_path, 'r', encoding='utf-8') as f:
            existing_config = json.load(f)
            def deep_merge(base, update):
                for key, value in update.items():
                    if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                        deep_merge(base[key], value)
                    else:
                        base[key] = value
            deep_merge(config, existing_config)
    
    # å°†ç®€å†™ trial å‚æ•°æ˜ å°„åˆ°çœŸå®å¼•æ“å­—æ®µï¼ˆé˜²æ­¢ä¿å­˜æ—¶é—æ¼ï¼‰
    shorthand_mapping = {
        'ctl_imp': 'flow.controlImpact',
        'drain_rate': 'flow.outputDrainPenalty',
        'gen_eff': 'flow.generationEfficiency',
        'damping': 'flow.dampingFactor',
        'entropy': 'flow.globalEntropy',
    }
    expanded_params = {}
    for k, v in best_params.items():
        if k in shorthand_mapping:
            expanded_params[shorthand_mapping[k]] = v
        expanded_params[k] = v

    # åº”ç”¨æœ€ä½³å‚æ•°
    for param_path, value in expanded_params.items():
        set_nested_param(config, param_path, value)
    
    # ä¿å­˜é…ç½®
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æœ€ä½³å‚æ•°å·²ä¿å­˜åˆ°: {output_path}")


def print_stage_report(stage_name: str, initial_loss: float, final_loss: float,
                      best_params: Dict[str, float], previous_params: Dict[str, float] = None):
    """
    æ‰“å°é˜¶æ®µæŠ¥å‘Šã€‚
    
    Args:
        stage_name: é˜¶æ®µåç§°
        initial_loss: åˆå§‹æŸå¤±
        final_loss: æœ€ç»ˆæŸå¤±
        best_params: æœ€ä½³å‚æ•°
        previous_params: å‰åºé˜¶æ®µçš„å‚æ•°ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    """
    print("\n" + "=" * 80)
    print(f"ğŸ“Š {stage_name} é˜¶æ®µæŠ¥å‘Š")
    print("=" * 80)
    print()
    
    improvement = initial_loss - final_loss
    improvement_pct = (improvement / initial_loss * 100) if initial_loss > 0 else 0.0
    
    print(f"æŸå¤±å˜åŒ–: {initial_loss:.2f} â†’ {final_loss:.2f}")
    print(f"æ”¹è¿›å¹…åº¦: {improvement:+.2f} ({improvement_pct:+.1f}%)")
    print()
    
    if previous_params:
        print("å…³é”®å‚æ•°å˜åŒ–:")
        print("-" * 80)
        for param_name in best_params.keys():
            old_value = previous_params.get(param_name, None)
            new_value = best_params[param_name]
            if old_value is not None and abs(old_value - new_value) > 0.01:
                change = new_value - old_value
                print(f"  {param_name:40s}: {old_value:.3f} â†’ {new_value:.3f} ({change:+.3f})")
        print()
    else:
        print("æœ€ä½³å‚æ•°:")
        print("-" * 80)
        for param_name, param_value in best_params.items():
            print(f"  {param_name:40s} = {param_value:.6f}")
        print()


def optimize_stage_1(locked_params: Dict[str, float], cases: List[Dict[str, Any]], 
                     base_config: Dict, n_trials: int = 200, seed_trial: Dict[str, float] = None, step: int = 1) -> Dict[str, float]:
    """ä¼˜åŒ– Stage 1: Foundation"""
    print("ğŸš€ Stage 1: ä¼˜åŒ–åœ°åŸºå±‚ (Foundation)")
    print("   å‚æ•°: æœˆä»¤æƒé‡ã€å¹´æŸ±æƒé‡ã€é€šæ ¹ç³»æ•°ç­‰")
    print()
    
    # è®¡ç®—åˆå§‹æŸå¤±
    config_init = copy.deepcopy(base_config)
    for param_path, value in locked_params.items():
        set_nested_param(config_init, param_path, value)
    engine_init = GraphNetworkEngine(config=config_init)
    initial_loss = calculate_weighted_loss(engine_init, cases, config_init, step=step)
    print(f"   åˆå§‹æŸå¤±: {initial_loss:.2f}")
    print()
    
    # åˆ›å»º Study
    study = optuna.create_study(
        direction="minimize",
        study_name="stage1_foundation",
        sampler=optuna.samplers.TPESampler(seed=42)
    )
    
    # V47.0: ç§å­åˆå§‹åŒ– - æ³¨å…¥ V45.0 æœ€ä½³å‚æ•°
    if seed_trial:
        study.enqueue_trial(seed_trial)
        print("   ğŸŒ± å·²æ³¨å…¥ç§å­å‚æ•°ï¼ˆV45.0 æœ€ä½³é…ç½®ï¼‰")
    
    # åˆ›å»ºç›®æ ‡å‡½æ•°
    objective = create_objective_for_group(
        GROUP_1_FOUNDATION,
        {k: v for k, v in locked_params.items() if k not in GROUP_1_FOUNDATION},
        cases,
        base_config,
        step=step
    )
    
    # è¿è¡Œä¼˜åŒ–
    print("   ğŸ”¬ å¼€å§‹ä¼˜åŒ–...")
    # V53.0: ç¦ç”¨è¿›åº¦æ¡è¾“å‡ºï¼Œå‡å°‘æ—¥å¿—å†—ä½™
    study.optimize(objective, n_trials=n_trials, show_progress_bar=False, n_jobs=1)
    
    # å°†æœ€ä½³ trial å‚æ•°åº”ç”¨åˆ°ä¸€ä»½å®Œæ•´é…ç½®æ˜ å°„ï¼Œè¿”å›å…¨è·¯å¾„å‚æ•°ï¼ˆä¸å†ä¿ç•™ç®€å†™ï¼‰
    best_trial_params = study.best_params
    mapped_params = {}
    def map_param(name: str, mapped_name: str):
        if name in best_trial_params:
            mapped_params[mapped_name] = best_trial_params[name]
    map_param('ctl_imp', 'flow.controlImpact')
    map_param('drain_rate', 'flow.outputDrainPenalty')
    map_param('gen_eff', 'flow.generationEfficiency')
    map_param('damping', 'flow.dampingFactor')
    map_param('entropy', 'flow.globalEntropy')
    
    return mapped_params


def optimize_stage_2(locked_params: Dict[str, float], cases: List[Dict[str, Any]], 
                     base_config: Dict, n_trials: int = 200, seed_trial: Dict[str, float] = None, step: int = 2) -> Dict[str, float]:
    """ä¼˜åŒ– Stage 2: Dynamics"""
    print("ğŸš€ Stage 2: ä¼˜åŒ–åŠ¨åŠ›å±‚ (Dynamics)")
    print("   å‚æ•°: ç”Ÿå…‹ä¼ å¯¼ç‡ã€é˜»å°¼ç³»æ•°ã€ç†µå¢ç­‰")
    print()
    
    # è®¡ç®—åˆå§‹æŸå¤±
    config_init = copy.deepcopy(base_config)
    for param_path, value in locked_params.items():
        set_nested_param(config_init, param_path, value)
    engine_init = GraphNetworkEngine(config=config_init)
    initial_loss = calculate_weighted_loss(engine_init, cases, config_init, step=step)
    print(f"   åˆå§‹æŸå¤±: {initial_loss:.2f}")
    print()
    
    # åˆ›å»º Study
    study = optuna.create_study(
        direction="minimize",
        study_name="stage2_dynamics",
        sampler=optuna.samplers.TPESampler(seed=42)
    )
    
    # V47.0: ç§å­åˆå§‹åŒ–
    if seed_trial:
        study.enqueue_trial(seed_trial)
        print("   ğŸŒ± å·²æ³¨å…¥ç§å­å‚æ•°")
    
    # åˆ›å»ºç›®æ ‡å‡½æ•°
    objective = create_objective_for_group(
        GROUP_2_DYNAMICS,
        locked_params,
        cases,
        base_config,
        step=step
    )
    
    # è¿è¡Œä¼˜åŒ–
    print("   ğŸ”¬ å¼€å§‹ä¼˜åŒ–...")
    # V53.0: ç¦ç”¨è¿›åº¦æ¡è¾“å‡ºï¼Œå‡å°‘æ—¥å¿—å†—ä½™
    study.optimize(objective, n_trials=n_trials, show_progress_bar=False, n_jobs=1)
    
    # è¿”å›æœ€ä½³å‚æ•°
    return study.best_params


def optimize_stage_3(locked_params: Dict[str, float], cases: List[Dict[str, Any]], 
                     base_config: Dict, n_trials: int = 200, seed_trial: Dict[str, float] = None, step: int = 0) -> Dict[str, float]:
    """ä¼˜åŒ– Stage 3: Interactions"""
    print("ğŸš€ Stage 3: ä¼˜åŒ–äº¤äº’å±‚ (Interactions)")
    print("   å‚æ•°: æ¶¦å±€ç³»æ•°ã€åˆåŒ–åŠ æˆã€å†²å…‹é˜»å°¼ç­‰")
    print()
    
    # è®¡ç®—åˆå§‹æŸå¤±
    config_init = copy.deepcopy(base_config)
    for param_path, value in locked_params.items():
        set_nested_param(config_init, param_path, value)
    engine_init = GraphNetworkEngine(config=config_init)
    initial_loss = calculate_weighted_loss(engine_init, cases, config_init, step=step)
    print(f"   åˆå§‹æŸå¤±: {initial_loss:.2f}")
    print()
    
    # åˆ›å»º Study
    study = optuna.create_study(
        direction="minimize",
        study_name="stage3_interactions",
        sampler=optuna.samplers.TPESampler(seed=42)
    )
    
    # V47.0: ç§å­åˆå§‹åŒ–
    if seed_trial:
        study.enqueue_trial(seed_trial)
        print("   ğŸŒ± å·²æ³¨å…¥ç§å­å‚æ•°")
    
    # åˆ›å»ºç›®æ ‡å‡½æ•°
    objective = create_objective_for_group(
        GROUP_3_INTERACTIONS,
        locked_params,
        cases,
        base_config,
        step=step
    )
    
    # è¿è¡Œä¼˜åŒ–
    print("   ğŸ”¬ å¼€å§‹ä¼˜åŒ–...")
    # V53.0: ç¦ç”¨è¿›åº¦æ¡è¾“å‡ºï¼Œå‡å°‘æ—¥å¿—å†—ä½™
    study.optimize(objective, n_trials=n_trials, show_progress_bar=False, n_jobs=1)
    
    # è¿”å›æœ€ä½³å‚æ•°
    return study.best_params


def run_cyclic_optimization(cases: List[Dict[str, Any]], base_config: Dict, 
                           cycles: int = 3, step: int = 1) -> Dict[str, float]:
    """
    V53.0 Step 1: åˆ†å±‚é”å®šä¼˜åŒ–
    
    Args:
        cases: æµ‹è¯•æ¡ˆä¾‹
        base_config: åŸºç¡€é…ç½®
        cycles: å¾ªç¯æ¬¡æ•°
        step: ä¼˜åŒ–é˜¶æ®µ (1=Foundation only, 2=Flow only, 3=All)
    
    Returns:
        æœ€ç»ˆæœ€ä½³å‚æ•°
    """
    print("=" * 80)
    if step == 1:
        print("ğŸ”„ Antigravity Cyclic AI Trainer (V53.0 Step 1)")
        print("   Foundation Locking Tuning - Physics/Structure ONLY")
        print("   Group 2 (Flow) and Group 3 (Interactions) are FROZEN")
    else:
        print("ğŸ”„ Antigravity Cyclic AI Trainer (V53.0)")
        print("   Controlled Float Strategy - Unlocking Base Parameters")
    print("=" * 80)
    print()
    
    # åˆå§‹åŒ–é”å®šå‚æ•°ï¼ˆä»åŸºç¡€é…ç½®ä¸­æå–ï¼‰
    locked_params = {}
    all_params = GROUP_1_FOUNDATION + GROUP_2_DYNAMICS + GROUP_3_INTERACTIONS
    for param_path in all_params:
        value = get_nested_param(base_config, param_path)
        if value is not None:
            locked_params[param_path] = value
    
    # è®¡ç®—åˆå§‹æŸå¤±
    config_init = copy.deepcopy(base_config)
    for param_path, value in locked_params.items():
        set_nested_param(config_init, param_path, value)
    engine_init = GraphNetworkEngine(config=config_init)
    initial_loss = calculate_weighted_loss(engine_init, cases, config_init, step=step)
    print(f"ğŸ“Š åˆå§‹æŸå¤±: {initial_loss:.2f}")
    print()
    
    best_loss = initial_loss
    best_params = locked_params.copy()
    
    # V53.0: æ ¹æ® step è°ƒæ•´æ€»è¯•éªŒæ¬¡æ•°
    if step == 1:
        total_trials = cycles * 200  # åªè·‘ Foundation
        print(f"ğŸ“Š è®­ç»ƒè§„æ¨¡: {cycles} ä¸ªå¾ªç¯ Ã— 200 = {total_trials} æ¬¡è¯•éªŒ (Foundation Only)")
    elif step == 2:
        total_trials = cycles * 300  # åªè·‘ Dynamicsï¼Œæ›´å¤šå°è¯•
        print(f"ğŸ“Š è®­ç»ƒè§„æ¨¡: {cycles} ä¸ªå¾ªç¯ Ã— 300 = {total_trials} æ¬¡è¯•éªŒ (Dynamics Only)")
    else:
        total_trials = cycles * (200 + 200 + 200)  # Foundation + Dynamics + Interactions
        print(f"ğŸ“Š è®­ç»ƒè§„æ¨¡: {cycles} ä¸ªå¾ªç¯ Ã— (200 + 200 + 200) = {total_trials} æ¬¡è¯•éªŒ")
    print(f"   é¢„è®¡è€—æ—¶: çº¦ {total_trials * 0.015:.0f} ç§’")
    print()
    
    # V53.0: ä¸å†ä½¿ç”¨ç¡¬ç¼–ç çš„ç§å­å‚æ•°ï¼Œç›´æ¥ä» config/parameters.json è¯»å–
    # è¿™æ ·å¯ä»¥ç¡®ä¿ç§å­å‚æ•°å§‹ç»ˆåœ¨æœç´¢èŒƒå›´å†…
    # seed_params_v49 å·²åºŸå¼ƒï¼Œæ”¹ä¸ºä½¿ç”¨ base_config ä¸­çš„å€¼
    
    # V53.0 Step 1/2: æ ¹æ® step å‚æ•°å†³å®šä¼˜åŒ–å“ªäº›é˜¶æ®µ
    if step == 1:
        # Step 1: åªä¼˜åŒ– Foundationï¼Œé”æ­»å…¶ä»–æ‰€æœ‰å‚æ•°
        print("ğŸ”’ V53.0 Step 1: Foundation Locking Tuning")
        print("   - ä»…ä¼˜åŒ– Group 1 (Foundation): pillarWeights, rootingWeight")
        print("   - Group 2 (Flow/Dynamics): é”æ­»ï¼Œä½¿ç”¨ config/parameters.json ä¸­çš„å›ºå®šå€¼")
        print("   - Group 3 (Interactions): é”æ­»ï¼Œä½¿ç”¨ config/parameters.json ä¸­çš„å›ºå®šå€¼")
        print()
        
        # å¾ªç¯ä¼˜åŒ–ï¼ˆåªä¼˜åŒ– Foundationï¼‰
        for cycle in range(cycles):
            print("\n" + "=" * 80)
            print(f"ğŸ”„ Cycle {cycle + 1}/{cycles} (Foundation Only)")
            print("=" * 80)
            print()
            
            cycle_start_loss = best_loss
            
            # åªè¿è¡Œ Stage 1: Foundation
            print(f"--- Cycle {cycle + 1} - Stage 1: Foundation ---")
            # V53.0: ä¸å†ä½¿ç”¨ç¡¬ç¼–ç çš„ç§å­å‚æ•°ï¼Œç›´æ¥ä» base_config è¯»å–
            seed_stage1 = {}
            stage1_params = optimize_stage_1(best_params, cases, base_config, n_trials=200, seed_trial=seed_stage1, step=step)
            best_params.update(stage1_params)
            
            # è®¡ç®— Stage 1 åçš„æŸå¤±
            config_s1 = copy.deepcopy(base_config)
            for param_path, value in best_params.items():
                set_nested_param(config_s1, param_path, value)
            engine_s1 = GraphNetworkEngine(config=config_s1)
            loss_s1 = calculate_weighted_loss(engine_s1, cases, config_s1, step=step)
            print(f"   Stage 1 åæŸå¤±: {loss_s1:.2f}")
            
            # V53.0: è®¡ç®—å¹¶æ˜¾ç¤ºå‡†ç¡®ç‡
            accuracies_s1 = calculate_accuracy(engine_s1, cases, config_s1)
            print(f"   ğŸ“ˆ Stage 1 åå‡†ç¡®ç‡:")
            print(f"      æ€»å‡†ç¡®ç‡: {accuracies_s1['Total']:.1f}%")
            for label in ["Strong", "Balanced", "Weak"]:
                print(f"      {label}: {accuracies_s1[label]:.1f}%")
            print()
            
            # æ›´æ–°æœ€ä½³æŸå¤±
            if loss_s1 < best_loss:
                best_loss = loss_s1
            
            # è®¡ç®—æœ€ç»ˆå‡†ç¡®ç‡ï¼ˆç”¨äº Cycle æŠ¥å‘Šï¼‰
            config_final = copy.deepcopy(base_config)
            for param_path, value in best_params.items():
                set_nested_param(config_final, param_path, value)
            engine_final = GraphNetworkEngine(config=config_final)
            accuracies_final = calculate_accuracy(engine_final, cases, config_final)
            
            # æ‰“å° Cycle æŠ¥å‘Š
            cycle_improvement = cycle_start_loss - loss_s1
            cycle_improvement_pct = (cycle_improvement / cycle_start_loss * 100) if cycle_start_loss > 0 else 0.0
            
            print("=" * 80)
            print(f"ğŸ“Š Cycle {cycle + 1} æŠ¥å‘Š (Foundation Only)")
            print("=" * 80)
            print(f"æŸå¤±å˜åŒ–: {cycle_start_loss:.2f} â†’ {loss_s1:.2f}")
            print(f"æ”¹è¿›å¹…åº¦: {cycle_improvement:+.2f} ({cycle_improvement_pct:+.1f}%)")
            print()
            print(f"ğŸ“ˆ å½“å‰å‡†ç¡®ç‡:")
            print(f"   æ€»å‡†ç¡®ç‡: {accuracies_final['Total']:.1f}%")
            for label in ["Strong", "Balanced", "Weak"]:
                print(f"   {label}: {accuracies_final[label]:.1f}%")
            print()
            print(f"ğŸ“ˆ å½“å‰å‡†ç¡®ç‡:")
            print(f"   æ€»å‡†ç¡®ç‡: {accuracies_final['Total']:.1f}%")
            for label in ["Strong", "Balanced", "Weak"]:
                print(f"   {label}: {accuracies_final[label]:.1f}%")
            print()
            
            # Checkpoint: ä¿å­˜å½“å‰æœ€ä½³å‚æ•°
            save_best_params(best_params)
            print(f"âœ… Cycle {cycle + 1} æœ€ä½³å‚æ•°å·²ä¿å­˜")
            print()
    elif step == 2:
        # Step 2: åªä¼˜åŒ– Dynamicsï¼Œé”æ­» Foundation å’Œ Interactions
        print("ğŸ”“ V53.0 Step 2: Dynamics Unlocking")
        print("   - ä»…ä¼˜åŒ– Group 2 (Flow/Dynamics): controlImpact, maxDrainRate, generationEfficiency, dampingFactor")
        print("   - Group 1 (Foundation): é”æ­»ï¼Œä½¿ç”¨å½“å‰ config/parameters.json çš„æœ€ä½³å€¼")
        print("   - Group 3 (Interactions): é”æ­»ï¼Œä¿æŒä¸å˜")
        print()

        for cycle in range(cycles):
            print("\n" + "=" * 80)
            print(f"ğŸ”„ Cycle {cycle + 1}/{cycles} (Dynamics Only)")
            print("=" * 80)
            print()

            cycle_start_loss = best_loss

            # åªè¿è¡Œ Stage 2: Dynamics
            print(f"--- Cycle {cycle + 1} - Stage 2: Dynamics ---")
            seed_stage2 = {}
            stage2_params = optimize_stage_2(
                best_params, cases, base_config, n_trials=300, seed_trial=seed_stage2, step=step
            )
            best_params.update(stage2_params)

            # è®¡ç®— Stage 2 åçš„æŸå¤±
            config_s2 = copy.deepcopy(base_config)
            for param_path, value in best_params.items():
                set_nested_param(config_s2, param_path, value)
            engine_s2 = GraphNetworkEngine(config=config_s2)
            loss_s2 = calculate_weighted_loss(engine_s2, cases, config_s2, step=step)
            print(f"   Stage 2 åæŸå¤±: {loss_s2:.2f}")
            print()

            # è®¡ç®—å‡†ç¡®ç‡ï¼ˆç”¨äº Cycle æŠ¥å‘Šï¼‰
            accuracies_final = calculate_accuracy(engine_s2, cases, config_s2)

            # æ‰“å° Cycle æŠ¥å‘Š
            cycle_improvement = cycle_start_loss - loss_s2
            cycle_improvement_pct = (cycle_improvement / cycle_start_loss * 100) if cycle_start_loss > 0 else 0.0

            print("=" * 80)
            print(f"ğŸ“Š Cycle {cycle + 1} æŠ¥å‘Š (Dynamics Only)")
            print("=" * 80)
            print(f"æŸå¤±å˜åŒ–: {cycle_start_loss:.2f} â†’ {loss_s2:.2f}")
            print(f"æ”¹è¿›å¹…åº¦: {cycle_improvement:+.2f} ({cycle_improvement_pct:+.1f}%)")
            print()
            print(f"ğŸ“ˆ å½“å‰å‡†ç¡®ç‡:")
            print(f"   æ€»å‡†ç¡®ç‡: {accuracies_final['Total']:.1f}%")
            for label in ["Strong", "Balanced", "Weak"]:
                print(f"   {label}: {accuracies_final[label]:.1f}%")
            print()

            # æ›´æ–°æœ€ä½³æŸå¤±
            if loss_s2 < best_loss:
                best_loss = loss_s2

            # Checkpoint: ä¿å­˜å½“å‰æœ€ä½³å‚æ•°
            save_best_params(best_params)
            print(f"âœ… Cycle {cycle + 1} æœ€ä½³å‚æ•°å·²ä¿å­˜")
            print()
    else:
        # å®Œæ•´ä¼˜åŒ–ï¼ˆæ‰€æœ‰é˜¶æ®µï¼‰
        # å¾ªç¯ä¼˜åŒ–
        for cycle in range(cycles):
            print("\n" + "=" * 80)
            print(f"ğŸ”„ Cycle {cycle + 1}/{cycles}")
            print("=" * 80)
            print()
            
            cycle_start_loss = best_loss
            
            # Round 1: Foundation
            print(f"--- Cycle {cycle + 1} - Stage 1: Foundation ---")
            # V53.0: ä¸å†ä½¿ç”¨ç¡¬ç¼–ç çš„ç§å­å‚æ•°ï¼Œç›´æ¥ä» base_config è¯»å–
            seed_stage1 = {}
            stage1_params = optimize_stage_1(best_params, cases, base_config, n_trials=200, seed_trial=seed_stage1, step=step)
            best_params.update(stage1_params)
            
            # è®¡ç®— Stage 1 åçš„æŸå¤±
            config_s1 = copy.deepcopy(base_config)
            for param_path, value in best_params.items():
                set_nested_param(config_s1, param_path, value)
            engine_s1 = GraphNetworkEngine(config=config_s1)
            loss_s1 = calculate_weighted_loss(engine_s1, cases, config_s1, step=step)
            print(f"   Stage 1 åæŸå¤±: {loss_s1:.2f}")
            print()
            
            # Round 2: Dynamics
            print(f"--- Cycle {cycle + 1} - Stage 2: Dynamics ---")
            # V53.0: ä¸å†ä½¿ç”¨ç¡¬ç¼–ç çš„ç§å­å‚æ•°ï¼Œç›´æ¥ä» base_config è¯»å–
            seed_stage2 = {}
            stage2_params = optimize_stage_2(best_params, cases, base_config, n_trials=200, seed_trial=seed_stage2, step=step)
            best_params.update(stage2_params)
            
            # è®¡ç®— Stage 2 åçš„æŸå¤±
            config_s2 = copy.deepcopy(base_config)
            for param_path, value in best_params.items():
                set_nested_param(config_s2, param_path, value)
            engine_s2 = GraphNetworkEngine(config=config_s2)
            loss_s2 = calculate_weighted_loss(engine_s2, cases, config_s2, step=step)
            print(f"   Stage 2 åæŸå¤±: {loss_s2:.2f}")
            print()
            
            # Round 3: Interactions
            print(f"--- Cycle {cycle + 1} - Stage 3: Interactions ---")
            # V53.0: ä¸å†ä½¿ç”¨ç¡¬ç¼–ç çš„ç§å­å‚æ•°ï¼Œç›´æ¥ä» base_config è¯»å–
            seed_stage3 = {}
            stage3_params = optimize_stage_3(best_params, cases, base_config, n_trials=200, seed_trial=seed_stage3, step=step)
            best_params.update(stage3_params)
            
            # è®¡ç®— Stage 3 åçš„æŸå¤±
            config_s3 = copy.deepcopy(base_config)
            for param_path, value in best_params.items():
                set_nested_param(config_s3, param_path, value)
            engine_s3 = GraphNetworkEngine(config=config_s3)
            loss_s3 = calculate_weighted_loss(engine_s3, cases, config_s3, step=step)
            print(f"   Stage 3 åæŸå¤±: {loss_s3:.2f}")
            print()
            
            # æ›´æ–°æœ€ä½³æŸå¤±
            if loss_s3 < best_loss:
                best_loss = loss_s3
            
            # æ‰“å° Cycle æŠ¥å‘Š
            cycle_improvement = cycle_start_loss - loss_s3
            cycle_improvement_pct = (cycle_improvement / cycle_start_loss * 100) if cycle_start_loss > 0 else 0.0
            
            print("=" * 80)
            print(f"ğŸ“Š Cycle {cycle + 1} æŠ¥å‘Š")
            print("=" * 80)
            print(f"æŸå¤±å˜åŒ–: {cycle_start_loss:.2f} â†’ {loss_s3:.2f}")
            print(f"æ”¹è¿›å¹…åº¦: {cycle_improvement:+.2f} ({cycle_improvement_pct:+.1f}%)")
            print()
            
            # Checkpoint: ä¿å­˜å½“å‰æœ€ä½³å‚æ•°
            save_best_params(best_params)
            print(f"âœ… Cycle {cycle + 1} æœ€ä½³å‚æ•°å·²ä¿å­˜")
            print()
    
    return best_params


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå¾ªç¯ä¼˜åŒ–"""
    print("=" * 80)
    print("ğŸ¤– Antigravity Cyclic AI Trainer (V53.0)")
    print("   Controlled Float: Unlocking Base Parameters for Golden Dataset 2.0")
    print("=" * 80)
    print()
    
    # åŠ è½½æµ‹è¯•æ¡ˆä¾‹
    print("ğŸ“‹ åŠ è½½æµ‹è¯•æ¡ˆä¾‹...")
    cases = load_golden_cases()
    print(f"   å·²åŠ è½½ {len(cases)} ä¸ªæ¡ˆä¾‹")
    print()
    
    if not cases:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æµ‹è¯•æ¡ˆä¾‹")
        return
    
    # åŠ è½½åŸºç¡€é…ç½®
    base_config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
    
    # å¦‚æœå­˜åœ¨ç°æœ‰é…ç½®æ–‡ä»¶ï¼Œå…ˆåŠ è½½å®ƒ
    config_path = project_root / "config" / "parameters.json"
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            existing_config = json.load(f)
            def deep_merge(base, update):
                for key, value in update.items():
                    if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                        deep_merge(base[key], value)
                    else:
                        base[key] = value
            deep_merge(base_config, existing_config)
        print("ğŸ“‚ å·²åŠ è½½ç°æœ‰é…ç½®æ–‡ä»¶ä½œä¸ºèµ·ç‚¹")
        print()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description="Antigravity Cyclic AI Trainer")
    parser.add_argument("--step", type=int, default=2, choices=[0, 1, 2],
                        help="è®­ç»ƒé˜¶æ®µ: 0=å…¨é˜¶æ®µ, 1=ä»…åŸºç¡€å±‚(Foundation), 2=ä»…åŠ¨åŠ›å±‚(Dynamics)ã€‚é»˜è®¤ 2")
    parser.add_argument("--mode", type=str, default="unified", choices=["unified", "legacy"],
                        help="unified=å•ä¸€studyè”åˆè°ƒä¼˜(æ¨è); legacy=æŒ‰stepåˆ†é˜¶æ®µæ—§æ¨¡å¼")
    parser.add_argument("--trials", type=int, default=400, help="æ¯è½®è¯•éªŒæ¬¡æ•° (unified æ¨¡å¼)")
    parser.add_argument("--max-loops", type=int, default=0, help="æœ€å¤§å¾ªç¯è½®æ•° (0=æ— é™ç›´åˆ°è€å¿ƒè€—å°½)")
    parser.add_argument("--patience", type=int, default=2, help="æ— æ”¹è¿›å®¹å¿è½®æ•° (unified æ¨¡å¼)")
    parser.add_argument("--min-improve", type=float, default=1e-3, help="è§†ä¸ºæ”¹è¿›çš„æœ€å° loss å·®å€¼")
    args = parser.parse_args()

    step = args.step
    if step == 1:
        print("ğŸ”’ æ¨¡å¼: Step 1 - Foundation Locking Tuning (åªè°ƒåŸºç¡€å±‚)")
    elif step == 2:
        print("ğŸ”“ æ¨¡å¼: Step 2 - Dynamics Unlocking (åªè°ƒåŠ¨åŠ›å±‚)")
    else:
        print("ğŸ” æ¨¡å¼: å…¨é˜¶æ®µä¼˜åŒ– (Foundation + Dynamics + Interactions)")
    print(f"ğŸ›ï¸ è¿è¡Œæ¨¡å¼: {args.mode}")
    print()

    # è¿è¡Œä¼˜åŒ–
    if args.mode == "unified":
        best_params = run_unified_optimization(
            cases,
            base_config,
            n_trials=args.trials,
            max_loops=args.max_loops,
            patience=args.patience,
            min_improve=args.min_improve,
        )
    else:
        best_params = run_cyclic_optimization(cases, base_config, cycles=5, step=step)
    
    # ===========================================
    # æœ€ç»ˆæŠ¥å‘Š
    # ===========================================
    print("\n" + "=" * 80)
    print("ğŸ“Š æœ€ç»ˆè®­ç»ƒæŠ¥å‘Š")
    print("=" * 80)
    print()
    
    # è®¡ç®—æœ€ç»ˆæŸå¤±
    config_final = copy.deepcopy(base_config)
    for param_path, value in best_params.items():
        set_nested_param(config_final, param_path, value)
    engine_final = GraphNetworkEngine(config=config_final)
    final_loss = calculate_weighted_loss(engine_final, cases, config_final, step=step)
    
    print(f"æœ€ç»ˆæŸå¤±: {final_loss:.2f}")
    print()
    
    print("æœ€ç»ˆæœ€ä½³å‚æ•°:")
    print("-" * 80)
    for param_name, param_value in sorted(best_params.items()):
        print(f"  {param_name:40s} = {param_value:.6f}")
    print()
    
    # ä¿å­˜æœ€ä½³å‚æ•°
    print("ğŸ’¾ ä¿å­˜æœ€ç»ˆæœ€ä½³å‚æ•°...")
    save_best_params(best_params)
    print()
    
    # ç”Ÿæˆæ”¹è¿›æŠ¥å‘Šï¼ˆå‡†ç¡®ç‡ï¼‰
    print("=" * 80)
    print("ğŸ“ˆ å‡†ç¡®ç‡æŠ¥å‘Š")
    print("=" * 80)
    print()
    
    correct_count = 0
    total_count = 0
    label_stats = {"Strong": {"correct": 0, "total": 0}, 
                   "Balanced": {"correct": 0, "total": 0},
                   "Weak": {"correct": 0, "total": 0}}
    
    for case in cases:
        true_label = case.get('true_label')
        if not true_label:
            continue
        
        try:
            result = engine_final.analyze(
                bazi=case['bazi'],
                day_master=case['day_master'],
                luck_pillar=None,
                year_pillar=None,
                geo_modifiers=None
            )
            
            strength_score = result.get('strength_score', 0.0)
            strength_label = result.get('strength_label', 'Unknown')
            
            # ä½¿ç”¨å¼•æ“è¿”å›çš„æ ‡ç­¾
            if strength_label in ["Strong", "Balanced", "Weak", "Special_Strong"]:
                pred_label = strength_label
            else:
                grading_config = config_final.get('grading', {})
                strong_threshold = grading_config.get('strong_threshold', 60.0)
                weak_threshold = grading_config.get('weak_threshold', 40.0)
                pred_label = predict_strength(strength_score, strong_threshold, weak_threshold)
            
            # ç‰¹æ®Šæ ¼å±€ä¾‹å¤–å¤„ç†
            is_correct = (pred_label == true_label)
            if not is_correct:
                if pred_label == "Special_Strong" and true_label in ["Balanced", "Strong"]:
                    is_correct = True
            
            total_count += 1
            if is_correct:
                correct_count += 1
            
            if true_label in label_stats:
                label_stats[true_label]["total"] += 1
                if is_correct:
                    label_stats[true_label]["correct"] += 1
        
        except Exception as e:
            print(f"âš ï¸  æ¡ˆä¾‹ {case.get('id')} å‡ºé”™: {e}")
    
    # æ‰“å°ç»Ÿè®¡
    accuracy = (correct_count / total_count * 100) if total_count > 0 else 0.0
    print(f"æ€»å‡†ç¡®ç‡: {accuracy:.1f}% ({correct_count}/{total_count})")
    print()
    
    print("æŒ‰æ ‡ç­¾åˆ†ç±»çš„å‡†ç¡®ç‡:")
    print("-" * 80)
    for label, stats in label_stats.items():
        if stats["total"] > 0:
            label_accuracy = (stats["correct"] / stats["total"] * 100)
            print(f"  {label:10s}: {label_accuracy:.1f}% ({stats['correct']}/{stats['total']})")
    print()
    
    print("=" * 80)
    print("âœ… å¾ªç¯ AI è®­ç»ƒå®Œæˆ")
    print("=" * 80)
    print()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
