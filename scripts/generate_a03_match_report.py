#!/usr/bin/env python3
"""
A-03 æ ¼å±€åŒ¹é…æŠ¥å‘Šç”Ÿæˆå™¨
========================
ä»å…¨é‡ 51.8 ä¸‡æ ·æœ¬ä¸­æ‰«æ A-03 æ ¼å±€ï¼Œç”Ÿæˆè¯¦ç»†çš„åŒ¹é…æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
    python3 scripts/generate_a03_match_report.py
"""

import json
import sys
from pathlib import Path
from collections import Counter
from datetime import datetime
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

def generate_report():
    """ç”Ÿæˆ A-03 åŒ¹é…æŠ¥å‘Š"""
    
    result_file = project_root / "results" / "a03_full_518k_scan.matched.json"
    stats_file = project_root / "data_file" / "holographic_universe_518k.jsonl"
    
    print("=" * 80)
    print("ğŸ”¬ A-03 ç¾Šåˆƒæ¶æ€æ ¼ - å…¨é‡æ ·æœ¬åŒ¹é…éªŒè¯æŠ¥å‘Š")
    print("=" * 80)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # 1. è¯»å–ç»Ÿè®¡æ–‡ä»¶
    stats_data = {}
    stats_json_file = project_root / "results" / "a03_full_518k_scan.stats.json"
    if stats_json_file.exists():
        with open(stats_json_file, 'r', encoding='utf-8') as f:
            stats_data = json.load(f)
            # æå–statså­—æ®µä¸­çš„ä¿¡æ¯
            if 'stats' in stats_data:
                stats_data = stats_data['stats']
    
    # 2. åˆ†æåŒ¹é…ç»“æœ
    print("ğŸ“Š æ­£åœ¨åˆ†æåŒ¹é…ç»“æœ...")
    matched_results = []
    precision_scores = []
    mahalanobis_dists = []
    sai_values = []
    tensor_data = []
    error_count = 0
    
    # æ–‡ä»¶æ˜¯å•ä¸ªJSONå¯¹è±¡ï¼Œä¸æ˜¯JSONLæ ¼å¼
    with open(result_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ä»JSONå¯¹è±¡ä¸­æå–ä¿¡æ¯
    matched_count_from_file = data.get('matched_count', 0)
    results = data.get('results', [])
    total_samples = stats_data.get('total_samples', 518400)  # é»˜è®¤51.8ä¸‡
    error_count_from_stats = stats_data.get('error_count', 0)
    
    print(f"âœ… ä»æ–‡ä»¶ä¸­è¯»å–åˆ° {len(results):,} ä¸ªç»“æœ")
    
    # åˆ†ææ¯ä¸ªç»“æœ
    for result in results:
        if result.get('status') == 'error':
            error_count += 1
            continue
        
        if result.get('pattern_status') == 'MATCHED':
            matched_results.append(result)
            precision_scores.append(result.get('precision_score', 0))
            mahalanobis_dists.append(result.get('mahalanobis_dist', 0))
            sai_values.append(result.get('sai', 0))
            if 'tensor' in result:
                tensor_data.append(result['tensor'])
    
    matched_count = len(matched_results)
    match_rate = (matched_count / total_samples * 100) if total_samples > 0 else 0
    # å¦‚æœç»Ÿè®¡æ–‡ä»¶ä¸­æœ‰é”™è¯¯æ•°ï¼Œä½¿ç”¨ç»Ÿè®¡æ–‡ä»¶çš„é”™è¯¯æ•°
    if error_count == 0 and error_count_from_stats > 0:
        error_count = error_count_from_stats
    
    # 3. ç”ŸæˆæŠ¥å‘Š
    report = {
        "report_meta": {
            "pattern_id": "A-03",
            "pattern_name": "ç¾Šåˆƒæ¶æ€æ ¼ (Blade & Killer)",
            "generated_at": datetime.now().isoformat(),
            "data_source": "holographic_universe_518k.jsonl"
        },
        "summary": {
            "total_samples": total_samples,
            "matched_count": matched_count,
            "error_count": error_count,
            "match_rate_percent": round(match_rate, 2),
            "processing_status": "âœ… å®Œæˆ"
        },
        "statistics": {},
        "top_matches": [],
        "distribution": {}
    }
    
    # Precision Score ç»Ÿè®¡
    if precision_scores:
        report["statistics"]["precision_score"] = {
            "max": float(np.max(precision_scores)),
            "min": float(np.min(precision_scores)),
            "mean": float(np.mean(precision_scores)),
            "median": float(np.median(precision_scores)),
            "std": float(np.std(precision_scores)),
            "q25": float(np.percentile(precision_scores, 25)),
            "q75": float(np.percentile(precision_scores, 75))
        }
        
        # åˆ†æ•°åˆ†å¸ƒ
        bins = [0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        hist, _ = np.histogram(precision_scores, bins=bins)
        report["distribution"]["precision_score"] = {}
        for i in range(len(bins)-1):
            count = int(hist[i])
            percentage = (count / len(precision_scores) * 100) if len(precision_scores) > 0 else 0
            report["distribution"]["precision_score"][f"{bins[i]:.1f}-{bins[i+1]:.1f}"] = {
                "count": count,
                "percentage": round(percentage, 2)
            }
    
    # Mahalanobis Distance ç»Ÿè®¡
    if mahalanobis_dists:
        report["statistics"]["mahalanobis_distance"] = {
            "min": float(np.min(mahalanobis_dists)),
            "max": float(np.max(mahalanobis_dists)),
            "mean": float(np.mean(mahalanobis_dists)),
            "median": float(np.median(mahalanobis_dists)),
            "std": float(np.std(mahalanobis_dists))
        }
    
    # SAI ç»Ÿè®¡
    if sai_values:
        report["statistics"]["sai"] = {
            "min": float(np.min(sai_values)),
            "max": float(np.max(sai_values)),
            "mean": float(np.mean(sai_values)),
            "median": float(np.median(sai_values)),
            "std": float(np.std(sai_values))
        }
    
    # Top 20 åŒ¹é…æ¡ˆä¾‹
    sorted_results = sorted(matched_results, key=lambda x: x.get('precision_score', 0), reverse=True)
    for result in sorted_results[:20]:
        report["top_matches"].append({
            "uid": result.get('uid'),
            "line_number": result.get('line_number'),
            "precision_score": round(result.get('precision_score', 0), 4),
            "mahalanobis_dist": round(result.get('mahalanobis_dist', 0), 4),
            "sai": round(result.get('sai', 0), 4),
            "tensor": result.get('tensor', {})
        })
    
    # 4. ä¿å­˜æŠ¥å‘Š
    report_file = project_root / "results" / "a03_full_518k_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # 5. æ‰“å°æ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸ“‹ åŒ¹é…æ‘˜è¦")
    print("=" * 80)
    print(f"æ€»æ ·æœ¬æ•°: {total_samples:,}")
    print(f"åŒ¹é…æ•°é‡: {matched_count:,}")
    print(f"é”™è¯¯æ•°é‡: {error_count:,}")
    print(f"åŒ¹é…ç‡: {match_rate:.2f}%")
    
    if precision_scores:
        print(f"\nğŸ“ˆ Precision Score ç»Ÿè®¡:")
        print(f"  æœ€é«˜åˆ†: {max(precision_scores):.4f}")
        print(f"  æœ€ä½åˆ†: {min(precision_scores):.4f}")
        print(f"  å¹³å‡åˆ†: {np.mean(precision_scores):.4f}")
        print(f"  ä¸­ä½æ•°: {np.median(precision_scores):.4f}")
        print(f"  æ ‡å‡†å·®: {np.std(precision_scores):.4f}")
        
        print(f"\n  åˆ†æ•°åˆ†å¸ƒ:")
        bins = [0.0, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        hist, _ = np.histogram(precision_scores, bins=bins)
        for i in range(len(bins)-1):
            count = int(hist[i])
            pct = (count / len(precision_scores) * 100) if len(precision_scores) > 0 else 0
            print(f"    {bins[i]:.1f}-{bins[i+1]:.1f}: {count:,} ä¸ª ({pct:.2f}%)")
    
    if mahalanobis_dists:
        print(f"\nğŸ“ Mahalanobis Distance ç»Ÿè®¡:")
        print(f"  æœ€å°: {min(mahalanobis_dists):.4f}")
        print(f"  æœ€å¤§: {max(mahalanobis_dists):.4f}")
        print(f"  å¹³å‡: {np.mean(mahalanobis_dists):.4f}")
        print(f"  ä¸­ä½æ•°: {np.median(mahalanobis_dists):.4f}")
    
    if sai_values:
        print(f"\nâš¡ SAI (ç»“æ„æ€»èƒ½é‡) ç»Ÿè®¡:")
        print(f"  æœ€å°: {min(sai_values):.4f}")
        print(f"  æœ€å¤§: {max(sai_values):.4f}")
        print(f"  å¹³å‡: {np.mean(sai_values):.4f}")
        print(f"  ä¸­ä½æ•°: {np.median(sai_values):.4f}")
    
    print(f"\nğŸ† Top 10 æœ€ä½³åŒ¹é…æ¡ˆä¾‹:")
    for i, result in enumerate(sorted_results[:10], 1):
        uid = result.get('uid', 'N/A')
        precision = result.get('precision_score', 0)
        mdist = result.get('mahalanobis_dist', 0)
        sai = result.get('sai', 0)
        uid_str = str(uid) if uid != 'N/A' else 'N/A'
        print(f"  {i:2d}. UID {uid_str:>6s}: Precision={precision:.4f}, M-Dist={mdist:.4f}, SAI={sai:.4f}")
    
    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("=" * 80)
    
    return report

if __name__ == "__main__":
    try:
        generate_report()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)

