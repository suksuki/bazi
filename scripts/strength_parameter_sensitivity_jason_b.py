#!/usr/bin/env python3
"""
Jason B (èº«å¼±ç”¨å°) å‚æ•°æ•æ„Ÿåº¦åˆ†æ
================================

é’ˆå¯¹"èº«å¼±ç”¨å°"å‘½å±€ç»“æ„çš„å‚æ•°æ•æ„Ÿåº¦åˆ†æ
é‡ç‚¹åˆ†æ"å°æ˜Ÿå¸®èº«"æœºåˆ¶ä¸ºä½•æœªè¢«å……åˆ†æ¿€æ´»

ä½œè€…: Antigravity Team
ç‰ˆæœ¬: V10.0
æ—¥æœŸ: 2025-12-17
"""

import sys
import json
import numpy as np
import logging
from pathlib import Path
from typing import Dict, List, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.strength_probability_wave import StrengthProbabilityWave
from core.gat_strength_attention import GATStrengthAttention
from core.bayesian_strength_calibration import BayesianStrengthCalibration
from core.engine_graph import GraphNetworkEngine
from core.config_schema import DEFAULT_FULL_ALGO_PARAMS
import copy


class JasonBParameterSensitivityAnalyzer:
    """
    Jason B (èº«å¼±ç”¨å°) å‚æ•°æ•æ„Ÿåº¦åˆ†æå™¨
    é‡ç‚¹åˆ†æ"å°æ˜Ÿå¸®èº«"æœºåˆ¶
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.case_data = self._load_jason_b_case()
        logger.info(f"âœ… åŠ è½½ Jason B æ¡ˆä¾‹: {self.case_data['name']}")
    
    def _load_jason_b_case(self) -> Dict:
        """åŠ è½½ Jason B æ¡ˆä¾‹æ•°æ®"""
        case_file = project_root / "calibration_cases.json"
        if case_file.exists():
            with open(case_file, 'r', encoding='utf-8') as f:
                cases = json.load(f)
                for case in cases:
                    if case.get('id', '').startswith('JASON_B'):
                        return case
        
        # ä½¿ç”¨é»˜è®¤æ•°æ®
        return {
            'id': 'JASON_B_T1964_0910',
            'name': 'Jason B (èº«å¼±ç”¨å°)',
            'bazi': ['ç”²è¾°', 'ç™¸é…‰', 'å·±äº¥', 'æˆŠè¾°'],
            'day_master': 'å·±',
            'gender': 'ç”·',
            'description': 'èº«å¼±ç”¨å°ï¼Œå°æ˜Ÿå¸®èº«',
            'timeline': [
                {
                    'year': 1999,
                    'ganzhi': 'å·±å¯',
                    'dayun': 'ä¸ä¸‘',
                    'type': 'WEALTH',
                    'real_magnitude': 100.0,
                    'desc': 'è´¢å¯Œçˆ†å‘'
                },
                {
                    'year': 2007,
                    'ganzhi': 'ä¸äº¥',
                    'dayun': 'æˆŠå¯…',
                    'type': 'WEALTH',
                    'real_magnitude': 70.0,
                    'desc': 'è´¢å¯Œç§¯ç´¯'
                },
                {
                    'year': 2014,
                    'ganzhi': 'ç”²åˆ',
                    'dayun': 'å·±å¯',
                    'type': 'WEALTH',
                    'real_magnitude': 100.0,
                    'desc': 'è´¢å¯Œå†æ¬¡çˆ†å‘'
                }
            ]
        }
    
    def analyze_generation_efficiency_sensitivity(self) -> Dict:
        """
        åˆ†æ"ç”Ÿçš„æ•ˆç‡" (generationEfficiency) çš„æ•æ„Ÿåº¦
        è¿™æ˜¯"å°æ˜Ÿå¸®èº«"æœºåˆ¶çš„æ ¸å¿ƒå‚æ•°
        """
        logger.info("=" * 80)
        logger.info("ğŸ“Š åˆ†æ'ç”Ÿçš„æ•ˆç‡' (generationEfficiency) æ•æ„Ÿåº¦")
        logger.info("=" * 80)
        
        efficiency_range = np.linspace(0.1, 2.0, 20)
        losses = []
        
        for efficiency in efficiency_range:
            total_loss = 0.0
            for event in self.case_data['timeline']:
                year = event.get('year')
                real_wealth = event.get('real_magnitude', 0.0)
                year_pillar = event.get('ganzhi', '')
                luck_pillar = event.get('dayun', '')
                
                # åˆ›å»ºé…ç½®
                config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
                config['flow']['generationEfficiency'] = efficiency
                
                # è®¡ç®—é¢„æµ‹å€¼
                engine = GraphNetworkEngine(config=config)
                result = engine.calculate_wealth_index(
                    bazi=self.case_data['bazi'],
                    day_master=self.case_data['day_master'],
                    gender=self.case_data['gender'],
                    luck_pillar=luck_pillar,
                    year_pillar=year_pillar
                )
                
                if isinstance(result, dict):
                    predicted = result.get('wealth_index', 0.0)
                else:
                    predicted = float(result)
                
                # è®¡ç®—è¯¯å·®
                error = (predicted - real_wealth) ** 2
                total_loss += error
            
            avg_loss = total_loss / len(self.case_data['timeline'])
            losses.append(avg_loss)
        
        # æ‰¾åˆ°æœ€ä¼˜å€¼
        optimal_idx = np.argmin(losses)
        optimal_efficiency = efficiency_range[optimal_idx]
        optimal_loss = losses[optimal_idx]
        
        # è®¡ç®—æ•æ„Ÿåº¦
        sensitivity = np.gradient(losses, efficiency_range)
        
        result = {
            'parameter_name': 'generationEfficiency',
            'parameter_range': efficiency_range.tolist(),
            'losses': losses,
            'sensitivity': sensitivity.tolist(),
            'optimal_value': float(optimal_efficiency),
            'optimal_loss': float(optimal_loss),
            'sensitivity_range': [float(np.min(sensitivity)), float(np.max(sensitivity))]
        }
        
        logger.info(f"âœ… æœ€ä¼˜'ç”Ÿçš„æ•ˆç‡': {optimal_efficiency:.4f}")
        logger.info(f"   æœ€ä¼˜æŸå¤±: {optimal_loss:.4f}")
        logger.info(f"   æ•æ„Ÿåº¦èŒƒå›´: [{np.min(sensitivity):.4f}, {np.max(sensitivity):.4f}]")
        
        return result
    
    def analyze_strength_threshold_sensitivity(self) -> Dict:
        """
        åˆ†ææ—ºè¡°é˜ˆå€¼å¯¹"èº«å¼±ç”¨å°"å‘½å±€çš„å½±å“
        """
        logger.info("=" * 80)
        logger.info("ğŸ“Š åˆ†ææ—ºè¡°é˜ˆå€¼æ•æ„Ÿåº¦ï¼ˆèº«å¼±ç”¨å°ï¼‰")
        logger.info("=" * 80)
        
        threshold_range = np.linspace(2.0, 4.0, 20)
        losses = []
        
        for threshold in threshold_range:
            total_loss = 0.0
            for event in self.case_data['timeline']:
                year = event.get('year')
                real_wealth = event.get('real_magnitude', 0.0)
                year_pillar = event.get('ganzhi', '')
                luck_pillar = event.get('dayun', '')
                
                # åˆ›å»ºé…ç½®
                config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
                if 'strength' not in config:
                    config['strength'] = {}
                config['strength']['energy_threshold_center'] = threshold
                
                # è®¡ç®—é¢„æµ‹å€¼
                engine = GraphNetworkEngine(config=config)
                result = engine.calculate_wealth_index(
                    bazi=self.case_data['bazi'],
                    day_master=self.case_data['day_master'],
                    gender=self.case_data['gender'],
                    luck_pillar=luck_pillar,
                    year_pillar=year_pillar
                )
                
                if isinstance(result, dict):
                    predicted = result.get('wealth_index', 0.0)
                else:
                    predicted = float(result)
                
                # è®¡ç®—è¯¯å·®
                error = (predicted - real_wealth) ** 2
                total_loss += error
            
            avg_loss = total_loss / len(self.case_data['timeline'])
            losses.append(avg_loss)
        
        # æ‰¾åˆ°æœ€ä¼˜å€¼
        optimal_idx = np.argmin(losses)
        optimal_threshold = threshold_range[optimal_idx]
        optimal_loss = losses[optimal_idx]
        
        # è®¡ç®—æ•æ„Ÿåº¦
        sensitivity = np.gradient(losses, threshold_range)
        
        result = {
            'parameter_name': 'energy_threshold_center',
            'parameter_range': threshold_range.tolist(),
            'losses': losses,
            'sensitivity': sensitivity.tolist(),
            'optimal_value': float(optimal_threshold),
            'optimal_loss': float(optimal_loss),
            'sensitivity_range': [float(np.min(sensitivity)), float(np.max(sensitivity))]
        }
        
        logger.info(f"âœ… æœ€ä¼˜æ—ºè¡°é˜ˆå€¼: {optimal_threshold:.4f}")
        logger.info(f"   æœ€ä¼˜æŸå¤±: {optimal_loss:.4f}")
        logger.info(f"   æ•æ„Ÿåº¦èŒƒå›´: [{np.min(sensitivity):.4f}, {np.max(sensitivity):.4f}]")
        
        return result
    
    def analyze_seal_boost_sensitivity(self) -> Dict:
        """
        åˆ†æ"å°æ˜ŸåŠ æˆ" (Seal Boost) çš„æ•æ„Ÿåº¦
        è¿™æ˜¯"èº«å¼±ç”¨å°"å‘½å±€çš„å…³é”®æœºåˆ¶
        """
        logger.info("=" * 80)
        logger.info("ğŸ“Š åˆ†æ'å°æ˜ŸåŠ æˆ'æ•æ„Ÿåº¦")
        logger.info("=" * 80)
        
        # æŸ¥æ‰¾é…ç½®ä¸­çš„å°æ˜Ÿç›¸å…³å‚æ•°
        # é€šå¸¸å°æ˜ŸåŠ æˆå¯èƒ½åœ¨ physics æˆ– structure ä¸­
        boost_range = np.linspace(0.5, 2.0, 20)
        losses = []
        
        for boost in boost_range:
            total_loss = 0.0
            for event in self.case_data['timeline']:
                year = event.get('year')
                real_wealth = event.get('real_magnitude', 0.0)
                year_pillar = event.get('ganzhi', '')
                luck_pillar = event.get('dayun', '')
                
                # åˆ›å»ºé…ç½®
                config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
                # å‡è®¾å°æ˜ŸåŠ æˆåœ¨ physics ä¸­ï¼ˆéœ€è¦æ ¹æ®å®é™…é…ç½®è°ƒæ•´ï¼‰
                if 'sealBoost' not in config.get('physics', {}):
                    config.setdefault('physics', {})['sealBoost'] = boost
                else:
                    config['physics']['sealBoost'] = boost
                
                # è®¡ç®—é¢„æµ‹å€¼
                engine = GraphNetworkEngine(config=config)
                result = engine.calculate_wealth_index(
                    bazi=self.case_data['bazi'],
                    day_master=self.case_data['day_master'],
                    gender=self.case_data['gender'],
                    luck_pillar=luck_pillar,
                    year_pillar=year_pillar
                )
                
                if isinstance(result, dict):
                    predicted = result.get('wealth_index', 0.0)
                else:
                    predicted = float(result)
                
                # è®¡ç®—è¯¯å·®
                error = (predicted - real_wealth) ** 2
                total_loss += error
            
            avg_loss = total_loss / len(self.case_data['timeline'])
            losses.append(avg_loss)
        
        # æ‰¾åˆ°æœ€ä¼˜å€¼
        optimal_idx = np.argmin(losses)
        optimal_boost = boost_range[optimal_idx]
        optimal_loss = losses[optimal_idx]
        
        # è®¡ç®—æ•æ„Ÿåº¦
        sensitivity = np.gradient(losses, boost_range)
        
        result = {
            'parameter_name': 'sealBoost',
            'parameter_range': boost_range.tolist(),
            'losses': losses,
            'sensitivity': sensitivity.tolist(),
            'optimal_value': float(optimal_boost),
            'optimal_loss': float(optimal_loss),
            'sensitivity_range': [float(np.min(sensitivity)), float(np.max(sensitivity))]
        }
        
        logger.info(f"âœ… æœ€ä¼˜'å°æ˜ŸåŠ æˆ': {optimal_boost:.4f}")
        logger.info(f"   æœ€ä¼˜æŸå¤±: {optimal_loss:.4f}")
        logger.info(f"   æ•æ„Ÿåº¦èŒƒå›´: [{np.min(sensitivity):.4f}, {np.max(sensitivity):.4f}]")
        
        return result
    
    def analyze_weak_wealth_reversal_sensitivity(self) -> Dict:
        """
        åˆ†æ"èº«å¼±è´¢é‡åè½¬"æœºåˆ¶çš„æ•æ„Ÿåº¦
        è¿™æ˜¯"èº«å¼±ç”¨å°"å‘½å±€çš„å…³é”®é€»è¾‘
        """
        logger.info("=" * 80)
        logger.info("ğŸ“Š åˆ†æ'èº«å¼±è´¢é‡åè½¬'æœºåˆ¶æ•æ„Ÿåº¦")
        logger.info("=" * 80)
        
        # æŸ¥æ‰¾é…ç½®ä¸­çš„èº«å¼±è´¢é‡åè½¬å‚æ•°
        # é€šå¸¸åœ¨ wealth æˆ– interactions ä¸­
        reversal_factor_range = np.linspace(-2.0, 0.0, 20)  # è´Ÿå€¼è¡¨ç¤ºåè½¬
        losses = []
        
        for factor in reversal_factor_range:
            total_loss = 0.0
            for event in self.case_data['timeline']:
                year = event.get('year')
                real_wealth = event.get('real_magnitude', 0.0)
                year_pillar = event.get('ganzhi', '')
                luck_pillar = event.get('dayun', '')
                
                # åˆ›å»ºé…ç½®
                config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
                # å‡è®¾èº«å¼±è´¢é‡åè½¬åœ¨ wealth ä¸­ï¼ˆéœ€è¦æ ¹æ®å®é™…é…ç½®è°ƒæ•´ï¼‰
                if 'weakWealthReversal' not in config.get('wealth', {}):
                    config.setdefault('wealth', {})['weakWealthReversal'] = factor
                else:
                    config['wealth']['weakWealthReversal'] = factor
                
                # è®¡ç®—é¢„æµ‹å€¼
                engine = GraphNetworkEngine(config=config)
                result = engine.calculate_wealth_index(
                    bazi=self.case_data['bazi'],
                    day_master=self.case_data['day_master'],
                    gender=self.case_data['gender'],
                    luck_pillar=luck_pillar,
                    year_pillar=year_pillar
                )
                
                if isinstance(result, dict):
                    predicted = result.get('wealth_index', 0.0)
                else:
                    predicted = float(result)
                
                # è®¡ç®—è¯¯å·®
                error = (predicted - real_wealth) ** 2
                total_loss += error
            
            avg_loss = total_loss / len(self.case_data['timeline'])
            losses.append(avg_loss)
        
        # æ‰¾åˆ°æœ€ä¼˜å€¼
        optimal_idx = np.argmin(losses)
        optimal_factor = reversal_factor_range[optimal_idx]
        optimal_loss = losses[optimal_idx]
        
        # è®¡ç®—æ•æ„Ÿåº¦
        sensitivity = np.gradient(losses, reversal_factor_range)
        
        result = {
            'parameter_name': 'weakWealthReversal',
            'parameter_range': reversal_factor_range.tolist(),
            'losses': losses,
            'sensitivity': sensitivity.tolist(),
            'optimal_value': float(optimal_factor),
            'optimal_loss': float(optimal_loss),
            'sensitivity_range': [float(np.min(sensitivity)), float(np.max(sensitivity))]
        }
        
        logger.info(f"âœ… æœ€ä¼˜'èº«å¼±è´¢é‡åè½¬å› å­': {optimal_factor:.4f}")
        logger.info(f"   æœ€ä¼˜æŸå¤±: {optimal_loss:.4f}")
        logger.info(f"   æ•æ„Ÿåº¦èŒƒå›´: [{np.min(sensitivity):.4f}, {np.max(sensitivity):.4f}]")
        
        return result
    
    def generate_sensitivity_report(self, output_dir: Path = None) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´çš„æ•æ„Ÿåº¦åˆ†ææŠ¥å‘Š
        """
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ¯ å¼€å§‹ç”Ÿæˆ Jason B (èº«å¼±ç”¨å°) å‚æ•°æ•æ„Ÿåº¦åˆ†ææŠ¥å‘Š")
        logger.info("=" * 80)
        
        # åˆ†æå…³é”®å‚æ•°
        efficiency_result = self.analyze_generation_efficiency_sensitivity()
        threshold_result = self.analyze_strength_threshold_sensitivity()
        seal_boost_result = self.analyze_seal_boost_sensitivity()
        reversal_result = self.analyze_weak_wealth_reversal_sensitivity()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'case_id': self.case_data['id'],
            'case_name': self.case_data['name'],
            'case_description': self.case_data.get('description', ''),
            'analysis_date': str(Path(__file__).stat().st_mtime),
            'test_events_count': len(self.case_data['timeline']),
            'parameters': {
                'generationEfficiency': efficiency_result,
                'energy_threshold_center': threshold_result,
                'sealBoost': seal_boost_result,
                'weakWealthReversal': reversal_result
            },
            'summary': {
                'most_sensitive_parameter': self._find_most_sensitive_parameter([
                    efficiency_result,
                    threshold_result,
                    seal_boost_result,
                    reversal_result
                ]),
                'recommendations': self._generate_recommendations([
                    efficiency_result,
                    threshold_result,
                    seal_boost_result,
                    reversal_result
                ])
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        if output_dir is None:
            output_dir = project_root / "reports"
        output_dir.mkdir(exist_ok=True)
        
        report_file = output_dir / "jason_b_sensitivity_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        return report
    
    def _find_most_sensitive_parameter(self, results: List[Dict]) -> str:
        """æ‰¾åˆ°æœ€æ•æ„Ÿçš„å‚æ•°"""
        max_sensitivity = 0.0
        most_sensitive = None
        
        for result in results:
            sensitivity_range = result.get('sensitivity_range', [0, 0])
            max_sens = max(abs(sensitivity_range[0]), abs(sensitivity_range[1]))
            if max_sens > max_sensitivity:
                max_sensitivity = max_sens
                most_sensitive = result['parameter_name']
        
        return most_sensitive or 'unknown'
    
    def _generate_recommendations(self, results: List[Dict]) -> List[str]:
        """ç”Ÿæˆè°ƒä¼˜å»ºè®®"""
        recommendations = []
        
        for result in results:
            param_name = result['parameter_name']
            optimal_value = result['optimal_value']
            sensitivity_range = result.get('sensitivity_range', [0, 0])
            max_sens = max(abs(sensitivity_range[0]), abs(sensitivity_range[1]))
            
            if max_sens > 100.0:
                recommendations.append(
                    f"{param_name} æé«˜æ•æ„Ÿï¼Œå¿…é¡»ä¼˜å…ˆè°ƒä¼˜ã€‚å½“å‰æœ€ä¼˜å€¼: {optimal_value:.4f}"
                )
            elif max_sens > 10.0:
                recommendations.append(
                    f"{param_name} é«˜åº¦æ•æ„Ÿï¼Œå»ºè®®ä¼˜å…ˆè°ƒä¼˜ã€‚å½“å‰æœ€ä¼˜å€¼: {optimal_value:.4f}"
                )
            elif max_sens > 5.0:
                recommendations.append(
                    f"{param_name} ä¸­ç­‰æ•æ„Ÿï¼Œå»ºè®®å…³æ³¨ã€‚å½“å‰æœ€ä¼˜å€¼: {optimal_value:.4f}"
                )
            else:
                recommendations.append(
                    f"{param_name} ä½æ•æ„Ÿï¼Œå¯ä»¥ä¿æŒé»˜è®¤å€¼ã€‚å½“å‰æœ€ä¼˜å€¼: {optimal_value:.4f}"
                )
        
        return recommendations


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Jason B (èº«å¼±ç”¨å°) å‚æ•°æ•æ„Ÿåº¦åˆ†æ')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: reports/ï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = JasonBParameterSensitivityAnalyzer()
    
    # ç”ŸæˆæŠ¥å‘Š
    output_dir = Path(args.output) if args.output else None
    report = analyzer.generate_sensitivity_report(output_dir=output_dir)
    
    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š Jason B (èº«å¼±ç”¨å°) æ•æ„Ÿåº¦åˆ†ææ€»ç»“")
    print("=" * 80)
    print(f"æœ€æ•æ„Ÿå‚æ•°: {report['summary']['most_sensitive_parameter']}")
    print("\nè°ƒä¼˜å»ºè®®:")
    for rec in report['summary']['recommendations']:
        print(f"  - {rec}")
    print("\nâœ… åˆ†æå®Œæˆï¼")


if __name__ == '__main__':
    main()

