# 自动进化元优化器 (Auto-Evolution Meta-Optimizer) V50.0

## 概述

`auto_evolve.py` 是一个**无人值守的元优化器**，它会自动：
1. 加载当前最佳参数作为种子（基于 V49.0 的黄金平衡配置）
2. 运行训练和验证
3. 动态调整 Loss 函数权重（准确率越低，权重越高）
4. 自适应扩大触顶参数的搜索范围
5. 无限循环直到达到目标准确率（默认 82%）

**V50.0 新特性**：
- ✅ 支持无限循环模式（`--max-iter 0`）
- ✅ 更激进的动态权重公式
- ✅ 自适应搜索空间调整
- ✅ 连续无改进自动扩大搜索范围

## 使用方法

### 基本用法

```bash
# 使用默认设置（目标82%，无限循环直到达标）
python scripts/auto_evolve.py

# 自定义目标准确率
python scripts/auto_evolve.py --target 85.0

# 限制最大迭代次数（用于测试）
python scripts/auto_evolve.py --target 80.0 --max-iter 5

# 自定义每次迭代的试验数
python scripts/auto_evolve.py --target 82.0 --trials 500
```

### 参数说明

- `--target`: 目标总准确率（默认: 82.0%）
- `--max-iter`: 最大迭代次数（默认: 0 = 无限循环直到达标）
- `--trials`: 每次迭代的试验次数（默认: 300，实际使用 train_model_optuna.py 的循环配置）

## 工作原理

### 1. 自动诊断

脚本会自动运行 `batch_verify.py`，解析准确率结果：
- 总准确率
- Strong 准确率
- Balanced 准确率
- Weak 准确率

### 2. 动态权重调整（V50.0 改进）

使用更激进的动态公式：
```
weight = base_weight * (1.0 + (1.0 - accuracy) * 5.0)
```

这意味着：
- **准确率 50%**: 权重提升 2.5倍
- **准确率 70%**: 权重提升 1.5倍
- **准确率 90%**: 权重接近基础值

准确率越低，权重越高，迫使优化器专注于短板。

### 3. 参数范围扩展

自动检测哪些参数触顶（接近上限），并扩大其搜索范围：
- `rootingWeight`: 上限可扩大到 30.0
- `controlImpact`: 上限可扩大到 15.0
- `earthMetalMoistureBoost`: 上限可扩大到 25.0

### 4. 自动迭代

循环执行以下步骤直到达到目标准确率或达到最大迭代次数：
1. 更新权重配置到 `train_model_optuna.py`
2. 运行训练（调用 `train_model_optuna.py`）
3. 运行验证（调用 `batch_verify.py`）
4. 诊断和调整策略
5. 重复

## 输出示例

```
🤖 Antigravity 自动进化元优化器 (V1.0)
   Auto-Evolution Meta-Optimizer
================================================================================

🎯 目标准确率: 75.0%
🔄 最大迭代次数: 10
🔬 每次迭代试验数: 200

================================================================================
🔄 迭代 1/10
================================================================================

📝 步骤1: 更新训练配置...
   📋 当前权重配置:
      Strong: 1.0
      Weak: 4.0
      Balanced: 4.0

   ✅ 已更新 train_model_optuna.py 中的权重配置

🔬 步骤2: 运行 Optuna 训练...
   ✅ 训练完成

📊 步骤3: 运行批量验证...
   📈 准确率结果:
      总准确率: 72.7%
      Strong: 72.7%
      Balanced: 72.7%
      Weak: 72.7%

🔍 步骤4: 诊断短板并调整策略...
   🔍 诊断结果: Strong 准确率最低 (72.7%)
   ⬇️  Strong 权重降低至 0.9
```

## 注意事项

### 1. 修改 train_model_optuna.py

脚本会**直接修改** `scripts/train_model_optuna.py` 中的权重配置。建议：
- 使用版本控制（Git）来跟踪更改
- 或者在运行前备份文件

### 2. 参数范围扩展

目前参数范围扩展功能**仅检测和打印提示**，不会自动修改 `train_model_optuna.py` 中的参数范围。如果需要自动修改，可以：
- 手动修改 `train_model_optuna.py` 中的参数范围
- 或者增强脚本以支持自动修改（需要更复杂的代码解析）

### 3. 运行时间

每次迭代需要运行完整的训练和验证流程，可能需要较长时间。建议：
- 在后台运行（使用 `nohup` 或 `screen`）
- 或者降低 `--trials` 参数以加快速度

## 未来改进方向

1. **自动参数范围修改**: 自动修改 `train_model_optuna.py` 中的参数范围
2. **并行训练**: 支持多进程并行训练
3. **早停机制**: 如果连续N次迭代没有改进，自动停止
4. **结果可视化**: 生成准确率变化图表
5. **配置导出**: 自动导出每轮的最佳配置到独立文件

## 与方案二、方案三的对比

- **方案一（本脚本）**: 
  - ✅ 无需安装新工具
  - ✅ 完全自动化
  - ⚠️ 需要修改训练脚本（但可版本控制）

- **方案二（Aider/OpenInterpreter）**: 
  - ✅ 更智能，可以处理更复杂的逻辑
  - ✅ 可以自动修复代码错误
  - ⚠️ 需要安装和学习新工具

- **方案三（Cursor Composer Agent）**: 
  - ✅ 利用现有工具
  - ✅ 可视化界面
  - ⚠️ 需要手动确认步骤

## 总结

`auto_evolve.py` 是打破"人肉中继器"循环的第一步。它可以在您睡觉时自动运行，醒来时获得最优配置。结合版本控制，这是一个安全且高效的自动化方案。

