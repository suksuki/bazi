import json
import os
import math

# ==========================================
# D-02 Step 4: Singularity Audit (The Spectrum)
# ==========================================

UNIVERSE_FILE = "core/data/holographic_universe_518k.jsonl"
OUTPUT_AUDIT_FILE = "core/subjects/holographic_pattern/mining_cache/d02_step4_singularities.json"

print(f"ğŸŒŠ [Step 4 START] Splitting the D-02 Spectrum...")

# å®šä¹‰èšç±»å®¹å™¨
clusters = {
    "SP_D02_STANDARD": {"samples": [], "sum_tensor": {k:0.0 for k in "EOMSR"}},
    "SP_D02_SYNDICATE": {"samples": [], "sum_tensor": {k:0.0 for k in "EOMSR"}},
    "SP_D02_COLLIDER": {"samples": [], "sum_tensor": {k:0.0 for k in "EOMSR"}}
}

scanned_count = 0

with open(UNIVERSE_FILE, 'r', encoding='utf-8') as f:
    for line in f:
        try:
            row = json.loads(line)
            if "tensor" not in row: continue
        except:
            continue
            
        scanned_count += 1
        t = row['tensor']
        y = row.get('y_true', 0)
        
        # 1. åŸºç¡€ D-02 é—¨æ§› (èº«æ—ºè´¢æ—º)
        if t['M'] < 0.55 or t['E'] < 0.45:
            continue
            
        # 2. åªæœ‰æˆåŠŸè€…æ‰æœ‰èµ„æ ¼å®šä¹‰æ ¼å±€
        if y < 0.75:
            continue
            
        # 3. å…‰è°±åˆ†ç¦» (Spectral Separation)
        
        # Priority A: Collider (High S) - é£é™©æœ€é«˜ï¼Œç‰¹å¾æœ€æ˜æ˜¾
        if t['S'] > 0.55:
            target = "SP_D02_COLLIDER"
            
        # Priority B: Syndicate (High R) - ä¼—ç­¹è´¢å›¢
        elif t['R'] > 0.55:
            target = "SP_D02_SYNDICATE"
            
        # Priority C: Standard (Balanced) - ä¼ ç»Ÿå¤§é³„
        else:
            target = "SP_D02_STANDARD"
            
        # 4. å½’ä»“
        clusters[target]["samples"].append(t)
        for k in "EOMSR":
            clusters[target]["sum_tensor"][k] += t[k]

print(f"âš¡ Spectrum Analysis Complete. Scanned {scanned_count} entities.")

# è®¡ç®—å„ç°‡çš„å‡å€¼å‘é‡ (Manifold Centers)
output_clusters = {}

for pid, data in clusters.items():
    count = len(data["samples"])
    if count < 30:
        print(f"âš ï¸  Cluster {pid} too small ({count}), discarding.")
        continue
        
    mean_vector = {k: v / count for k, v in data["sum_tensor"].items()}
    
    print(f"ğŸ§© {pid}:")
    print(f"   - Count: {count}")
    print(f"   - Mean R: {mean_vector['R']:.4f}")
    print(f"   - Mean S: {mean_vector['S']:.4f}")
    print(f"   - Mean M: {mean_vector['M']:.4f}")

    output_clusters[pid] = {
        "name": pid,
        "count": count,
        "manifold_data": {
            "mean_vector": mean_vector
            # ç®€åŒ–ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾åæ–¹å·®çŸ©é˜µä½¿ç”¨ Step 3 çš„å…¨å±€çŸ©é˜µ
            # åœ¨ Step 5 å°è£…æ—¶ï¼Œæˆ‘ä»¬ä¼šå¤ç”¨å…¨å±€åæ–¹å·®ï¼Œä½†åœ¨è·¯ç”±æ—¶ä½¿ç”¨è¿™äº›ç‰¹å®šçš„ Mean å‘é‡
        }
    }

# ç‰©ç†å†™å…¥
output_data = {
    "pattern_id": "D-02",
    "step": "Step 4 - Singularity Audit",
    "clusters": output_clusters
}

os.makedirs(os.path.dirname(OUTPUT_AUDIT_FILE), exist_ok=True)
with open(OUTPUT_AUDIT_FILE, 'w', encoding='utf-8') as f:
    json.dump(output_data, f, indent=2)

print(f"ğŸ’¾ Spectrum Registered: {OUTPUT_AUDIT_FILE}")
