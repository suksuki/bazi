#!/usr/bin/env python3
"""
V11.1 Agentic Optimizer - æ™ºèƒ½ä½“è‡ªåŠ¨ä¼˜åŒ–å·¥ä½œæµ
==============================================

å®ç°"è§‚å¯Ÿ-æ€è€ƒ-è¡ŒåŠ¨"å¾ªç¯ï¼Œè‡ªåŠ¨ä¼˜åŒ–SVMæ¨¡å‹ï¼š

1. è§‚å¯Ÿï¼ˆObserveï¼‰ï¼šè¯»å–è®­ç»ƒç»“æœï¼Œåˆ†ææ€§èƒ½æŒ‡æ ‡
2. æ€è€ƒï¼ˆThinkï¼‰ï¼šè¯Šæ–­é—®é¢˜ï¼Œè¯†åˆ«æ”¹è¿›æ–¹å‘
3. è¡ŒåŠ¨ï¼ˆActï¼‰ï¼šè‡ªåŠ¨è°ƒæ•´å‚æ•°æˆ–ç­–ç•¥
4. å¾ªç¯ï¼ˆLoopï¼‰ï¼šé‡æ–°è®­ç»ƒå¹¶è¯„ä¼°ï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡

ä½¿ç”¨æ–¹æ³•ï¼š
    python3 scripts/v11_1_agentic_optimizer.py --max_iterations 5 --target_accuracy 65
"""

import argparse
import sys
import json
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import subprocess

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class V11AgenticOptimizer:
    """V11.1 æ™ºèƒ½ä½“ä¼˜åŒ–å™¨"""
    
    def __init__(self, target_accuracy: float = 65.0):
        self.target_accuracy = target_accuracy
        self.iteration = 0
        self.history: List[Dict[str, Any]] = []
        self.config_file = project_root / "config" / "v11_agentic_config.json"
        
        # å¯è°ƒå‚æ•°
        self.config = self._load_config()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
        if self.config_file.exists():
            existing_config = json.load(open(self.config_file, 'r', encoding='utf-8'))
            # V11.2: å¦‚æœç°æœ‰é…ç½®çš„classic_weightè¿‡é«˜ï¼Œå¼ºåˆ¶é‡ç½®ä¸º2.0
            if existing_config.get('classic_weight', 3.0) > 2.5:
                logger.info("ğŸ”„ V11.2: æ£€æµ‹åˆ°classic_weightè¿‡é«˜ï¼Œé‡ç½®ä¸º2.0ä»¥ç¼“è§£è¿‡æ‹Ÿåˆ")
                existing_config['classic_weight'] = 2.0
            # V11.2: å¼ºåˆ¶å¼€å¯SMOTE
            if not existing_config.get('use_smote', True):
                logger.info("ğŸ”„ V11.2: å¼ºåˆ¶å¼€å¯SMOTE")
                existing_config['use_smote'] = True
            # V11.2: ç¡®ä¿æœ‰test_random_state
            if 'test_random_state' not in existing_config:
                existing_config['test_random_state'] = 100
            # V11.2: ç¡®ä¿æœ‰GridSearchå‚æ•°èŒƒå›´
            if 'gridsearch_c_range' not in existing_config:
                existing_config['gridsearch_c_range'] = [0.01, 0.1, 1.0]
            if 'gridsearch_gamma_range' not in existing_config:
                existing_config['gridsearch_gamma_range'] = ['scale', 'auto', 0.1, 0.01]
            return existing_config
        
        # é»˜è®¤é…ç½®ï¼ˆV11.2ä¼˜åŒ–ï¼‰
        return {
            'use_smote': True,  # V11.2: å¼ºåˆ¶å¼€å¯SMOTE
            'smote_target_ratio': 0.4,
            'use_gridsearch': True,
            'classic_weight': 2.0,  # V11.2: é™ä½æƒé‡ï¼Œä»4.0é™å›2.0ï¼Œé¿å…è¿‡æ‹Ÿåˆ
            'synthetic_weight': 2.0,
            'modern_weight': 1.0,
            'synthetic_count': 300,  # V11.8: å¤§è§„æ¨¡å¢å…µï¼Œä»50æå‡åˆ°300
            'use_dynamic_cleaning': True,
            'confidence_threshold': 0.90,
            'test_random_state': 100,  # V11.2: æ›´æ¢random_stateï¼Œé‡æ–°åˆ’åˆ†æµ‹è¯•é›†
            'gridsearch_c_range': [0.01, 0.1, 1.0],  # V11.2: é‡ç‚¹æœç´¢å°Cå€¼ï¼ˆæ­£åˆ™åŒ–ï¼‰
            'gridsearch_gamma_range': ['scale', 'auto', 0.1, 0.01]  # V11.2: æ‰©å¤§gammaæœç´¢èŒƒå›´
        }
    
    def _save_config(self):
        """ä¿å­˜é…ç½®"""
        self.config_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
    
    def observe(self) -> Dict[str, Any]:
        """
        è§‚å¯Ÿï¼šè¿è¡Œè®­ç»ƒå¹¶æ”¶é›†ç»“æœ
        
        Returns:
            åŒ…å«è®­ç»ƒç»“æœçš„å­—å…¸
        """
        logger.info(f"ğŸ” [è§‚å¯Ÿ] å¼€å§‹ç¬¬ {self.iteration + 1} æ¬¡è®­ç»ƒ...")
        
        # è¿è¡Œè®­ç»ƒè„šæœ¬ï¼ˆéœ€è¦ä¿®æ”¹v11_svm_trainer.pyæ”¯æŒé…ç½®å‚æ•°ï¼‰
        # è¿™é‡Œæˆ‘ä»¬ç›´æ¥è¿è¡Œå¹¶è§£æè¾“å‡º
        try:
            result = subprocess.run(
                ['python3', str(project_root / 'scripts' / 'v11_svm_trainer.py')],
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            # è§£æè¾“å‡ºï¼ˆæ—¥å¿—å¯èƒ½è¾“å‡ºåˆ°stderrï¼Œæ‰€ä»¥åˆå¹¶stdoutå’Œstderrï¼‰
            output = result.stdout + result.stderr
            
            # æå–å…³é”®æŒ‡æ ‡ï¼ˆä»è¾“å‡ºä¸­è§£æï¼‰
            metrics = self._parse_training_output(output)
            
            logger.info(f"   âœ… è®­ç»ƒå®Œæˆ")
            logger.info(f"   - è®­ç»ƒé›†å‡†ç¡®ç‡: {metrics.get('train_score', 0):.2%}")
            logger.info(f"   - æµ‹è¯•é›†å‡†ç¡®ç‡: {metrics.get('test_score', 0):.2%}")
            logger.info(f"   - äº¤å‰éªŒè¯å‡†ç¡®ç‡: {metrics.get('cv_mean', 0):.2%}")
            
            return {
                'metrics': metrics,
                'output': output,
                'error': result.stderr if hasattr(result, 'stderr') else '',
                'success': result.returncode == 0 and len(metrics) > 0
            }
        
        except subprocess.TimeoutExpired:
            logger.error("   âŒ è®­ç»ƒè¶…æ—¶")
            return {'success': False, 'error': 'timeout'}
        except Exception as e:
            logger.error(f"   âŒ è®­ç»ƒå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def _parse_training_output(self, output: str) -> Dict[str, float]:
        """
        ä»è®­ç»ƒè¾“å‡ºä¸­è§£æå…³é”®æŒ‡æ ‡ï¼ˆä½¿ç”¨å¢å¼ºçš„æ­£åˆ™è¡¨è¾¾å¼ï¼‰
        
        æ”¯æŒå¤šç§æ ¼å¼ï¼š
        - ç™¾åˆ†æ¯”æ ¼å¼: "è®­ç»ƒé›†å‡†ç¡®ç‡: 62.90%"
        - å°æ•°æ ¼å¼: "train_score: 0.629"
        - å¸¦æ‹¬å·æ ¼å¼: "äº¤å‰éªŒè¯å‡†ç¡®ç‡: 55.95% (Â±6.83%)"
        """
        import re
        metrics = {}
        
        # DEBUG: æ‰“å°æœ€å200ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
        if len(output) > 200:
            debug_output = output[-500:]  # å–æœ€å500å­—ç¬¦
            logger.debug(f"DEBUG: è§£æè¾“å‡ºæœ«å°¾å†…å®¹:\n{debug_output}")
        
        try:
            # æ¨¡å¼1: ç™¾åˆ†æ¯”æ ¼å¼ "è®­ç»ƒé›†å‡†ç¡®ç‡: 62.90%"
            train_match = re.search(r'è®­ç»ƒé›†å‡†ç¡®ç‡[ï¼š:]\s*([\d.]+)%', output)
            if train_match:
                metrics['train_score'] = float(train_match.group(1)) / 100.0
                logger.debug(f"è§£æè®­ç»ƒé›†å‡†ç¡®ç‡ï¼ˆç™¾åˆ†æ¯”æ ¼å¼ï¼‰: {metrics['train_score']:.4f}")
            else:
                # æ¨¡å¼2: å°æ•°æ ¼å¼ "train_score: 0.629" æˆ– "Training Accuracy: 0.629"
                train_match_dec = re.search(r'(?:train_score|è®­ç»ƒé›†å‡†ç¡®ç‡|Training Accuracy)[ï¼š:]\s*0?\.?(\d+)', output)
                if train_match_dec:
                    value_str = '0.' + train_match_dec.group(1) if '.' not in train_match_dec.group(0) else train_match_dec.group(0).split(':')[-1].strip()
                    metrics['train_score'] = float(value_str)
                    logger.debug(f"è§£æè®­ç»ƒé›†å‡†ç¡®ç‡ï¼ˆå°æ•°æ ¼å¼ï¼‰: {metrics['train_score']:.4f}")
            
            # æ¨¡å¼1: ç™¾åˆ†æ¯”æ ¼å¼ "æµ‹è¯•é›†å‡†ç¡®ç‡: 33.33%"
            test_match = re.search(r'æµ‹è¯•é›†å‡†ç¡®ç‡[ï¼š:]\s*([\d.]+)%', output)
            if test_match:
                metrics['test_score'] = float(test_match.group(1)) / 100.0
                logger.debug(f"è§£ææµ‹è¯•é›†å‡†ç¡®ç‡ï¼ˆç™¾åˆ†æ¯”æ ¼å¼ï¼‰: {metrics['test_score']:.4f}")
            else:
                # æ¨¡å¼2: å°æ•°æ ¼å¼
                test_match_dec = re.search(r'(?:test_score|æµ‹è¯•é›†å‡†ç¡®ç‡|Test Accuracy)[ï¼š:]\s*0?\.?(\d+)', output)
                if test_match_dec:
                    value_str = '0.' + test_match_dec.group(1) if '.' not in test_match_dec.group(0) else test_match_dec.group(0).split(':')[-1].strip()
                    metrics['test_score'] = float(value_str)
                    logger.debug(f"è§£ææµ‹è¯•é›†å‡†ç¡®ç‡ï¼ˆå°æ•°æ ¼å¼ï¼‰: {metrics['test_score']:.4f}")
            
            # äº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼ˆä¼˜å…ˆåŒ¹é…å¸¦Â±çš„å®Œæ•´æ ¼å¼ï¼‰
            cv_match = re.search(r'äº¤å‰éªŒè¯å‡†ç¡®ç‡[ï¼š:]\s*([\d.]+)%\s*[ï¼ˆ(]Â±\s*([\d.]+)%[ï¼‰)]', output)
            if cv_match:
                metrics['cv_mean'] = float(cv_match.group(1)) / 100.0
                metrics['cv_std'] = float(cv_match.group(2)) / 100.0
                logger.debug(f"è§£æäº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼ˆå®Œæ•´æ ¼å¼ï¼‰: {metrics['cv_mean']:.4f} Â± {metrics['cv_std']:.4f}")
            else:
                # æ¨¡å¼2: åªæœ‰ç™¾åˆ†æ¯” "äº¤å‰éªŒè¯å‡†ç¡®ç‡: 55.95%"
                cv_simple_match = re.search(r'äº¤å‰éªŒè¯å‡†ç¡®ç‡[ï¼š:]\s*([\d.]+)%', output)
                if cv_simple_match:
                    metrics['cv_mean'] = float(cv_simple_match.group(1)) / 100.0
                    logger.debug(f"è§£æäº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼ˆç®€å•æ ¼å¼ï¼‰: {metrics['cv_mean']:.4f}")
                else:
                    # æ¨¡å¼3: å°æ•°æ ¼å¼
                    cv_dec_match = re.search(r'(?:cv_mean|cv_score|äº¤å‰éªŒè¯å‡†ç¡®ç‡|Cross Validation)[ï¼š:]\s*0?\.?(\d+)', output)
                    if cv_dec_match:
                        value_str = '0.' + cv_dec_match.group(1) if '.' not in cv_dec_match.group(0) else cv_dec_match.group(0).split(':')[-1].strip()
                        metrics['cv_mean'] = float(value_str)
                        logger.debug(f"è§£æäº¤å‰éªŒè¯å‡†ç¡®ç‡ï¼ˆå°æ•°æ ¼å¼ï¼‰: {metrics['cv_mean']:.4f}")
            
            # æœ€ä½³äº¤å‰éªŒè¯åˆ†æ•°
            best_cv_match = re.search(r'æœ€ä½³CVåˆ†æ•°[ï¼š:]\s*([\d.]+)%', output)
            if best_cv_match:
                metrics['best_cv_score'] = float(best_cv_match.group(1)) / 100.0
                logger.debug(f"è§£ææœ€ä½³CVåˆ†æ•°: {metrics['best_cv_score']:.4f}")
            else:
                # å°æ•°æ ¼å¼
                best_cv_dec_match = re.search(r'(?:best_cv_score|æœ€ä½³CVåˆ†æ•°)[ï¼š:]\s*0?\.?(\d+)', output)
                if best_cv_dec_match:
                    value_str = '0.' + best_cv_dec_match.group(1) if '.' not in best_cv_dec_match.group(0) else best_cv_dec_match.group(0).split(':')[-1].strip()
                    metrics['best_cv_score'] = float(value_str)
                    logger.debug(f"è§£ææœ€ä½³CVåˆ†æ•°ï¼ˆå°æ•°æ ¼å¼ï¼‰: {metrics['best_cv_score']:.4f}")
            
            # éªŒè¯è§£æç»“æœ
            if len(metrics) == 0:
                logger.warning("âš ï¸  æœªèƒ½è§£æåˆ°ä»»ä½•æŒ‡æ ‡ï¼")
                logger.warning(f"DEBUG: è¾“å‡ºæœ€å500å­—ç¬¦:\n{output[-500:]}")
            else:
                logger.debug(f"âœ… æˆåŠŸè§£æ {len(metrics)} ä¸ªæŒ‡æ ‡: {list(metrics.keys())}")
        
        except Exception as e:
            logger.error(f"âŒ è§£æè¾“å‡ºæ—¶å‡ºé”™: {e}")
            logger.error(f"DEBUG: é”™è¯¯å‘ç”Ÿæ—¶çš„è¾“å‡ºæœ«å°¾:\n{output[-500:]}")
            import traceback
            logger.debug(traceback.format_exc())
        
        return metrics
    
    def think(self, observation: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ€è€ƒï¼šåˆ†æç»“æœï¼Œè¯Šæ–­é—®é¢˜
        
        Args:
            observation: è§‚å¯Ÿç»“æœ
        
        Returns:
            è¯Šæ–­ç»“æœå’Œå»ºè®®
        """
        logger.info("ğŸ§  [æ€è€ƒ] åˆ†æè®­ç»ƒç»“æœ...")
        
        if not observation.get('success'):
            return {
                'status': 'error',
                'issues': ['è®­ç»ƒå¤±è´¥'],
                'recommendations': ['æ£€æŸ¥è®­ç»ƒè„šæœ¬å’Œä¾èµ–']
            }
        
        metrics = observation.get('metrics', {})
        cv_mean = metrics.get('cv_mean', 0.0)
        test_score = metrics.get('test_score', 0.0)
        train_score = metrics.get('train_score', 0.0)
        
        issues = []
        recommendations = []
        
        # è¯Šæ–­1: æµ‹è¯•é›†å‡†ç¡®ç‡è¿‡ä½
        if test_score < 0.40:
            issues.append(f"æµ‹è¯•é›†å‡†ç¡®ç‡è¿‡ä½ ({test_score:.2%})")
            recommendations.append("é™ä½SMOTEå¼ºåº¦æˆ–ç¦ç”¨SMOTE")
            recommendations.append("å¢åŠ æµ‹è¯•é›†æ ·æœ¬é‡")
            recommendations.append("æ£€æŸ¥æ•°æ®åˆ†å¸ƒæ˜¯å¦åˆç†")
            # V11.7.1: å¦‚æœæ•°æ®é‡å¤ªå°ï¼Œå»ºè®®è°ƒæ•´å†²çªæ¸…æ´—ç­–ç•¥
            if 'æ•°æ®é‡' in str(observation.get('output', '')) or 'æ¸…æ´—åæ¡ˆä¾‹æ•°' in str(observation.get('output', '')):
                recommendations.append("è°ƒæ•´å†²çªæ¸…æ´—ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä»0.95æå‡åˆ°0.98ï¼‰")
                recommendations.append("ä¼˜åŒ–Modern vs Modernæ¸…æ´—ç­–ç•¥ï¼ˆä¸è¦å…¨éƒ¨åˆ é™¤ï¼‰")
        
        # è¯Šæ–­2: è¿‡æ‹Ÿåˆï¼ˆè®­ç»ƒé›†é«˜ä½†æµ‹è¯•é›†ä½ï¼‰
        if train_score - test_score > 0.20:
            issues.append(f"è¿‡æ‹Ÿåˆä¸¥é‡ (è®­ç»ƒ: {train_score:.2%}, æµ‹è¯•: {test_score:.2%})")
            recommendations.append("é™ä½SMOTEå¼ºåº¦")
            recommendations.append("å‡å°‘åˆæˆæ•°æ®æ•°é‡")
            recommendations.append("å¢åŠ æ­£åˆ™åŒ–ï¼ˆé™ä½Cå‚æ•°ï¼‰")
        
        # è¯Šæ–­3: äº¤å‰éªŒè¯å‡†ç¡®ç‡ä½äºç›®æ ‡
        if cv_mean < self.target_accuracy / 100.0:
            issues.append(f"äº¤å‰éªŒè¯å‡†ç¡®ç‡ä½äºç›®æ ‡ ({cv_mean:.2%} < {self.target_accuracy/100.0:.2%})")
            
            if cv_mean < 0.50:
                recommendations.append("å¢åŠ åˆæˆæ•°æ®æ•°é‡ï¼ˆç‰¹åˆ«é’ˆå¯¹å°‘æ•°ç±»åˆ«ï¼‰")
                recommendations.append("è°ƒæ•´æ ·æœ¬æƒé‡ï¼ˆæé«˜Classicæƒé‡ï¼‰")
            elif cv_mean < 0.55:
                recommendations.append("ä¼˜åŒ–GridSearchå‚æ•°èŒƒå›´")
                recommendations.append("å¢åŠ SMOTEç›®æ ‡æ¯”ä¾‹")
        
        # è¯Šæ–­4: è®­ç»ƒé›†å‡†ç¡®ç‡è¿‡ä½
        if train_score < 0.50:
            issues.append(f"è®­ç»ƒé›†å‡†ç¡®ç‡è¿‡ä½ ({train_score:.2%})")
            recommendations.append("æ£€æŸ¥ç‰¹å¾å·¥ç¨‹")
            recommendations.append("å¢åŠ è®­ç»ƒæ•°æ®")
        
        if not issues:
            issues.append("æ€§èƒ½è‰¯å¥½ï¼Œæ— éœ€è°ƒæ•´")
        
        logger.info(f"   ğŸ“Š è¯Šæ–­ç»“æœ:")
        logger.info(f"      - è¯†åˆ«åˆ° {len(issues)} ä¸ªé—®é¢˜")
        logger.info(f"      - æå‡º {len(recommendations)} æ¡å»ºè®®")
        
        # V11.2: ä»¥æµ‹è¯•é›†å‡†ç¡®ç‡ä¸ºä¸»è¦åˆ¤æ–­æ ‡å‡†ï¼ˆè€ŒéCVï¼‰
        # åªæœ‰å½“æµ‹è¯•é›†å‡†ç¡®ç‡è¾¾æ ‡ï¼Œä¸”è¿‡æ‹Ÿåˆä¸ä¸¥é‡æ—¶ï¼Œæ‰è®¤ä¸º"ok"
        is_ok = (test_score >= self.target_accuracy / 100.0 and 
                 train_score - test_score < 0.15)  # è¿‡æ‹Ÿåˆå·®è·å°äº15%
        
        return {
            'status': 'ok' if is_ok else 'needs_improvement',
            'issues': issues,
            'recommendations': recommendations,
            'metrics': metrics
        }
    
    def act(self, diagnosis: Dict[str, Any]) -> bool:
        """
        è¡ŒåŠ¨ï¼šæ ¹æ®è¯Šæ–­ç»“æœè°ƒæ•´å‚æ•°
        
        Args:
            diagnosis: è¯Šæ–­ç»“æœ
        
        Returns:
            æ˜¯å¦è¿›è¡Œäº†è°ƒæ•´
        """
        if diagnosis.get('status') == 'ok':
            logger.info("âœ… [è¡ŒåŠ¨] æ€§èƒ½å·²è¾¾æ ‡ï¼Œæ— éœ€è°ƒæ•´")
            return False
        
        if diagnosis.get('status') == 'error':
            logger.warning("âš ï¸  [è¡ŒåŠ¨] è®­ç»ƒå¤±è´¥ï¼Œè·³è¿‡è°ƒæ•´")
            return False
        
        logger.info("ğŸ”§ [è¡ŒåŠ¨] æ ¹æ®è¯Šæ–­ç»“æœè°ƒæ•´å‚æ•°...")
        
        issues = diagnosis.get('issues', [])
        recommendations = diagnosis.get('recommendations', [])
        metrics = diagnosis.get('metrics', {})
        
        changes_made = []
        
        # è¡ŒåŠ¨1: V11.2 å¦‚æœè¿‡æ‹Ÿåˆï¼Œé™ä½SMOTEå¼ºåº¦ï¼ˆä½†ä¸ç¦ç”¨ï¼‰
        if 'è¿‡æ‹Ÿåˆ' in ' '.join(issues) or 'SMOTE' in ' '.join(recommendations):
            if 'é™ä½SMOTEå¼ºåº¦' in recommendations:
                current_ratio = self.config.get('smote_target_ratio', 0.4)
                new_ratio = max(0.2, current_ratio - 0.1)
                if new_ratio != current_ratio:
                    self.config['smote_target_ratio'] = new_ratio
                    changes_made.append(f"é™ä½SMOTEç›®æ ‡æ¯”ä¾‹: {current_ratio:.2f} -> {new_ratio:.2f}")
        
        # V11.2: å¼ºåˆ¶ä¿æŒSMOTEå¼€å¯
        if not self.config.get('use_smote', True):
            self.config['use_smote'] = True
            changes_made.append("å¼ºåˆ¶å¼€å¯SMOTEï¼ˆV11.2ç­–ç•¥ï¼‰")
        
        # è¡ŒåŠ¨2: å¦‚æœå‡†ç¡®ç‡ä½ï¼Œå¢åŠ åˆæˆæ•°æ®
        if 'å¢åŠ åˆæˆæ•°æ®' in ' '.join(recommendations):
            current_count = self.config.get('synthetic_count', 50)
            new_count = min(100, current_count + 10)
            self.config['synthetic_count'] = new_count
            changes_made.append(f"å¢åŠ åˆæˆæ•°æ®æ•°é‡: {current_count} -> {new_count}")
        
        # è¡ŒåŠ¨3: å¦‚æœå‡†ç¡®ç‡ä½ï¼Œæé«˜Classicæƒé‡
        if 'æé«˜Classicæƒé‡' in ' '.join(recommendations):
            current_weight = self.config.get('classic_weight', 3.0)
            new_weight = min(5.0, current_weight + 0.5)
            self.config['classic_weight'] = new_weight
            changes_made.append(f"æé«˜Classicæƒé‡: {current_weight:.1f} -> {new_weight:.1f}")
        
        # è¡ŒåŠ¨4: å¦‚æœè¿‡æ‹Ÿåˆï¼Œé™ä½åˆæˆæ•°æ®æ•°é‡
        if 'å‡å°‘åˆæˆæ•°æ®æ•°é‡' in ' '.join(recommendations):
            current_count = self.config.get('synthetic_count', 50)
            new_count = max(20, current_count - 10)
            self.config['synthetic_count'] = new_count
            changes_made.append(f"å‡å°‘åˆæˆæ•°æ®æ•°é‡: {current_count} -> {new_count}")
        
        # è¡ŒåŠ¨5: å¦‚æœæµ‹è¯•é›†å‡†ç¡®ç‡æä½ï¼Œç¦ç”¨SMOTE
        test_score = metrics.get('test_score', 0.0)
        if test_score < 0.30 and self.config.get('use_smote', True):
            self.config['use_smote'] = False
            changes_made.append("ç¦ç”¨SMOTEï¼ˆæµ‹è¯•é›†å‡†ç¡®ç‡è¿‡ä½ï¼‰")
        
        # è¡ŒåŠ¨6: V11.7.1 å¦‚æœæ•°æ®é‡å¤ªå°ï¼Œè°ƒæ•´å†²çªæ¸…æ´—ç­–ç•¥
        if 'è°ƒæ•´å†²çªæ¸…æ´—ç›¸ä¼¼åº¦é˜ˆå€¼' in ' '.join(recommendations):
            # æå‡ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå‡å°‘åˆ é™¤
            if 'conflict_similarity_threshold' not in self.config:
                self.config['conflict_similarity_threshold'] = 0.98  # ä»0.95æå‡åˆ°0.98
                changes_made.append("æå‡å†²çªæ¸…æ´—ç›¸ä¼¼åº¦é˜ˆå€¼: 0.95 -> 0.98ï¼ˆå‡å°‘åˆ é™¤ï¼‰")
            elif self.config.get('conflict_similarity_threshold', 0.95) < 0.98:
                self.config['conflict_similarity_threshold'] = 0.98
                changes_made.append("æå‡å†²çªæ¸…æ´—ç›¸ä¼¼åº¦é˜ˆå€¼: -> 0.98ï¼ˆå‡å°‘åˆ é™¤ï¼‰")
        
        # ä¿å­˜é…ç½®
        if changes_made:
            self._save_config()
            logger.info(f"   âœ… è¿›è¡Œäº† {len(changes_made)} é¡¹è°ƒæ•´:")
            for change in changes_made:
                logger.info(f"      - {change}")
            return True
        else:
            logger.info("   â„¹ï¸  æœªè¿›è¡Œä»»ä½•è°ƒæ•´")
            return False
    
    def run(self, max_iterations: int = 5):
        """
        è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–å¾ªç¯
        
        Args:
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        logger.info("=" * 80)
        logger.info("ğŸš€ V11.1 Agentic Optimizer å¯åŠ¨")
        logger.info("=" * 80)
        logger.info(f"ç›®æ ‡å‡†ç¡®ç‡: {self.target_accuracy:.1f}%")
        logger.info(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        logger.info("")
        
        for iteration in range(max_iterations):
            self.iteration = iteration
            logger.info(f"\n{'=' * 80}")
            logger.info(f"è¿­ä»£ {iteration + 1}/{max_iterations}")
            logger.info(f"{'=' * 80}\n")
            
            # è§‚å¯Ÿ
            observation = self.observe()
            if not observation.get('success'):
                logger.error("è®­ç»ƒå¤±è´¥ï¼Œåœæ­¢ä¼˜åŒ–")
                break
            
            # æ€è€ƒ
            diagnosis = self.think(observation)
            
            # è®°å½•å†å²
            history_entry = {
                'iteration': iteration + 1,
                'timestamp': datetime.now().isoformat(),
                'metrics': observation.get('metrics', {}),
                'diagnosis': diagnosis,
                'config': self.config.copy()
            }
            self.history.append(history_entry)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾æ ‡ï¼ˆV11.2: ä¼˜å…ˆçœ‹æµ‹è¯•é›†å‡†ç¡®ç‡ï¼Œè€ŒéCVï¼‰
            test_score = observation.get('metrics', {}).get('test_score', 0.0)
            cv_mean = observation.get('metrics', {}).get('cv_mean', 0.0)
            
            # V11.2: å¦‚æœæµ‹è¯•é›†å‡†ç¡®ç‡è¾¾åˆ°ç›®æ ‡ï¼Œæˆ–è€…CVå’Œæµ‹è¯•é›†éƒ½æ¥è¿‘ç›®æ ‡ï¼Œåˆ™åœæ­¢
            if test_score >= self.target_accuracy / 100.0:
                logger.info(f"\nğŸ‰ è¾¾æˆç›®æ ‡ï¼æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.2%} >= {self.target_accuracy/100.0:.2%}")
                break
            elif cv_mean >= self.target_accuracy / 100.0 and test_score >= (self.target_accuracy - 5) / 100.0:
                # CVè¾¾æ ‡ä¸”æµ‹è¯•é›†æ¥è¿‘ç›®æ ‡ï¼ˆå·®è·5%ä»¥å†…ï¼‰
                logger.info(f"\nâœ… æ¥è¿‘ç›®æ ‡ï¼šCV {cv_mean:.2%}ï¼Œæµ‹è¯•é›† {test_score:.2%}ï¼ˆå·®è· {(cv_mean - test_score):.2%}ï¼‰")
                # ç»§ç»­ä¼˜åŒ–ï¼Œä¸åœæ­¢
            
            # è¡ŒåŠ¨ï¼ˆæœ€åä¸€æ¬¡è¿­ä»£ä¸è°ƒæ•´ï¼‰
            if iteration < max_iterations - 1:
                changed = self.act(diagnosis)
                if not changed:
                    logger.info("æœªè¿›è¡Œä»»ä½•è°ƒæ•´ï¼Œåœæ­¢ä¼˜åŒ–")
                    break
            else:
                logger.info("æœ€åä¸€æ¬¡è¿­ä»£ï¼Œè·³è¿‡å‚æ•°è°ƒæ•´")
        
        # ä¿å­˜å†å²
        history_file = project_root / "logs" / f"v11_agentic_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        history_file.parent.mkdir(parents=True, exist_ok=True)
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\n{'=' * 80}")
        logger.info("ğŸ“Š ä¼˜åŒ–å†å²å·²ä¿å­˜åˆ°: " + str(history_file))
        logger.info(f"{'=' * 80}\n")
        
        # æ‰“å°æ€»ç»“
        self._print_summary()
    
    def _print_summary(self):
        """æ‰“å°ä¼˜åŒ–æ€»ç»“"""
        logger.info("ğŸ“ˆ ä¼˜åŒ–æ€»ç»“:")
        logger.info("")
        
        for entry in self.history:
            iteration = entry['iteration']
            metrics = entry['metrics']
            cv_mean = metrics.get('cv_mean', 0.0)
            test_score = metrics.get('test_score', 0.0)
            
            logger.info(f"  è¿­ä»£ {iteration}:")
            logger.info(f"    - äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_mean:.2%}")
            logger.info(f"    - æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.2%}")
            logger.info(f"    - è¯Šæ–­: {', '.join(entry['diagnosis'].get('issues', [])[:2])}")
            logger.info("")


def main():
    parser = argparse.ArgumentParser(description='V11.1 Agentic Optimizer')
    parser.add_argument('--max_iterations', type=int, default=5, help='æœ€å¤§è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--target_accuracy', type=float, default=65.0, help='ç›®æ ‡å‡†ç¡®ç‡(%)')
    
    args = parser.parse_args()
    
    optimizer = V11AgenticOptimizer(target_accuracy=args.target_accuracy)
    optimizer.run(max_iterations=args.max_iterations)


if __name__ == '__main__':
    main()

