#!/usr/bin/env python3
"""
FDS-V1.4 é‡æ–°æ‹Ÿåˆè„šæœ¬ï¼šA-03 ç¾Šåˆƒæ¶æ€ï¼ˆå¯¹é½V2.1è§„èŒƒï¼‰
ä½¿ç”¨æ–°çš„transfer_matrixé‡æ–°è®¡ç®—feature_anchorsï¼ˆè´¨å¿ƒï¼‰

é‡ç‚¹ï¼š
- Step 3: ä½¿ç”¨transfer_matrixè®¡ç®—5ç»´æŠ•å½±ï¼Œé‡æ–°è®¡ç®—è´¨å¿ƒ
- Step 5: æ›´æ–°feature_anchorsåˆ°æ³¨å†Œè¡¨
"""

import sys
from pathlib import Path
import json
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from controllers.holographic_pattern_controller import HolographicPatternController
from core.trinity.core.unified_arbitrator_master import QuantumUniversalFramework
from core.registry_loader import RegistryLoader
from core.math_engine import (
    calculate_centroid,
    tensor_normalize,
    project_tensor_with_matrix
)
from core.physics_engine import compute_energy_flux

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FDSV14RefitEngine:
    """
    FDS-V1.4 é‡æ–°æ‹Ÿåˆå¼•æ“ï¼ˆV2.1å¯¹é½ç‰ˆï¼‰
    ä½¿ç”¨transfer_matrixé‡æ–°è®¡ç®—è´¨å¿ƒ
    """
    
    def __init__(self, pattern_id: str = 'A-03'):
        self.pattern_id = pattern_id
        self.controller = HolographicPatternController()
        self.framework = QuantumUniversalFramework()
        self.registry_loader = RegistryLoader()
        self.pattern = self.controller.get_pattern_by_id(pattern_id)
        
        if not self.pattern:
            raise ValueError(f"æ ¼å±€ {pattern_id} ä¸å­˜åœ¨")
        
        logger.info(f"åˆå§‹åŒ–FDS-V1.4é‡æ–°æ‹Ÿåˆå¼•æ“: {pattern_id}")
    
    def load_fitting_data(self) -> Dict[str, Any]:
        """åŠ è½½ç°æœ‰æ‹Ÿåˆæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨Step 2å…¨é‡æµ·é€‰ç»“æœï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨Step 2å…¨é‡æµ·é€‰ç»“æœ
        step2_file = project_root / "data" / "holographic_pattern" / "A-03_Step2_FullScan_Results.json"
        if step2_file.exists():
            logger.info(f"åŠ è½½Step 2å…¨é‡æµ·é€‰ç»“æœ: {step2_file}")
            with open(step2_file, 'r', encoding='utf-8') as f:
                step2_data = json.load(f)
            
            # è½¬æ¢ä¸ºStep 3æ ¼å¼
            tier_a_samples = step2_data.get('tier_a_samples', [])
            tier_x_samples = step2_data.get('tier_x_samples', [])
            
            # æ„å»ºresultsæ ¼å¼ï¼ˆç”¨äºStep 3ï¼‰
            results = []
            for sample in tier_a_samples + tier_x_samples:
                results.append({
                    'chart': sample['chart'],
                    'day_master': sample['day_master'],
                    'purity_score': sample.get('purity_score', 0.0),
                    'singularity_protocol': sample.get('singularity_protocol', {})
                })
            
            return {
                'step3': {
                    'results': results
                }
            }
        
        # å›é€€åˆ°æ—§çš„æ‹Ÿåˆæ•°æ®
        fitting_file = project_root / "data" / "holographic_pattern" / "A-03_FDS_Fitting_Results.json"
        if fitting_file.exists():
            logger.info(f"åŠ è½½ç°æœ‰æ‹Ÿåˆæ•°æ®: {fitting_file}")
            with open(fitting_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            logger.warning("æœªæ‰¾åˆ°ç°æœ‰æ‹Ÿåˆæ•°æ®ï¼Œéœ€è¦é‡æ–°æ‰§è¡ŒStep 2")
            return {}
    
    def calculate_frequency_vector(self, chart: List[str], day_master: str) -> Dict[str, float]:
        """
        è®¡ç®—åç¥é¢‘ç‡å‘é‡ï¼ˆç”¨äºtransfer_matrixè¾“å…¥ï¼‰
        
        Returns:
            {"parallel": float, "resource": float, "power": float, "wealth": float, "output": float}
        """
        parallel = compute_energy_flux(chart, day_master, "æ¯”è‚©") + \
                   compute_energy_flux(chart, day_master, "åŠ«è´¢")
        resource = compute_energy_flux(chart, day_master, "æ­£å°") + \
                   compute_energy_flux(chart, day_master, "åå°")
        power = compute_energy_flux(chart, day_master, "ä¸ƒæ€") + \
                compute_energy_flux(chart, day_master, "æ­£å®˜")
        wealth = compute_energy_flux(chart, day_master, "æ­£è´¢") + \
                 compute_energy_flux(chart, day_master, "åè´¢")
        output = compute_energy_flux(chart, day_master, "é£Ÿç¥") + \
                 compute_energy_flux(chart, day_master, "ä¼¤å®˜")
        
        return {
            "parallel": parallel,
            "resource": resource,
            "power": power,
            "wealth": wealth,
            "output": output
        }
    
    def step3_calculate_centroids_with_matrix(
        self,
        fitting_data: Dict[str, Any],
        transfer_matrix: Dict[str, Dict[str, float]]
    ) -> Dict[str, Any]:
        """
        Step 3: ä½¿ç”¨transfer_matrixè®¡ç®—è´¨å¿ƒï¼ˆV2.1ï¼‰
        
        Args:
            fitting_data: ç°æœ‰æ‹Ÿåˆæ•°æ®ï¼ˆåŒ…å«step3.resultsï¼‰
            transfer_matrix: 5x5è½¬æ¢çŸ©é˜µ
            
        Returns:
            è´¨å¿ƒè®¡ç®—ç»“æœ
        """
        logger.info("=" * 70)
        logger.info("Step 3: ä½¿ç”¨transfer_matrixè®¡ç®—è´¨å¿ƒï¼ˆV2.1ï¼‰")
        logger.info("=" * 70)
        
        step3_data = fitting_data.get('step3', {})
        results = step3_data.get('results', [])
        
        if not results:
            raise ValueError("æœªæ‰¾åˆ°Step 3çš„æ‹Ÿåˆç»“æœï¼Œè¯·å…ˆæ‰§è¡ŒStep 2å’ŒStep 3")
        
        logger.info(f"å¤„ç† {len(results)} ä¸ªæ ·æœ¬...")
        
        # 1. æå–Tier Aå’ŒTier Xæ ·æœ¬
        tier_a_projections = []
        tier_x_projections = []
        
        for result in results:
            chart = result.get('chart', [])
            day_master = result.get('day_master', '')
            
            if not chart or not day_master:
                continue
            
            # è®¡ç®—åç¥é¢‘ç‡å‘é‡
            frequency_vector = self.calculate_frequency_vector(chart, day_master)
            
            # ä½¿ç”¨transfer_matrixè®¡ç®—5ç»´æŠ•å½±
            projection = project_tensor_with_matrix(frequency_vector, transfer_matrix)
            
            # å½’ä¸€åŒ–æŠ•å½±
            normalized_projection = tensor_normalize(projection)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºTier Xï¼ˆæ ¹æ®singularity_protocolï¼‰
            singularity_protocol = result.get('singularity_protocol', {})
            is_singularity = (
                singularity_protocol.get('law_of_extremum', False) or
                singularity_protocol.get('law_of_phase_change', False) or
                singularity_protocol.get('law_of_algorithm_failure', False)
            )
            
            if is_singularity:
                tier_x_projections.append(normalized_projection)
            else:
                tier_a_projections.append(normalized_projection)
        
        logger.info(f"Tier Aæ ·æœ¬æ•°: {len(tier_a_projections)}")
        logger.info(f"Tier Xæ ·æœ¬æ•°: {len(tier_x_projections)}")
        
        # 2. è®¡ç®—è´¨å¿ƒ
        standard_centroid = None
        singularity_centroids = []
        
        if tier_a_projections:
            standard_centroid = calculate_centroid(tier_a_projections)
            logger.info(f"Tier Aè´¨å¿ƒ: {standard_centroid}")
        
        if tier_x_projections:
            # æŒ‰sub_idåˆ†ç»„ï¼ˆå¦‚æœæœ‰ï¼‰
            tier_x_groups = {}
            tier_x_idx = 0  # Tier XæŠ•å½±çš„ç´¢å¼•
            
            for result in results:
                singularity_protocol = result.get('singularity_protocol', {})
                if (singularity_protocol.get('law_of_extremum', False) or
                    singularity_protocol.get('law_of_phase_change', False) or
                    singularity_protocol.get('law_of_algorithm_failure', False)):
                    sub_id = singularity_protocol.get('sub_id', 'X1')
                    if sub_id not in tier_x_groups:
                        tier_x_groups[sub_id] = []
                    
                    # ä½¿ç”¨tier_x_idxè€Œä¸æ˜¯resultsçš„ç´¢å¼•
                    if tier_x_idx < len(tier_x_projections):
                        tier_x_groups[sub_id].append(tier_x_projections[tier_x_idx])
                        tier_x_idx += 1
            
            # è®¡ç®—æ¯ä¸ªç»„çš„è´¨å¿ƒ
            for sub_id, projections in tier_x_groups.items():
                centroid = calculate_centroid(projections)
                singularity_centroids.append({
                    'sub_id': sub_id,
                    'vector': centroid,
                    'sample_count': len(projections)
                })
                logger.info(f"{sub_id}è´¨å¿ƒ: {centroid} (æ ·æœ¬æ•°: {len(projections)})")
        
        return {
            'standard_centroid': standard_centroid,
            'singularity_centroids': singularity_centroids,
            'tier_a_count': len(tier_a_projections),
            'tier_x_count': len(tier_x_projections)
        }
    
    def step5_update_registry(
        self,
        centroids: Dict[str, Any]
    ) -> bool:
        """
        Step 5: æ›´æ–°feature_anchorsåˆ°æ³¨å†Œè¡¨
        
        Args:
            centroids: è´¨å¿ƒè®¡ç®—ç»“æœ
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        logger.info("=" * 70)
        logger.info("Step 5: æ›´æ–°feature_anchorsåˆ°æ³¨å†Œè¡¨ï¼ˆV2.1ï¼‰")
        logger.info("=" * 70)
        
        registry_path = project_root / "core" / "subjects" / "holographic_pattern" / "registry.json"
        
        # è¯»å–æ³¨å†Œè¡¨
        with open(registry_path, 'r', encoding='utf-8') as f:
            registry = json.load(f)
        
        pattern = registry.get('patterns', {}).get(self.pattern_id)
        if not pattern:
            logger.error(f"æ ¼å±€ {self.pattern_id} ä¸å­˜åœ¨äºæ³¨å†Œè¡¨")
            return False
        
        # æ›´æ–°feature_anchors
        if 'feature_anchors' not in pattern:
            pattern['feature_anchors'] = {}
        
        # æ›´æ–°standard_centroid
        standard_centroid = centroids.get('standard_centroid')
        if standard_centroid:
            if 'standard_centroid' not in pattern['feature_anchors']:
                pattern['feature_anchors']['standard_centroid'] = {}
            
            pattern['feature_anchors']['standard_centroid']['vector'] = standard_centroid
            pattern['feature_anchors']['standard_centroid']['description'] = "æ ‡å‡†æ’æ˜Ÿé”šç‚¹ (Tier A Mean) - åŸºäºtransfer_matrixè®¡ç®—"
            logger.info(f"âœ… å·²æ›´æ–°standard_centroid: {standard_centroid}")
        
        # æ›´æ–°singularity_centroids
        singularity_centroids = centroids.get('singularity_centroids', [])
        if singularity_centroids:
            if 'singularity_centroids' not in pattern['feature_anchors']:
                pattern['feature_anchors']['singularity_centroids'] = []
            
            # æ›´æ–°ç°æœ‰çš„æˆ–æ·»åŠ æ–°çš„
            existing_subs = {s.get('sub_id'): s for s in pattern['feature_anchors'].get('singularity_centroids', [])}
            
            for new_centroid in singularity_centroids:
                sub_id = new_centroid['sub_id']
                if sub_id in existing_subs:
                    # æ›´æ–°ç°æœ‰
                    existing_subs[sub_id]['vector'] = new_centroid['vector']
                    existing_subs[sub_id]['sample_count'] = new_centroid['sample_count']
                    existing_subs[sub_id]['description'] = f"{sub_id}è´¨å¿ƒ - åŸºäºtransfer_matrixè®¡ç®—"
                else:
                    # æ·»åŠ æ–°çš„
                    existing_subs[sub_id] = {
                        'sub_id': sub_id,
                        'vector': new_centroid['vector'],
                        'sample_count': new_centroid['sample_count'],
                        'description': f"{sub_id}è´¨å¿ƒ - åŸºäºtransfer_matrixè®¡ç®—",
                        'match_threshold': 0.9,
                        'risk_level': 'CRITICAL'
                    }
            
            pattern['feature_anchors']['singularity_centroids'] = list(existing_subs.values())
            logger.info(f"âœ… å·²æ›´æ–°singularity_centroids: {len(singularity_centroids)}ä¸ª")
        
        # æ›´æ–°ç‰ˆæœ¬ä¿¡æ¯
        pattern['version'] = '2.1'
        pattern['updated_at'] = datetime.now().strftime('%Y-%m-%d')
        
        # ä¿å­˜æ³¨å†Œè¡¨
        with open(registry_path, 'w', encoding='utf-8') as f:
            json.dump(registry, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… æ³¨å†Œè¡¨å·²æ›´æ–°: {registry_path}")
        return True
    
    def run_refit(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„é‡æ–°æ‹Ÿåˆæµç¨‹"""
        logger.info("=" * 70)
        logger.info("ğŸš€ å¼€å§‹FDS-V1.4é‡æ–°æ‹Ÿåˆï¼šA-03 ç¾Šåˆƒæ¶æ€ï¼ˆV2.1ï¼‰")
        logger.info("=" * 70)
        
        # 1. åŠ è½½ç°æœ‰æ‹Ÿåˆæ•°æ®
        fitting_data = self.load_fitting_data()
        
        # 2. è·å–transfer_matrix
        physics_kernel = self.pattern.get('physics_kernel', {})
        transfer_matrix = physics_kernel.get('transfer_matrix')
        
        if not transfer_matrix:
            raise ValueError("æ ¼å±€ç¼ºå°‘transfer_matrixé…ç½®ï¼Œè¯·å…ˆå‡çº§åˆ°V2.1")
        
        logger.info("âœ… å·²åŠ è½½transfer_matrix")
        
        # 3. Step 3: ä½¿ç”¨transfer_matrixè®¡ç®—è´¨å¿ƒ
        centroids = self.step3_calculate_centroids_with_matrix(fitting_data, transfer_matrix)
        
        # 4. Step 5: æ›´æ–°æ³¨å†Œè¡¨
        success = self.step5_update_registry(centroids)
        
        if not success:
            raise RuntimeError("æ›´æ–°æ³¨å†Œè¡¨å¤±è´¥")
        
        # 5. ä¿å­˜ç»“æœ
        result = {
            'pattern_id': self.pattern_id,
            'refit_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'fds_version': 'V1.4',
            'registry_version': '2.1',
            'step3': centroids
        }
        
        output_file = project_root / "data" / "holographic_pattern" / "A-03_Refit_V21_Results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… ç»“æœå·²ä¿å­˜: {output_file}")
        
        return result


if __name__ == '__main__':
    try:
        engine = FDSV14RefitEngine('A-03')
        result = engine.run_refit()
        
        print("\n" + "=" * 70)
        print("âœ… FDS-V1.4é‡æ–°æ‹Ÿåˆå®Œæˆï¼")
        print("=" * 70)
        print(f"Tier Aè´¨å¿ƒ: {result['step3']['standard_centroid']}")
        print(f"Tier Xè´¨å¿ƒæ•°: {len(result['step3']['singularity_centroids'])}")
        print("=" * 70)
        
    except Exception as e:
        logger.error(f"é‡æ–°æ‹Ÿåˆå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)

