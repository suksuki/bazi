#!/usr/bin/env python3
"""
V10.2 è‡ªåŠ¨è°ƒä¼˜ç³»ç»Ÿï¼šOptuna + MCP Agentic Workflow
===================================================

æ ¸å¿ƒæ¶æ„ï¼š
- Optuna (TPE + Pruning): è´Ÿè´£å‚æ•°æœç´¢çš„"å¾®æ“"
- MCP Server: è´Ÿè´£ä¸LLM/Cursorçš„"å¯¹è¯"
- Agent Loop: å®ç°"è§‚å¯Ÿ-æ€è€ƒ-è¡ŒåŠ¨"çš„æ™ºèƒ½è°ƒä¼˜å¾ªç¯

ä½¿ç”¨æ–¹æ³•ï¼š
    # è‡ªåŠ¨è°ƒä¼˜ï¼ˆå®Œæ•´æµç¨‹ï¼‰
    python3 scripts/v10_2_optuna_tuner.py --mode auto
    
    # æŒ‡å®šå±‚è°ƒä¼˜
    python3 scripts/v10_2_optuna_tuner.py --mode tune --layer structure --trials 50
"""

import argparse
import json
import sys
import copy
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import random
from dataclasses import dataclass
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    import optuna
    from optuna.trial import Trial
    from optuna.pruners import MedianPruner
    from optuna.samplers import TPESampler
except ImportError:
    print("âŒ è¯·å®‰è£… optuna: pip install optuna")
    sys.exit(1)

from controllers.quantum_lab_controller import QuantumLabController
from core.config_schema import DEFAULT_FULL_ALGO_PARAMS
from scripts.strength_parameter_tuning import StrengthParameterTuner

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    focus_layer: str = "all"  # "physics" | "structure" | "threshold" | "all"
    constraints: str = "soft"  # "strict" | "soft"
    target_case_type: str = "all"  # "classic" | "modern" | "all"
    n_trials: int = 50
    timeout: Optional[float] = None  # ç§’
    pruner_enabled: bool = True
    verbose: bool = True
    # [V10.2 æ ¸å¿ƒåˆ†æå¸ˆå»ºè®®] äº¤å‰éªŒè¯é€‰é¡¹
    cross_validation: bool = False  # æ˜¯å¦å¯ç”¨äº¤å‰éªŒè¯
    cv_splits: int = 3  # äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    train_ratio: float = 0.7  # è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆå¦‚æœå¯ç”¨äº¤å‰éªŒè¯ï¼‰
    # ğŸ§ª å‹åŠ›æµ‹è¯•æ¨¡å¼ï¼ˆCross-Validationï¼‰
    use_cross_validation: bool = False  # æ˜¯å¦ä½¿ç”¨äº¤å‰éªŒè¯
    cv_train_ratio: float = 0.7  # è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆ0.7 = 70%è®­ç»ƒï¼Œ30%éªŒè¯ï¼‰


class StrengthOptimizationObjective:
    """
    Optunaä¼˜åŒ–ç›®æ ‡å‡½æ•°
    
    å®ç°ï¼š
    1. åŠ æƒæŸå¤±å‡½æ•°ï¼ˆç»å…¸æ¡ˆä¾‹3å€æƒé‡ï¼‰
    2. ç‰©ç†å¸¸è¯†è½¯æƒ©ç½šï¼ˆBayesian Prior Penaltyï¼‰
    3. åˆ†å±‚å‚æ•°ç©ºé—´å®šä¹‰
    """
    
    def __init__(self, 
                 tuner: StrengthParameterTuner,
                 config: OptimizationConfig,
                 base_config: Dict[str, Any]):
        self.tuner = tuner
        self.config = config
        self.base_config = copy.deepcopy(base_config)
        self.best_score = float('inf')
        self.best_trial = None
        
    def _calculate_bayesian_penalty(self, trial_config: Dict[str, Any]) -> float:
        """
        è®¡ç®—è´å¶æ–¯å…ˆéªŒæƒ©ç½šï¼ˆç‰©ç†å¸¸è¯†çº¦æŸï¼‰
        
        æƒ©ç½šé¡¹ï¼š
        1. hour_weight > month_weight: è¿åç‰©ç†ç›´è§‰
        2. structure.rootingWeight > 3.0: é€šæ ¹æƒé‡è¿‡é«˜
        3. structure.samePillarBonus > 2.5: åŒæŸ±åŠ æˆè¿‡é«˜
        
        Returns:
            penalty: æƒ©ç½šå€¼ï¼ˆè¶Šå¤§è¶Šå·®ï¼Œä¼šè¢«åŠ åˆ°lossä¸Šï¼‰
        """
        penalty = 0.0
        
        # 1. æ£€æŸ¥æœˆä»¤ä¸æ—¶æŸ±æƒé‡å…³ç³»
        pillar_weights = trial_config.get('physics', {}).get('pillarWeights', {})
        month_weight = pillar_weights.get('month', 1.2)
        hour_weight = pillar_weights.get('hour', 0.9)
        
        if hour_weight > month_weight:
            # è¿åç‰©ç†ç›´è§‰ï¼šæ—¶æŸ±æƒé‡å¤§äºæœˆä»¤
            violation = hour_weight - month_weight
            penalty += violation * 100.0  # æƒ©ç½šç³»æ•°
            if self.config.verbose:
                logger.warning(f"âš ï¸  ç‰©ç†çº¦æŸè¿å: hour_weight({hour_weight:.3f}) > month_weight({month_weight:.3f}), æƒ©ç½š: {penalty:.2f}")
        
        # 2. æ£€æŸ¥é€šæ ¹æƒé‡
        structure = trial_config.get('structure', {})
        rooting_weight = structure.get('rootingWeight', 1.2)
        if rooting_weight > 3.0:
            violation = rooting_weight - 3.0
            penalty += violation * 50.0
            
        # 3. æ£€æŸ¥åŒæŸ±åŠ æˆ
        same_pillar_bonus = structure.get('samePillarBonus', 1.6)
        if same_pillar_bonus > 2.5:
            violation = same_pillar_bonus - 2.5
            penalty += violation * 50.0
        
        return penalty
    
    def _calculate_weighted_loss(self, result: Dict[str, Any]) -> float:
        """
        è®¡ç®—åŠ æƒæŸå¤±å‡½æ•°
        
        æŸå¤± = 1 - åŠ æƒåŒ¹é…ç‡ + è´å¶æ–¯æƒ©ç½š
        
        Args:
            result: evaluate_parameter_setçš„è¿”å›ç»“æœ
            
        Returns:
            loss: æŸå¤±å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        """
        # åŠ æƒåŒ¹é…ç‡ï¼ˆå·²ç»è€ƒè™‘äº†æ¡ˆä¾‹æƒé‡ï¼‰
        weighted_match_rate = result.get('match_rate', 0.0) / 100.0  # è½¬æ¢ä¸º0-1
        
        # æŸå¤± = 1 - åŒ¹é…ç‡ï¼ˆåŒ¹é…ç‡è¶Šé«˜ï¼ŒæŸå¤±è¶Šå°ï¼‰
        base_loss = 1.0 - weighted_match_rate
        
        return base_loss
    
    def _setup_cross_validation(self):
        """
        ğŸ§ª è®¾ç½®äº¤å‰éªŒè¯ï¼ˆå‹åŠ›æµ‹è¯•æ¨¡å¼ï¼‰
        
        å°†æ¡ˆä¾‹éšæœºåˆ‡åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        """
        import random
        random.seed(42)  # å¯å¤ç°
        
        total_cases = len(self.tuner.cases)
        train_size = int(total_cases * self.config.cv_train_ratio)
        
        # éšæœºæ‰“ä¹±ç´¢å¼•
        indices = list(range(total_cases))
        random.shuffle(indices)
        
        # åˆ‡åˆ†
        self.cv_train_indices = indices[:train_size]
        self.cv_val_indices = indices[train_size:]
        
        logger.info(f"ğŸ§ª Cross-Validationè®¾ç½®: è®­ç»ƒé›†={len(self.cv_train_indices)}ä¸ª, éªŒè¯é›†={len(self.cv_val_indices)}ä¸ª")
    
    def __call__(self, trial: Trial) -> float:
        """
        Optunaç›®æ ‡å‡½æ•°
        
        Args:
            trial: Optunaè¯•éªŒå¯¹è±¡
            
        Returns:
            loss: æŸå¤±å€¼ï¼ˆOptunaä¼šæœ€å°åŒ–è¿™ä¸ªå€¼ï¼‰
        """
        # 1. æ ¹æ®focus_layerå»ºè®®å‚æ•°
        trial_config = self._suggest_parameters(trial)
        
        # 2. è¯„ä¼°å‚æ•°ç»„åˆ
        if self.config.use_cross_validation:
            # ğŸ§ª Cross-Validationæ¨¡å¼ï¼šåªåœ¨è®­ç»ƒé›†ä¸Šä¼˜åŒ–ï¼Œåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
            # ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼šå®é™…åº”è¯¥åœ¨tunerå±‚é¢æ”¯æŒsubsetè¯„ä¼°ï¼‰
            result = self.tuner.evaluate_parameter_set(trial_config)
            # TODO: æœªæ¥å¯ä»¥åœ¨tunerä¸­å®ç°subsetè¯„ä¼°ï¼ŒçœŸæ­£æ”¯æŒCV
        else:
            result = self.tuner.evaluate_parameter_set(trial_config)
        
        # 3. è®¡ç®—åŸºç¡€æŸå¤±ï¼ˆåŠ æƒåŒ¹é…ç‡ï¼‰
        base_loss = self._calculate_weighted_loss(result)
        
        # 4. è®¡ç®—è´å¶æ–¯æƒ©ç½šï¼ˆç‰©ç†çº¦æŸï¼‰
        if self.config.constraints == "soft":
            penalty = self._calculate_bayesian_penalty(trial_config)
        else:
            # strictæ¨¡å¼ï¼šè¿åç‰©ç†çº¦æŸç›´æ¥è¿”å›å·¨å¤§æŸå¤±
            penalty = self._calculate_bayesian_penalty(trial_config)
            if penalty > 0.1:  # æœ‰æ˜¾è‘—è¿å
                return 1e6  # è¿”å›å·¨å¤§æŸå¤±ï¼Œè®©Optunaé¿å¼€è¿™ä¸ªåŒºåŸŸ
        
        # 5. æ€»æŸå¤± = åŸºç¡€æŸå¤± + æƒ©ç½š
        total_loss = base_loss + penalty
        
        # 6. è®°å½•æœ€ä½³ç»“æœ
        if total_loss < self.best_score:
            self.best_score = total_loss
            self.best_trial = {
                'trial_number': trial.number,
                'config': copy.deepcopy(trial_config),
                'result': copy.deepcopy(result),
                'loss': total_loss,
                'base_loss': base_loss,
                'penalty': penalty
            }
            if self.config.verbose:
                match_rate = result.get('match_rate', 0.0)
                logger.info(f"ğŸ¯ Trial {trial.number}: åŒ¹é…ç‡={match_rate:.1f}%, Loss={total_loss:.4f} (base={base_loss:.4f}, penalty={penalty:.4f})")
        
        # 7. æŠ¥å‘Šä¸­é—´å€¼ï¼ˆç”¨äºPruningï¼‰
        trial.report(total_loss, step=0)
        
        # 8. æ£€æŸ¥æ˜¯å¦åº”è¯¥å‰ªæ
        if trial.should_prune():
            raise optuna.TrialPruned()
        
        return total_loss
    
    def _suggest_parameters(self, trial: Trial) -> Dict[str, Any]:
        """
        æ ¹æ®focus_layerå»ºè®®å‚æ•°ç©ºé—´
        
        Args:
            trial: Optunaè¯•éªŒå¯¹è±¡
            
        Returns:
            å‚æ•°é…ç½®å­—å…¸
        """
        config = copy.deepcopy(self.base_config)
        
        if self.config.focus_layer == "physics":
            # åªä¼˜åŒ–ç‰©ç†å±‚å‚æ•°
            config.setdefault('physics', {}).setdefault('pillarWeights', {})
            config['physics']['pillarWeights']['month'] = trial.suggest_float(
                'physics.pillarWeights.month', 1.0, 2.0, log=False
            )
            config['physics']['pillarWeights']['hour'] = trial.suggest_float(
                'physics.pillarWeights.hour', 0.5, 1.5, log=False
            )
            config['physics']['pillarWeights']['year'] = trial.suggest_float(
                'physics.pillarWeights.year', 0.5, 1.5, log=False
            )
            config['physics']['pillarWeights']['day'] = trial.suggest_float(
                'physics.pillarWeights.day', 0.5, 1.5, log=False
            )
            
        elif self.config.focus_layer == "structure":
            # åªä¼˜åŒ–ç»“æ„å±‚å‚æ•°
            config.setdefault('structure', {})
            config['structure']['rootingWeight'] = trial.suggest_float(
                'structure.rootingWeight', 0.8, 2.5, log=False
            )
            config['structure']['exposedBoost'] = trial.suggest_float(
                'structure.exposedBoost', 1.0, 2.5, log=False
            )
            config['structure']['samePillarBonus'] = trial.suggest_float(
                'structure.samePillarBonus', 1.0, 2.5, log=False
            )
            config['structure']['voidPenalty'] = trial.suggest_float(
                'structure.voidPenalty', 0.0, 1.0, log=False
            )
            
        elif self.config.focus_layer == "threshold":
            # åªä¼˜åŒ–é˜ˆå€¼å‚æ•°
            config.setdefault('strength', {})
            config['strength']['energy_threshold_center'] = trial.suggest_float(
                'strength.energy_threshold_center', 2.0, 5.0, log=False
            )
            config['strength']['phase_transition_width'] = trial.suggest_float(
                'strength.phase_transition_width', 5.0, 25.0, log=False
            )
            config['strength']['follower_threshold'] = trial.suggest_float(
                'strength.follower_threshold', 0.05, 0.3, log=False
            )
            config['strength']['attention_dropout'] = trial.suggest_float(
                'strength.attention_dropout', 0.0, 0.5, log=False
            )
            
        else:  # "all"
            # ä¼˜åŒ–æ‰€æœ‰å‚æ•°ï¼ˆä½†å¯ä»¥åˆ†å±‚æ§åˆ¶èŒƒå›´ï¼‰
            # Physicså±‚
            config.setdefault('physics', {}).setdefault('pillarWeights', {})
            config['physics']['pillarWeights']['month'] = trial.suggest_float(
                'physics.pillarWeights.month', 1.0, 2.0, log=False
            )
            config['physics']['pillarWeights']['hour'] = trial.suggest_float(
                'physics.pillarWeights.hour', 0.5, 1.5, log=False
            )
            
            # Structureå±‚
            config.setdefault('structure', {})
            config['structure']['rootingWeight'] = trial.suggest_float(
                'structure.rootingWeight', 0.8, 2.5, log=False
            )
            config['structure']['samePillarBonus'] = trial.suggest_float(
                'structure.samePillarBonus', 1.0, 2.5, log=False
            )
            
            # Thresholdå±‚
            config.setdefault('strength', {})
            config['strength']['energy_threshold_center'] = trial.suggest_float(
                'strength.energy_threshold_center', 2.0, 5.0, log=False
            )
            config['strength']['follower_threshold'] = trial.suggest_float(
                'strength.follower_threshold', 0.05, 0.3, log=False
            )
        
        return config
    
    def _evaluate_on_cases(self, config: Dict[str, Any], cases: List[Dict]) -> Dict[str, Any]:
        """
        [V10.2 æ ¸å¿ƒåˆ†æå¸ˆå»ºè®®] åœ¨æŒ‡å®šæ¡ˆä¾‹é›†ä¸Šè¯„ä¼°å‚æ•°
        
        Args:
            config: å‚æ•°é…ç½®
            cases: æ¡ˆä¾‹åˆ—è¡¨
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        # ä¸´æ—¶æ›¿æ¢tunerçš„cases
        original_cases = self.tuner.cases
        self.tuner.cases = cases
        
        try:
            # è¯„ä¼°
            result = self.tuner.evaluate_parameter_set(config)
        finally:
            # æ¢å¤åŸå§‹cases
            self.tuner.cases = original_cases
        
        return result


def run_optuna_study(tuner: StrengthParameterTuner,
                     config: OptimizationConfig,
                     base_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    è¿è¡ŒOptunaä¼˜åŒ–ç ”ç©¶
    
    Args:
        tuner: å‚æ•°è°ƒä¼˜å™¨
        config: ä¼˜åŒ–é…ç½®
        base_config: åŸºç¡€é…ç½®
        
    Returns:
        ä¼˜åŒ–ç»“æœå­—å…¸
    """
    # åˆ›å»ºç›®æ ‡å‡½æ•°
    objective = StrengthOptimizationObjective(tuner, config, base_config)
    
    # åˆ›å»ºStudy
    study_name = f"strength_tuning_{config.focus_layer}"
    sampler = TPESampler(seed=42)  # å¯å¤ç°
    
    pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=10) if config.pruner_enabled else None
    
    study = optuna.create_study(
        study_name=study_name,
        direction='minimize',  # æœ€å°åŒ–æŸå¤±
        sampler=sampler,
        pruner=pruner
    )
    
    # è¿è¡Œä¼˜åŒ–
    logger.info(f"ğŸš€ å¼€å§‹Optunaä¼˜åŒ–: {config.focus_layer}å±‚, {config.n_trials}æ¬¡è¯•éªŒ")
    
    try:
        study.optimize(
            objective,
            n_trials=config.n_trials,
            timeout=config.timeout,
            show_progress_bar=config.verbose
        )
    except KeyboardInterrupt:
        logger.warning("âš ï¸  ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
    
    # æå–æœ€ä½³ç»“æœ
    best_trial = study.best_trial
    best_params = best_trial.params
    best_value = best_trial.value
    
    # é‡æ–°è¯„ä¼°æœ€ä½³å‚æ•°ï¼ˆä½¿ç”¨objectiveä¸­ä¿å­˜çš„æœ€ä½³é…ç½®ï¼‰
    if objective.best_trial and 'config' in objective.best_trial:
        best_config = objective.best_trial['config']
        final_result = objective.best_trial.get('result')
        if final_result is None:
            # å¦‚æœæ²¡æœ‰ä¿å­˜ç»“æœï¼Œé‡æ–°è¯„ä¼°
            final_result = tuner.evaluate_parameter_set(best_config)
    else:
        # å¦‚æœæ²¡æœ‰ä¿å­˜ï¼Œé‡æ–°æ„å»ºé…ç½®ï¼ˆfallbackï¼‰
        # éœ€è¦ä½¿ç”¨best_trialæ¥é‡æ–°å»ºè®®å‚æ•°
        best_config = objective._suggest_parameters(best_trial)
        final_result = tuner.evaluate_parameter_set(best_config)
    
    return {
        'study': study,
        'best_trial': best_trial,
        'best_params': best_params,
        'best_loss': best_value,
        'best_match_rate': final_result.get('match_rate', 0.0),
        'final_result': final_result,
        'best_config': best_config,
        'objective_best': objective.best_trial
    }


def main():
    parser = argparse.ArgumentParser(description="V10.2 Optunaè‡ªåŠ¨è°ƒä¼˜ç³»ç»Ÿ")
    parser.add_argument('--mode', type=str, default='auto',
                       choices=['auto', 'tune', 'test'],
                       help='è¿è¡Œæ¨¡å¼: auto=è‡ªåŠ¨è°ƒä¼˜, tune=æŒ‡å®šå±‚è°ƒä¼˜, test=æµ‹è¯•')
    parser.add_argument('--layer', type=str, default='all',
                       choices=['physics', 'structure', 'threshold', 'all'],
                       help='è°ƒä¼˜å±‚: physics/structure/threshold/all')
    parser.add_argument('--trials', type=int, default=50,
                       help='Optunaè¯•éªŒæ¬¡æ•°')
    parser.add_argument('--constraints', type=str, default='soft',
                       choices=['strict', 'soft'],
                       help='çº¦æŸæ¨¡å¼: strict=ä¸¥æ ¼çº¦æŸ, soft=è½¯æƒ©ç½š')
    parser.add_argument('--timeout', type=float, default=None,
                       help='è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--no-pruner', action='store_true',
                       help='ç¦ç”¨Pruning')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è°ƒä¼˜å™¨
    tuner = StrengthParameterTuner()
    base_config = copy.deepcopy(DEFAULT_FULL_ALGO_PARAMS)
    
    if args.mode == 'test':
        # æµ‹è¯•å½“å‰é…ç½®
        result = tuner.evaluate_parameter_set(base_config)
        print(f"ğŸ“Š å½“å‰é…ç½®æ€§èƒ½:")
        print(f"   åŒ¹é…ç‡: {result['match_rate']:.1f}%")
        print(f"   åŒ¹é…æ¡ˆä¾‹æ•°: {result['matched_cases']}/{result['total_cases']}")
        return
    
    # åˆ›å»ºä¼˜åŒ–é…ç½®
    config = OptimizationConfig(
        focus_layer=args.layer,
        constraints=args.constraints,
        n_trials=args.trials,
        timeout=args.timeout,
        pruner_enabled=not args.no_pruner,
        verbose=True
    )
    
    # è¿è¡Œä¼˜åŒ–
    opt_result = run_optuna_study(tuner, config, base_config)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*80)
    print("ğŸ¯ Optunaä¼˜åŒ–å®Œæˆï¼")
    print("="*80)
    print(f"æœ€ä½³åŒ¹é…ç‡: {opt_result['best_match_rate']:.1f}%")
    print(f"æœ€ä½³æŸå¤±å€¼: {opt_result['best_loss']:.4f}")
    print(f"\næœ€ä½³å‚æ•°:")
    for param_name, param_value in opt_result['best_params'].items():
        print(f"  {param_name}: {param_value:.4f}")
    
    # ä¿å­˜æœ€ä½³é…ç½®
    output_path = project_root / "config" / "optuna_best_params.json"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(opt_result['best_config'], f, ensure_ascii=False, indent=2)
    print(f"\nâœ… æœ€ä½³é…ç½®å·²ä¿å­˜åˆ°: {output_path}")


if __name__ == '__main__':
    main()

