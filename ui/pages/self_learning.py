import streamlit as st
import os
import time

def render_self_learning():
    """Renders the Self-Learning main page."""
    st.header("ğŸ§  è‡ªæˆ‘è¿›åŒ–çŸ©é˜µ (Self-Learning Matrix)")
    with st.container():
        st.write("æ¡ˆä¾‹åº“è¿æ¥: âœ… (Mock DB)")
        st.write("ä¼˜åŒ–å™¨çŠ¶æ€: å¾…æœº")
        
        if 'sl_main_active' not in st.session_state: st.session_state['sl_main_active'] = None
        
        # Navigation Header
        if st.session_state['sl_main_active']:
             if st.button("â¬…ï¸ è¿”å›çŸ©é˜µé¦–é¡µ (Back to Matrix)", key="btn_back_matrix"):
                  st.session_state['sl_main_active'] = None
                  st.rerun()
             st.divider()
        
        if not st.session_state['sl_main_active']:
             _render_learning_grid()
        else:
             mode = st.session_state['sl_main_active']
             
             if "Optimizer" in mode:
                 _render_optimizer()
             elif "Video Learner" in mode or "Multimedia" in mode:
                 _render_multimedia_learning()
             # Removed Real Data Mining
             elif "Forum Mining" in mode:
                 _render_forum_mining()
             elif "Insights" in mode:
                 _render_insights_chat()
             elif "Theory Miner" in mode:
                 _render_theory_miner()
             elif "Task Manager" in mode:
                 _render_task_manager()
             # Web Learner is merged into Video Learner



def _render_learning_grid():
     st.markdown("### ğŸ§© æ ¸å¿ƒè¿›åŒ–å¼•æ“ (Evolution Engine)")
     
     # Row 1
     r1c1, r1c2, r1c3 = st.columns(3)
     with r1c1:
          with st.container(border=True):
              st.markdown("#### ğŸ§¬ å¤ç±å­¦ä¹ \n**(Theory Miner)**")
              st.caption("AI é˜…è¯»å¤ç±æå–è§„åˆ™")
              if st.button("è¿›å…¥å­¦ä¹ ", key="nav_theory", width="stretch"):
                   st.session_state['sl_main_active'] = "å¤ç±å­¦ä¹  (Theory Miner)"
                   st.rerun()
     with r1c2:
          with st.container(border=True):
              st.markdown("#### ğŸ¥ å½±éŸ³ç ”ä¹ \n**(Multimedia)**")
              st.caption("è§†é¢‘å¬è¯¾ / ç½‘ç»œæœå­¦")
              if st.button("è¿›å…¥å­¦ä¹ ", key="nav_vid", width="stretch"):
                   st.session_state['sl_main_active'] = "ğŸ¥ å½±éŸ³ç ”ä¹  (Multimedia)"
                   st.rerun()
     with r1c3:
          with st.container(border=True):
              st.markdown("#### ğŸ“‹ ä»»åŠ¡ä¸­å¿ƒ\n**(Task Manager)**")
              st.caption("åå°ä»»åŠ¡ç®¡ç†ä¸ç›‘æ§")
              if st.button("æŸ¥çœ‹ä»»åŠ¡", key="nav_tasks", width="stretch"):
                   st.session_state['sl_main_active'] = "ğŸ“‹ ä»»åŠ¡ä¸­å¿ƒ (Task Manager)"
                   st.rerun()
     
     # Row 2
     r2c1, r2c2, r2c3 = st.columns(3)
     with r2c1:
          # Former Mining Console Slot - Now Empty or repurposed
          st.empty()
     with r2c2:
          with st.container(border=True):
              st.markdown("#### ğŸ’¬ è®ºå›æ½œæ°´\n**(Forum Mining)**")
              st.caption("æŒ–æ˜è®ºå›å®æˆ˜æ¡ˆä¾‹")
              if st.button("è¿›å…¥è®ºå›", key="nav_forum", width="stretch"):
                   st.session_state['sl_main_active'] = "ğŸ’¬ è®ºå›æ½œæ°´ (Forum Mining)"
                   st.rerun()
     with r2c3:
          with st.container(border=True):
              st.markdown("#### âš–ï¸ æƒé‡ä¼˜åŒ–\n**(Optimizer)**")
              st.caption("ç¥ç»ç½‘ç»œè‡ªåŠ¨è¿›åŒ–")
              if st.button("å¯åŠ¨ä¼˜åŒ–", key="nav_opt", width="stretch"):
                   st.session_state['sl_main_active'] = "æƒé‡ä¼˜åŒ– (Optimizer)"
                   st.rerun()
                   
     # Row 3 (Insights moved down or integrated)
     # Since we replaced the middle slot, let's put Insights below or keep it.
     # User requested Forum Mining, so prioritize visibility.
     
def _render_forum_mining():
    """
    New Module: Forum Data Ingestion & Source Management
    """
    st.subheader("ğŸ’¬ è®ºå›æ½œæ°´ (Forum Data Mining)")
    st.caption("ä»ä¸“ä¸šå‘½ç†è®ºå›æŒ–æ˜å¸¦çœŸå®åé¦ˆçš„é«˜è´¨é‡æ¡ˆä¾‹ã€‚")

    from learning.db import LearningDB
    db = LearningDB()

    # --- 1. Source Management ---
    with st.expander("ğŸŒ æŒ–æ˜æºç®¡ç† (Source Management)", expanded=True):
        st.info("é…ç½®å¯ä¿¡çš„å‘½ç†è®ºå›æˆ–æ•°æ®æ¥æºã€‚")
        
        # Default sources if not in DB (Implementation detail: We might need a table for sources, or just config)
        # For MVP, we manage a list in Session State or Config.
        # Let's check config first.
        from core.config_manager import ConfigManager
        cm = ConfigManager()
        stored_sources = cm.get("forum_sources", ["å…ƒäº¨åˆ©è´ (China)", "é¾™éšç½‘ (LongYin)"])
        
        # UI
        sel_src = st.multiselect("å·²å¯ç”¨æº", stored_sources, default=stored_sources, key="forum_src_multi")
        
        c_add, c_btn = st.columns([3, 1])
        new_src = c_add.text_input("æ·»åŠ æ–°æº (åç§°æˆ– URL)", placeholder="ä¾‹å¦‚: æŸæŸå‘¨æ˜“è®ºå›")
        if c_btn.button("â• æ·»åŠ "):
            if new_src and new_src not in stored_sources:
                stored_sources.append(new_src)
                cm.set("forum_sources", stored_sources)
                st.toast(f"å·²æ·»åŠ æº: {new_src}")
                st.rerun()

    st.divider()

    # --- 2. Ingestion Interface ---
    st.write("#### ğŸ“¥ æ¡ˆä¾‹æŠ•å–‚ (Case Ingestion)")
    
    # --- 2. Ingestion Interface ---
    st.write("#### ğŸ“¥ æ¡ˆä¾‹æŠ•å–‚ (Case Ingestion)")
    
    tab_text, tab_file, tab_crawl = st.tabs(["ğŸ“ æ–‡æœ¬ç²˜è´´ (Paste)", "ğŸ“‚ æ–‡ä»¶ä¸Šä¼  (Upload)", "ğŸ•·ï¸ è‡ªåŠ¨æŠ“å– (Auto-Crawl)"])
    
    with tab_text:
        st.caption("ç›´æ¥å°†å¸–å­å†…å®¹ï¼ˆåŒ…å«æ¥¼ä¸»æ’ç›˜å’Œåé¦ˆï¼‰ç²˜è´´äºæ­¤ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ç»“æ„ã€‚")
        raw_text = st.text_area("å¸–å­å†…å®¹", height=200, placeholder="[æ±‚æµ‹] ä¹¾é€ ï¼šç”²å­... åé¦ˆï¼šè¾›ä¸‘å¹´å‡èŒ...")
        
        col_src_sel, col_action = st.columns([1, 1])
        src_tag = col_src_sel.selectbox("æ•°æ®æ¥æºæ ‡ç­¾", sel_src if sel_src else ["Unknown"])
        
        if col_action.button("â›ï¸ ç«‹å³æŒ–æ˜ (Mine Now)", type="primary"):
            if not raw_text or len(raw_text.strip()) < 5:
                st.warning(f"å†…å®¹å¤ªçŸ­ (å½“å‰æœ‰æ•ˆå­—æ•°: {len(raw_text.strip()) if raw_text else 0})ã€‚è¯·ç²˜è´´å®Œæ•´çš„å…«å­—æ’ç›˜å’Œåé¦ˆå†…å®¹ã€‚")
            else:
                with st.spinner("ğŸš€ æ­£åœ¨å¯åŠ¨ V6.0 æŒ–æ˜æœº... (NLP Processing)"):
                    from learning.forum_miner import ForumMiner
                    miner = ForumMiner()
                    
                    # Run Synchronously for text paste
                    success = miner.process_thread_text(raw_text, source_id=f"Paste_{src_tag}")
                    
                    if success:
                        st.balloons()
                        st.success("âœ… æŒ–æ˜æˆåŠŸï¼æ¡ˆä¾‹å·²å…¥åº“ã€‚V5 å¼•æ“å°†åœ¨ä¸‹æ¬¡è®­ç»ƒæ—¶å¸æ”¶æ­¤ç»éªŒã€‚")
                    else:
                        st.error("âŒ æŒ–æ˜å¤±è´¥ã€‚å¯èƒ½åŸå› ï¼šæœªæ£€æµ‹åˆ°å®Œæ•´å…«å­—æˆ–æœ‰æ•ˆåé¦ˆã€‚")
                        st.info("æç¤ºï¼šè¯·ç¡®ä¿å†…å®¹ä¸­åŒ…å« 'å¹´/æœˆ/æ—¥/æ—¶' æˆ– 'ä¹¾é€ /å¤é€ ' ä»¥åŠ 'åé¦ˆ' å…³é”®è¯ã€‚")

    with tab_file:
        st.caption("æ‰¹é‡ä¸Šä¼ åŒ…å«å¤šä¸ªæ¡ˆä¾‹çš„ TXT æ–‡ä»¶ã€‚")
        up_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=['txt'])
        if up_file and st.button("ğŸ“‚ æ‰¹é‡å¤„ç†"):
            content = up_file.getvalue().decode("utf-8", errors="ignore")
            # Create a background job for bulk
            payload = {"type": "forum_bulk", "content_snippet": content[:100], "full_content_path": "TEMP_PATH"} # TODO: Save temp
            # For simplicity in this turn, run sync or save to temp
            st.info("æ„å»ºä¸­... è¯·ä½¿ç”¨æ–‡æœ¬ç²˜è´´æ¨¡å¼ã€‚")

    with tab_crawl:
        st.error("âš ï¸ è­¦å‘Šï¼šè‡ªåŠ¨æŠ“å–å±äºé«˜é£é™©æ“ä½œï¼Œè¯·ä¸¥æ ¼éµå®ˆç¤¼è²Œåè®®ã€‚")
        st.info("æ­¤æ¨¡å¼å°†æ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®æŒ‡å®šæ¿å—ï¼Œè‡ªåŠ¨ç¿»é¡µå¹¶æå–å¸¦åé¦ˆçš„å¸–å­ã€‚")
        
        c_url, c_pg = st.columns([3, 1])
        target_url = c_url.text_input("æ¿å— URL (Board URL)", value="http://bbs.china95.net/forum-103-1.html", help="ä¾‹å¦‚å…ƒäº¨åˆ©è´çš„å…«å­—å®ä¾‹åé¦ˆç‰ˆ")
        max_pages = c_pg.number_input("æŠ“å–é¡µæ•°", min_value=1, max_value=5, value=1)
        
        if st.button("ğŸ•·ï¸ å¯åŠ¨çˆ¬è™«ä»»åŠ¡ (Start Crawler Job)"):
            if "china95" not in target_url and "longyin" not in target_url:
                st.warning("ç›®å‰ä»…æ”¯æŒ YuanHengLiZhen (china95) æˆ– LongYin è®ºå›çš„è‡ªåŠ¨è§£æã€‚")
            else:
                # Create Job
                payload = {
                    "type": "forum_crawl", 
                    "url": target_url, 
                    "max_pages": max_pages, 
                    "keywords": ["åé¦ˆ", "å‡†", "ç¡®å®"] # Default keywords
                }
                # Assuming 'Forum Crawler' is a recognized internal job name or generic
                db.create_job("forum_crawl", target_file=f"Crawl {target_url[:20]}...", payload=payload)
                st.success(f"ğŸš€ çˆ¬è™«ä»»åŠ¡å·²åˆ›å»ºï¼å°†åœ¨åå°æ¨¡æ‹Ÿäººç±»è¡Œä¸ºè¿›è¡ŒæŠ“å– (é¢„è®¡è€—æ—¶: {max_pages * 2} åˆ†é’Ÿ)ã€‚")
                st.caption("è¯·å‰å¾€ã€ä»»åŠ¡ä¸­å¿ƒã€‘æŸ¥çœ‹æ—¥å¿—ã€‚")

def _render_optimizer():
    st.subheader("âš–ï¸ é‡å­å‚æ•°è¿›åŒ– (Quantum Evolution)")
    st.caption("åŸºäºè´å¶æ–¯é€»è¾‘ (Bayesian) ä¸ çœŸå®æ¡ˆä¾‹åé¦ˆ (Vreal Feedback) çš„ç‰©ç†å¼•æ“è‡ªé€‚åº”æ ¡æ­£ã€‚")
    
    from learning.db import LearningDB
    from learning.optimizer import Optimizer
    
    db = LearningDB()
    opt = Optimizer()
    cases = db.get_all_cases()
    
    # 1. State Display
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    with col_stat1:
        st.metric("ğŸ“š æ¡ˆä¾‹åº“è§„æ¨¡", f"{len(cases)}", delta="æ ·æœ¬æ•°")
    with col_stat2:
        curr_gamma = opt.current_weights.get("gamma_decay", 1.5)
        st.metric("ğŸŒ ç©ºé—´è¡°å‡ç³»æ•° (Î³)", f"{curr_gamma:.3f}", delta="ç‰©ç†å¸¸æ•°")
    with col_stat3:
        # Mock Loss or Last Loss
        last_loss = 0.0 # TODO: Store in DB
        st.metric("ğŸ“‰ å½“å‰å…¨å±€è¯¯å·® (MSE)", f"{last_loss:.4f}", delta_color="inverse")

    st.divider()

    # 2. Manual Tweak vs Auto
    tab_auto, tab_manual = st.tabs(["ğŸ§¬ è‡ªåŠ¨è¿›åŒ– (Auto-Evolve)", "ğŸ›ï¸ æ‰‹åŠ¨è°ƒå‚ (Manual Engineering)"])
    
    with tab_auto:
        st.markdown("#### ç¥ç»ç½‘ç»œåå‘ä¼ æ’­ (Gradient Descent)")
        st.write("ç³»ç»Ÿå°†å°è¯•é€šè¿‡å¾®è°ƒç‰©ç†å‚æ•°ï¼ˆå¦‚ Î³, $W_{Month}$ï¼‰æ¥å‡å°é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„è¯¯å·®ã€‚")
        
        if st.button("ğŸ§¬ å¯åŠ¨ä¸€è½®è¿­ä»£ (Run 1 Epoch)", type="primary"):
            if len(cases) < 5:
                st.warning(f"âš ï¸ æ ·æœ¬ä¸è¶³ (å½“å‰ {len(cases)}/5)ã€‚è¯·å…ˆåœ¨ã€å®æˆ˜æŒ–æ˜ã€‘æˆ–ã€æ’ç›˜åé¦ˆã€‘ä¸­ç§¯ç´¯æ›´å¤šçœŸå®æ¡ˆä¾‹ã€‚")
            else:
                progress_bar = st.progress(0, text="åˆå§‹åŒ–ä¼˜åŒ–å™¨...")
                with st.spinner("æ­£åœ¨é‡æ„å‘é‡ç©ºé—´ (Re-Vectorizing)..."):
                    time.sleep(0.5)
                    progress_bar.progress(30, text="è®¡ç®—åŸºå‡†è¯¯å·® (Baseline Loss)...")
                    
                    res = opt.run_training_step()
                    
                    progress_bar.progress(100, text="ä¼˜åŒ–å®Œæˆï¼")
                    
                    if res['result'] == "improved":
                        st.balloons()
                        st.success(f"âœ… è¿›åŒ–æˆåŠŸ! è¯¯å·®å¤§å¹…ä¸‹é™: {res['old_mse']:.4f} -> {res['new_mse']:.4f}")
                        st.write(f"**å‚æ•°æ›´æ–°**: Gamma {curr_gamma} -> {opt.current_weights['gamma_decay']}")
                    elif res['result'] == "reverted":
                        st.info(f"ğŸ”„ æœ¬æ¬¡å°è¯•æœªè·çªç ´ (MSE {res['new_mse']:.4f} >= {res['old_mse']:.4f})ï¼Œå·²å›æ»šå‚æ•°ã€‚")
                    else:
                        st.write(res)
                        
    with tab_manual:
        st.write("#### ç‰©ç†å¸¸æ•°è¦†å†™ (Override)")
        new_gamma = st.slider("Gamma (è·ç¦»è¡°å‡)", 0.1, 5.0, float(curr_gamma), 0.1)
        w_month = st.slider("Month Weight (æœˆä»¤æƒé‡)", 1.0, 10.0, float(opt.current_weights.get('month_branch_weight', 4.0)), 0.1)
        
        if st.button("ğŸ’¾ å¼ºåˆ¶ä¿å­˜å‚æ•°"):
            opt.current_weights['gamma_decay'] = new_gamma
            opt.current_weights['month_branch_weight'] = w_month
            db.save_weights(opt.current_weights, 0, note="Manual Override")
            st.success("å‚æ•°å·²å¼ºåˆ¶æ›´æ–°ï¼æ–°æ¨¡å‹å°†åœ¨ä¸‹æ¬¡è®­ç»ƒæ—¶ç”Ÿæ•ˆã€‚")


def _render_multimedia_learning(): # Renamed function
    st.caption("ğŸ¥ å½±éŸ³å­¦ä¹ å®éªŒå®¤ï¼šå¬æ‡‚å‘½ç†æ•™å­¦è§†é¢‘ï¼Œæ‰«æç½‘ç»œèµ„æºã€‚") # Updated caption
    
    tab_av, tab_net = st.tabs(["ğŸ§ æœ¬åœ°å¬è¯¾ (File)", "ğŸŒ å…¨ç½‘æœå­¦ (Network)"]) # Removed tab_chat
    
    # --- Tab 1: Local File ---
    with tab_av:
        st.write("#### ğŸ“¤ ä¸Šä¼ éŸ³è§†é¢‘æ–‡ä»¶ (Whisper Listening)")
        media_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘/è§†é¢‘ (mp3/mp4)", type=['mp3', 'wav', 'mp4', 'm4a', 'mov'])
        
        if media_file:
            if media_file.type.startswith('video'):
                st.video(media_file)
            else: 
                st.audio(media_file)
            
            if st.button("ğŸ‘‚ å¼€å§‹å¬è¯¾ (Transcribe & Learn)"):
                with st.spinner("ğŸ§ æ­£åœ¨è†å¬å¹¶è½¬æ¢ä¸ºæ–‡å­—... (Loading Whisper & Transcribing)"):
                    import tempfile
                    suffix = "." + media_file.name.split('.')[-1]
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        tmp.write(media_file.getvalue())
                        tmp_path = tmp.name
                    
                    from learning.media_miner import MediaMiner
                    mm = MediaMiner(model_size="base") 
                    text = mm.transcribe(tmp_path)
                    os.remove(tmp_path)

                    if text.startswith("[Error"):
                        st.error(f"è½¬å½•å¤±è´¥: {text}")
                    else:
                        st.subheader("ğŸ“ å¬è¯¾ç¬”è®° (Transcript)")
                        st.text_area("åŸæ–‡", text, height=200)
                        
                        if len(text) > 50:
                            st.info("ğŸ§  æ­£åœ¨ç†è§£å¹¶æå–å‘½ç†è§„åˆ™...")
                            from learning.theory_miner import TheoryMiner
                            tm = TheoryMiner(host=st.session_state.get('ollama_host', "http://localhost:11434"))
                            rules = tm.extract_rules(text)
                            
                            if rules:
                                st.success(f"ä»è§†é¢‘ä¸­å­¦ä¼šäº† {len(rules)} æ¡æ–°è§„åˆ™ï¼")
                                st.json(rules)
                                
                                from learning.db import LearningDB
                                db = LearningDB()
                                for r in rules:
                                    db.add_rule(r, source_book=f"[Video] {media_file.name}")
                                st.success("å·²å­˜å…¥çŸ¥è¯†åº“ï¼")
                            else:
                                st.warning("æœªèƒ½ä»å†…å®¹ä¸­æå–å‡ºæœ‰æ•ˆè§„åˆ™ã€‚")

    # --- Tab 2: Network ---
    with tab_net:
        st.write("#### ğŸŒ ç½‘ç»œè§†é¢‘æµåˆ†æ (Web Streams)")
        v_type = st.radio("æ¥æºç±»å‹", ["å•ä¸ªè§†é¢‘ (Video)", "é¢‘é“/æ’­æ”¾åˆ—è¡¨ (Channel/Playlist)"], horizontal=True)
        v_url = st.text_input("è§†é¢‘/é¢‘é“ URL (YouTube/Bilibili/TikTok/X)")
        
        if st.button("ğŸ’¾ è®¢é˜…å¹¶æ‰«æ (Subscribe & Scan)"):
            if not v_url:
                st.warning("è¯·è¾“å…¥ URL")
            else:
                from learning.db import LearningDB
                db = LearningDB()
                
                if "Channel" in v_type:
                    with st.spinner("æ­£åœ¨è§£æé¢‘é“å…ƒæ•°æ®..."):
                        from learning.video_downloader import VideoDownloader
                        dl = VideoDownloader()
                        res = dl.get_channel_info(v_url)
                        if isinstance(res, tuple):
                            vids, ch_title = res
                        else:
                            vids, ch_title = res, v_url
    
                    if not vids and isinstance(ch_title, str) and "Error" in ch_title:
                         st.error(f"è§£æå¤±è´¥: {ch_title}")
                    else:
                         real_name = ch_title if ch_title and "Unknown" not in ch_title else v_url
                         is_new = db.add_channel(real_name, v_url, "YouTube", "Added via UI")
                         
                         if is_new:
                              st.success(f"ğŸ“º é¢‘é“ [{real_name}] å·²è®¢é˜…ï¼")
                         else:
                              st.info(f"ğŸ”„ æ­£åœ¨æ›´æ–°é¢‘é“ [{real_name}]...")
                        
                         if vids:
                            from learning.video_miner import VideoMiner
                            vm = VideoMiner()
                            history = vm.get_history()
                            for v in vids:
                                v_id = vm.get_video_id(v['url'])
                                is_done = v_id in history
                                v['Status'] = "âœ… å·²å­¦" if is_done else "ğŸ†• æ–°è¯¾"
                                v['Select'] = not is_done
                                v['Video_ID'] = v_id
                            
                            st.session_state[f"scan_res_{v_url}"] = vids
                         else:
                             st.error("æœªèƒ½æ‰¾åˆ°è§†é¢‘ï¼Œè¯·æ£€æŸ¥ URL")
                else:
                    st.warning("å•è§†é¢‘æ¨¡å¼è¯·ç›´æ¥åŠ å…¥é˜Ÿåˆ— (Single Video mode not supported for subscription yet)")
    
        st.markdown("#### ğŸ“º å·²è®¢é˜…é¢‘é“ (Subscribed Channels)")
        from learning.db import LearningDB
        db = LearningDB()
        channels = db.get_all_channels()
        if channels:
            for ch in channels:
                with st.container():
                    c1, c3, c4 = st.columns([5, 1.5, 0.5])
                    c1.markdown(f"ğŸ“º **[{ch['name']}]({ch['url']})**")
                    
                    scan_key = f"scan_res_{ch['url']}"
    
                    if c3.button("ğŸ” æ‰«æ", key=f"scan_btn_{ch['id']}"):
                         with st.spinner(f"æ­£åœ¨æ‰«æ {ch['name']}..."):
                            from learning.video_downloader import VideoDownloader
                            dl = VideoDownloader()
                            res = dl.get_channel_info(ch['url'])
                            if isinstance(res, tuple):
                                 vids, fresh_name = res
                                 if fresh_name and "http" not in fresh_name and "Unknown" not in fresh_name:
                                      db.add_channel(fresh_name, ch['url'])
                            else:
                                 vids = res
                            
                            if not vids: vids = []
                            
                            from learning.video_miner import VideoMiner
                            vm = VideoMiner()
                            history = vm.get_history()
                            
                            for v in vids:
                                v_id = vm.get_video_id(v['url'])
                                is_done = v_id in history
                                v['Status'] = "âœ… å·²å­¦" if is_done else "ğŸ†• æ–°è¯¾"
                                v['Select'] = not is_done 
                                v['Video_ID'] = v_id 
                            
                            st.session_state[scan_key] = vids
                            st.rerun()
    
                    if scan_key in st.session_state:
                        vids = st.session_state[scan_key]
                        with st.expander(f"ğŸ“‹ {ch['name']} - è§†é¢‘åˆ—è¡¨", expanded=True):
                            if not vids:
                                st.warning("æœªæ‰¾åˆ°è§†é¢‘")
                            else:
                                import pandas as pd
                                
                                c_tool_1, c_tool_2, c_tool_3, c_tool_4 = st.columns([0.8, 0.8, 1.4, 2])
                                with c_tool_1:
                                    if st.button("å…¨é€‰", key=f"all_{ch['id']}"):
                                        for v in vids: v['Select'] = True
                                        st.rerun()
                                with c_tool_2:
                                    if st.button("å…¨ä¸é€‰", key=f"none_{ch['id']}"):
                                        for v in vids: v['Select'] = False
                                        st.rerun()
                                
                                with c_tool_3:
                                    sort_opt = st.selectbox("æ’åº", ["æœ€è¿‘æ›´æ–° (Default)", "æ ‡é¢˜", "ğŸ†• æ–°è¯¾ä¼˜å…ˆ", "ğŸ’¬ å­—å¹•ä¼˜å…ˆ"], key=f"sort_{ch['id']}", label_visibility="collapsed")
                                    
                                if sort_opt == "æ ‡é¢˜":
                                    vids.sort(key=lambda x: x['title'])
                                elif sort_opt == "ğŸ†• æ–°è¯¾ä¼˜å…ˆ":
                                    vids.sort(key=lambda x: 0 if "æ–°è¯¾" in x['Status'] else 1)
                                elif sort_opt == "ğŸ’¬ å­—å¹•ä¼˜å…ˆ":
                                    vids.sort(key=lambda x: 0 if "ğŸ’¬" in x['title'] else 1)
                                
                                if "å­—å¹•" in sort_opt:
                                    st.caption("æ³¨: ğŸ’¬ ä»…ä»£è¡¨å¿«é€Ÿæ‰«æèƒ½æ£€æµ‹åˆ°çš„åŒ…å«å­—å¹•çš„è§†é¢‘ (Beta)ã€‚")
    
                                df = pd.DataFrame(vids)
                                edited_df = st.data_editor(
                                    df,
                                    column_config={
                                        "Select": st.column_config.CheckboxColumn("é€‰æ‹©", required=True),
                                        "Status": st.column_config.TextColumn("çŠ¶æ€", width="small"),
                                        "title": st.column_config.TextColumn("æ ‡é¢˜", width="large"),
                                        "url": st.column_config.LinkColumn("é“¾æ¥"),
                                    },
                                    disabled=["Status", "title", "url"],
                                    hide_index=True,
                                    width="stretch",
                                    key=f"editor_{ch['id']}"
                                )
                                
                                if st.button("ğŸ“¥ å°†é€‰ä¸­è§†é¢‘åŠ å…¥é˜Ÿåˆ—", key=f"q_sel_{ch['id']}"):
                                    sel_rows = edited_df[edited_df['Select'] == True]
                                    
                                    if sel_rows.empty:
                                        st.warning("æœªé€‰æ‹©ä»»ä½•è§†é¢‘")
                                    else:
                                        count = 0
                                        for idx, row in sel_rows.iterrows():
                                            payload = {"type": "video", "url": row['url'], "title": row['title']}
                                            db.create_job("video_learn", target_file=row['title'], payload=payload)
                                            count += 1
                                        
                                        st.success(f"å·²åŠ å…¥ {count} ä¸ªä»»åŠ¡ï¼")
                                        db.update_channel_last_scanned(ch['url'])
                                        time.sleep(1)
                                        del st.session_state[scan_key] 
                                        st.rerun()
                                
                                if st.button("æ”¶èµ·åˆ—è¡¨", key=f"hide_{ch['id']}"):
                                    del st.session_state[scan_key]
                                    st.rerun()
                    
                    if c4.button("ğŸ—‘ï¸", key=f"del_ch_{ch['id']}"):
                        db.delete_channel(ch['url'])
                        st.rerun()

def _render_insights_chat(): # New function for Insights & Chat
    st.write("#### ğŸ’¡ çŸ¥è¯†åº“ä¸ç ”è®¨ (Knowledge & Discussion)")
    from learning.db import LearningDB
    db = LearningDB()
    
    # 1. Rules Display
    rules = db.get_all_rules()
    st.caption(f"å½“å‰ç³»ç»Ÿå·²ä¹ å¾— {len(rules)} æ¡å‘½ç†è§„åˆ™ã€‚")
    
    with st.expander("æŸ¥çœ‹æ‰€æœ‰è§„åˆ™ (View Rules)", expanded=False):
            if rules:
                import pandas as pd
                df_rules = pd.DataFrame(rules)
                # Fix for PyArrow ArrowInvalid error: Convert dict/list cols to string
                # Identify object columns and convert them to string representation
                for col in df_rules.columns:
                    if df_rules[col].dtype == 'object':
                        df_rules[col] = df_rules[col].apply(lambda x: str(x) if isinstance(x, (dict, list)) else x)
                
                st.dataframe(df_rules)
            else:
                st.info("æš‚æ— è§„åˆ™ã€‚è¯·å…ˆé€šè¿‡å¬è¯¾æˆ–é˜…è¯»ç§¯ç´¯çŸ¥è¯†ã€‚")
    
    # 2. Chat Interface
    st.divider()
    st.write("#### ğŸ’¬ ä¸ç³»ç»Ÿè®ºé“ (Chat with Bazi AI)")
    
    if "learn_chat_msgs" not in st.session_state: st.session_state["learn_chat_msgs"] = []
    
    for msg in st.session_state["learn_chat_msgs"]:
            st.chat_message(msg["role"]).write(msg["content"])
            
    if prompt := st.chat_input("æ¢è®¨å‘½ç†è§„åˆ™..."):
            st.session_state["learn_chat_msgs"].append({"role": "user", "content": prompt})
            st.chat_message("user").write(prompt)
            
            import ollama
            host = st.session_state.get('ollama_host')
            model = st.session_state.get('selected_model_name', 'qwen2.5')
            
            # Context Construction
            rule_summary = "\n".join([f"- {r.get('rule_name', 'Rule')}: {str(r)[0:100]}..." for r in rules[-20:]]) # Limit context
            
            sys_prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªæ­£åœ¨ä¸æ–­å­¦ä¹ è¿›åŒ–çš„å…«å­—å‘½ç†ç³»ç»Ÿã€‚
            ä½ å·²ç»å­¦ä¼šäº†ä»¥ä¸‹è§„åˆ™ï¼ˆæœ€è¿‘20æ¡ï¼‰ï¼š
            {rule_summary}
            
            ç”¨æˆ·æ˜¯ä½ çš„å¯¼å¸ˆæˆ–ç ”è®¨ä¼™ä¼´ã€‚è¯·æ ¹æ®ä½ çš„çŸ¥è¯†åº“å›ç­”é—®é¢˜ï¼Œæˆ–è€…è®¨è®ºæ–°çš„æ„Ÿæ‚Ÿã€‚
            """
            
            stream = ollama.Client(host=host).chat(
                model=model, 
                messages=[{'role': 'system', 'content': sys_prompt}] + st.session_state["learn_chat_msgs"],
                stream=True
            )
            
            with st.chat_message("assistant"):
                resp = st.write_stream(stream)
            st.session_state["learn_chat_msgs"].append({"role": "assistant", "content": resp})

def _render_theory_miner():
    """
    Renders the Theory Miner (Library) Interface with Categories.
    """
    st.subheader("ğŸ“š è—ç»é˜ (Ancient Library)")
    
    book_dir = "data/books"
    os.makedirs(book_dir, exist_ok=True)
    
    # Layout: Left (List) | Right (Reader)
    c_list, c_reader = st.columns([1, 2])
    
    with c_list:
        st.write("#### ğŸ“‚ åˆ†ç±»ç´¢å¼• (Index)")
        
        # 1. Category Filter
        cat_filter = st.radio(
            "é€‰æ‹©åˆ†ç±»", 
            ["ğŸ“œ ç»å…¸å¤ç± (Classics)", "ğŸ¥ å½±éŸ³å®å½• (Transcripts)"], 
            horizontal=True,
            label_visibility="collapsed"
        )
        
        # 2. Get Files & Filter
        all_files = sorted([f for f in os.listdir(book_dir) if f.endswith('.txt')])
        
        def is_media(f):
            return f.startswith("[Media]") or f.startswith("[Video]") or f.startswith("[Audio]")
            
        if "Classics" in cat_filter:
            display_files = [f for f in all_files if not is_media(f)]
        else:
            display_files = [f for f in all_files if is_media(f)]
            
        # 3. File List
        if not display_files:
            st.info("æ­¤åˆ†ç±»ä¸‹æš‚æ— è—ä¹¦ã€‚")
            selected_book = None
        else:
            # Use a unique key based on category to reset selection when switching tabs
            selected_book = st.radio("ä¹¦ç›®åˆ—è¡¨", display_files, label_visibility="collapsed", key=f"list_{cat_filter}")
            st.session_state['selected_book'] = selected_book

        st.divider()
        
        # 4. Upload / Delete Tools
        with st.expander("ğŸ› ï¸ ç®¡ç†å·¥å…· (Manage)", expanded=False):
            tab_up, tab_del = st.tabs(["ğŸ“¥ å…¥åº“", "ğŸ—‘ï¸ ç„šæ¯"])
            
            with tab_up:
                up_type = st.selectbox("ä¹¦ç±ç±»å‹", ["ç»å…¸å¤ç±", "å½±éŸ³å®å½•"], index=0 if "Classics" in cat_filter else 1)
                uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (.txt)", type="txt", label_visibility="collapsed")
                
                if uploaded_file and st.button("ç¡®è®¤å…¥åº“"):
                    fname = uploaded_file.name
                    # Auto-tagging
                    if up_type == "å½±éŸ³å®å½•" and not is_media(fname):
                        fname = f"[Media] {fname}"
                    elif up_type == "ç»å…¸å¤ç±" and is_media(fname):
                        # Attempt to strip tag if user insists it's classic? Or just leave it.
                        pass
                        
                    path = os.path.join(book_dir, fname)
                    if not os.path.exists(path):
                        with open(path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        st.toast(f"âœ… å·²å…¥åº“: {fname}")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.warning("æ–‡ä»¶å·²å­˜åœ¨")
            
            with tab_del:
                if selected_book:
                    st.write(f"é€‰ä¸­: **{selected_book}**")
                    if st.button("ç¡®è®¤ç„šæ¯", type="primary"):
                         try:
                             os.remove(os.path.join(book_dir, selected_book))
                             st.toast("ğŸ”¥ å·²ç„šæ¯")
                             time.sleep(0.5)
                             st.rerun()
                         except Exception as e:
                             st.error(str(e))
                else:
                    st.caption("è¯·å…ˆåœ¨ä¸Šæ–¹é€‰æ‹©ä¸€æœ¬ä¹¦")

    with c_reader:
        sel = st.session_state.get('selected_book')
        # Verify it exists in current dir (safety)
        if sel and os.path.exists(os.path.join(book_dir, sel)):
            book_name = sel
            path = os.path.join(book_dir, book_name)
            
            st.write(f"#### ğŸ“– {book_name}")
            
            try:
                with open(path, "r", encoding='utf-8') as f:
                    content = f.read()
            except:
                try:
                     with open(path, "r", encoding='gb18030') as f:
                        content = f.read()
                except:
                    content = "âš ï¸ æ— æ³•è§£ç æ–‡ä»¶å†…å®¹ã€‚"
            
            # Context info
            col_info, col_act = st.columns([1, 1])
            with col_info:
                 st.caption(f"å­—æ•°: {len(content)}")
                 tags = "ğŸ·ï¸ å¤æ–‡/åŸè‘—" if not is_media(book_name) else "ğŸ·ï¸ è¯­éŸ³è½¬å½•/ç¬”è®°"
                 st.caption(tags)
            
            with col_act:
                 if st.button("ğŸ§  AI æ·±åº¦ç ”è¯» (Deep Mine)", width="stretch"):
                     from learning.db import LearningDB
                     db = LearningDB()
                     payload = {"type": "text_mining", "filename": book_name}
                     db.create_job("theory_mine", target_file=path, payload=payload)
                     st.info(f"ğŸ¤– ä¹¦ç«¥å·²é¢†å‘½ï¼Œæ­£åœ¨åå°ç ”è¯»ã€Š{book_name}ã€‹...")
            
            st.divider()
            st.text_area("Reader", content, height=600, label_visibility="collapsed")
            
        else:
            if not display_files:
                st.info("ğŸ‘ˆ è¯·ä¸Šä¼ ä¹¦ç±")
            else:
                st.info("ğŸ‘ˆ è¯·é€‰æ‹©ä¹¦ç±å¼€å§‹é˜…è¯»")

def _render_task_manager():
    st.subheader("ğŸ“‹ ä»»åŠ¡æ§åˆ¶ä¸­å¿ƒ (Job Control Center)")
    from learning.db import LearningDB
    from datetime import datetime
    from core.config_manager import ConfigManager
    import sqlite3
    import json
    import pandas as pd
    
    db = LearningDB()
    cm = ConfigManager()
    
    # --- 1. Top Stats & Config ---
    # æ˜¾ç¤ºå½“å‰å¹¶å‘é…ç½®
    col_cfg1, col_cfg2, col_cfg3 = st.columns(3)
    with col_cfg1:
        max_concurrent = cm.get('max_concurrent_jobs', 3)
        st.info(f"âš¡ **æœ€å¤§å¹¶å‘æ•°**: {max_concurrent} ä¸ªä»»åŠ¡")
    with col_cfg2:
        subtitle_priority = cm.get('subtitle_priority', True)
        priority_text = "âœ… å·²å¼€å¯" if subtitle_priority else "âŒ å·²å…³é—­"
        st.info(f"ğŸ’¬ **å­—å¹•ä¼˜å…ˆçº§**: {priority_text}")
    with col_cfg3:
        # Deduplicate Button here for visibility
        if st.button("ğŸ§¹ åˆå¹¶é‡å¤ä»»åŠ¡", width="stretch", help="è‡ªåŠ¨ä¿ç•™è¿›åº¦æœ€å¿«çš„ä¸€ä¸ªï¼Œæ¸…ç†é‡å¤é¡¹"):
            count = db.deduplicate_jobs()
            if count > 0:
                st.success(f"âœ… å·²æ¸…ç† {count} ä¸ªé‡å¤ä»»åŠ¡ï¼")
                time.sleep(1)
                st.rerun()
            else:
                st.info("æ²¡æœ‰å‘ç°é‡å¤ä»»åŠ¡ã€‚")
    
    st.divider()
    
    # --- 2. Filter & Controls ---
    col_ctrl1, col_ctrl2 = st.columns([4, 1])
    with col_ctrl1:
        # Multi-select status filter
        status_options = ['running', 'pending', 'paused', 'failed', 'finished']
        status_labels =  ['ğŸŸ¢ è¿è¡Œä¸­', 'ğŸ”µ ç­‰å¾…ä¸­', 'ğŸŸ¡ å·²æš‚åœ', 'ğŸ”´ å¤±è´¥', 'âœ… å·²å®Œæˆ']
        
        # Smart default: Show all relevant including finished for better feedback
        default_statuses = ['running', 'pending', 'paused', 'failed', 'finished']
        
        selected_statuses = st.multiselect(
            "ç­›é€‰ä»»åŠ¡çŠ¶æ€",
            status_options,
            default=default_statuses,
            format_func=lambda x: dict(zip(status_options, status_labels)).get(x, x)
        )
    with col_ctrl2:
         st.write("") # Spacer
         if st.button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", width='stretch'):
             st.rerun()
         
         if st.checkbox("è‡ªåŠ¨åˆ·æ–° (Auto)", value=False, key="task_auto_refresh"):
             time.sleep(3)
             st.rerun()

    # Get Jobs
    jobs = db.get_jobs_by_status(selected_statuses if selected_statuses else status_options, limit=1000)
    
    if not jobs:
        st.info("âœ¨ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ä»»åŠ¡ã€‚")
        return

    # --- 3. Data Processing for View ---
    # Convert to DataFrame for Data Editor
    
    # Helper for elapsed time
    def calc_elapsed_time(created_at_str):
        try:
            created = datetime.strptime(created_at_str, "%Y-%m-%d %H:%M:%S")
            elapsed = datetime.now() - created
            hours = int(elapsed.total_seconds() // 3600)
            minutes = int((elapsed.total_seconds() % 3600) // 60)
            if hours > 0: return f"{hours}h {minutes}m"
            if minutes > 0: return f"{minutes}m"
            return "<1m"
        except: return "N/A"

    data_list = []
    for j in jobs:
        try: payload = json.loads(j['payload']) if j['payload'] else {}
        except: payload = {}
        
        title = payload.get('title', os.path.basename(j['target_file']))
        url = payload.get('url', '')
        
        # Type Map
        t_map = {'video_learn': 'ğŸ¥ è§†é¢‘', 'theory_mine': 'ğŸ“š å¤ç±', 'case_mine': 'â›ï¸ æŒ–æ˜'}
        
        # Progress map
        pct = 0
        if j['total_work'] > 0:
            pct = int((j['current_progress'] / j['total_work']) * 100)
        
        data_list.append({
            "Select": False,
            "ID": j['id'],
            "Status": j['status'],
            "Type": t_map.get(j['job_type'], j['job_type']),
            "Title": title,
            "Progress": pct,
            "Created": j['created_at'][5:16], # mm-dd HH:MM
            "Elapsed": calc_elapsed_time(j['created_at']),
            "_full_job": j # Hidden store
        })
        
    df = pd.DataFrame(data_list)
    
    # --- 4. Main Table View (Data Editor) ---
    st.write(f"å…± **{len(jobs)}** ä¸ªä»»åŠ¡")
    
    edited_df = st.data_editor(
        df,
        column_config={
            "Select": st.column_config.CheckboxColumn("é€‰æ‹©", width="small"),
            "ID": st.column_config.NumberColumn("ID", width="small"),
            "Status": st.column_config.TextColumn("çŠ¶æ€", width="small"),
            "Type": st.column_config.TextColumn("ç±»å‹", width="small"),
            "Title": st.column_config.TextColumn("ä»»åŠ¡æ ‡é¢˜", width="large"),
            "Progress": st.column_config.ProgressColumn("è¿›åº¦", min_value=0, max_value=100, format="%d%%"),
            "Created": st.column_config.TextColumn("åˆ›å»ºæ—¶é—´", width="medium"),
            "Elapsed": st.column_config.TextColumn("è€—æ—¶", width="small"),
            "_full_job": None # Hide
        },
        disabled=["ID", "Status", "Type", "Title", "Progress", "Created", "Elapsed"],
        hide_index=True,
        width="stretch",
        key="job_editor"
    )
    
    # Get Selected IDs
    selected_rows = edited_df[edited_df['Select'] == True]
    selected_ids = selected_rows['ID'].tolist()
    
    # --- 5. Bulk Actions Footer ---
    if selected_ids:
        st.markdown(f"### ğŸ› ï¸ å¯¹é€‰ä¸­çš„ {len(selected_ids)} ä¸ªä»»åŠ¡æ‰§è¡Œæ“ä½œ:")
        
        b1, b2, b3, b4 = st.columns(4)
        
        with b1:
            if st.button("â–¶ï¸ æ‰¹é‡æ¢å¤/å¼€å§‹", width="stretch"):
                db.batch_update_status(selected_ids, 'pending')
                st.success(f"å·²æ¢å¤ {len(selected_ids)} ä¸ªä»»åŠ¡")
                time.sleep(1)
                st.rerun()
                
        with b2:
            if st.button("â¸ï¸ æ‰¹é‡æš‚åœ", width="stretch"):
                db.batch_update_status(selected_ids, 'paused')
                st.success(f"å·²æš‚åœ {len(selected_ids)} ä¸ªä»»åŠ¡")
                time.sleep(1)
                st.rerun()
                
        with b3:
            if st.button("ğŸ”„ æ‰¹é‡é‡è¯• (å½’é›¶)", width="stretch"):
                # Retry implies pending + reset progress
                db.batch_update_status(selected_ids, 'pending')
                for jid in selected_ids:
                    db.update_job_progress(jid, 0, 3) # Reset to 0
                st.success(f"å·²é‡ç½® {len(selected_ids)} ä¸ªä»»åŠ¡")
                time.sleep(1)
                st.rerun()
                
        with b4:
            if st.button("ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤", type="primary", width="stretch"):
                db.batch_delete_jobs(selected_ids)
                st.success(f"å·²åˆ é™¤ {len(selected_ids)} ä¸ªä»»åŠ¡")
                time.sleep(1)
                st.rerun()
    else:
        # Show global cleanup if nothing selected
        st.caption("æç¤º: åœ¨ä¸Šæ–¹è¡¨æ ¼å‹¾é€‰ä»»åŠ¡åå¯è¿›è¡Œæ‰¹é‡æ“ä½œã€‚")
        with st.expander("æ›´å¤šå…¨å±€æ“ä½œ"):
            g1, g2 = st.columns(2)
            with g1:
                if st.button("ğŸ—‘ï¸ æ¸…ç†æ‰€æœ‰å·²å®Œæˆä»»åŠ¡"):
                    count = db.delete_completed_jobs()
                    st.success(f"æ¸…ç†äº† {count} ä¸ªå†å²ä»»åŠ¡")
                    time.sleep(1)
                    st.rerun()
            with g2:
                if st.button("âš ï¸ æš‚åœå…¨éƒ¨ä»»åŠ¡ (Panic Button)"):
                    active = db.get_jobs_by_status(['running', 'pending'])
                    ids = [j['id'] for j in active]
                    if ids:
                         db.batch_update_status(ids, 'paused')
                         st.success(f"å·²å¼ºåˆ¶æš‚åœ {len(ids)} ä¸ªæ´»è·ƒä»»åŠ¡")
                         time.sleep(1)
                         st.rerun()

