import streamlit as st
import pandas as pd
import json
import time
import os
import sys

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from service.case_db import CaseDatabase
from service.rule_db import RuleDatabase
from service.processor import ContentProcessor
from service.sanitizer import Sanitizer
from service.web_hunter import WebHunter
from core.config_manager import ConfigManager

def render():
    st.set_page_config(page_title="Crimson Vein æŒ–æ˜æ§åˆ¶å°", layout="wide")
    
    st.title("â›ï¸ å®æˆ˜æŒ–æ˜æ§åˆ¶å° (Mining Console)")
    st.caption("é¡¹ç›®ä»£å·ï¼šCrimson Vein | æ ¸å¿ƒç›®æ ‡ï¼šä»éç»“æ„åŒ–äº’è”ç½‘æ•°æ®ä¸­æç‚¼çœŸå®ç‰©ç†å‚æ•°")

    # Initialize Services
    case_db = CaseDatabase()
    rule_db = RuleDatabase()
    processor = ContentProcessor()
    
    # Main Layout
    tab_ops, tab_analysis = st.tabs(["ğŸ”¨ æŒ–æ˜æ“ä½œ (Operations)", "ğŸ§  æŒ–æ˜ååˆ†æ (Analysis)"])

    # ==========================================
    # Tab 1: Mining Operations (æŒ–æ˜æ“ä½œ)
    # ==========================================
    with tab_ops:
        col_op_l, col_op_r = st.columns([2, 1])
        
        with col_op_l:
            st.subheader("1. æŠ•å–‚æ•°æ®æº (Feed Data)")
            
            source_type = st.radio("é€‰æ‹©æ¥æºç±»å‹", ["ğŸ† åäºº/ç™¾ç§‘ç‹©çŒ (VIP Hunter)", "ğŸ¤– å…¨è‡ªåŠ¨æœçŒ (Auto-Pilot)", "ğŸŒ Web URL (è‡ªåŠ¨æŠ“å–)", "ğŸ“ æ–‡æœ¬ç²˜è´´ (æ‰‹åŠ¨)", "ğŸ“‚ æœ¬åœ°æ–‡ä»¶ (æ‰¹é‡)"], horizontal=True)
            
            # --- Type 1: Celebrity Hunter (Dedicated) ---
            if source_type == "ğŸ† åäºº/ç™¾ç§‘ç‹©çŒ (VIP Hunter)":
                st.info("ğŸ¯ ä¸“æ³¨äºã€Baike/Wiki ç”Ÿå¹³ã€‘+ã€åå®¶æ’ç›˜ã€‘çš„å®šå‘æŒ–æ˜ã€‚")
                st.markdown("æ­¤æ¨¡å¼å°†å¿½ç•¥è®ºå›å’Œæœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥æœç´¢åäººç™¾ç§‘ä¸æ’ç›˜åˆ†æã€‚")
                
                # Dictionary Status
                vip_count = 0
                dict_path = "data/dictionaries/celebrities.txt"
                if os.path.exists(dict_path):
                    with open(dict_path, "r") as f:
                        vip_count = len([l for l in f if l.strip() and not l.startswith("#")])
                        
                st.write(f"#### ğŸ“œ ç›®æ ‡å­—å…¸ (Target Dictionary)")
                st.caption(f"å·²åŠ è½½: **{vip_count}** ä½ | è·¯å¾„: `{dict_path}`")
                
                # Preview
                preview = []
                if os.path.exists(dict_path):
                     with open(dict_path) as f: 
                        preview = [l.strip() for l in f if l.strip() and not l.startswith("#")][:5]
                st.code("\n".join(preview)+"\n...", language="text")
                
                cycles = st.slider("ç›®æ ‡æ•°é‡ (Targets)", 1, 20, 5, help="æ¯æ¬¡ä»»åŠ¡éšæœºæŠ½å–çš„åäººæ•°é‡ã€‚")
                
                if st.button("ğŸ¹ å¯åŠ¨çŒå¤´è¡ŒåŠ¨ (Start Hunter)", type="primary"):
                    try:
                        from learning.db import LearningDB
                        ldb = LearningDB()
                    except ImportError: 
                        ldb = None
                        st.error("DB Load Failed")
                    
                    if ldb:
                        payload = {"type": "auto_mine", "cycles": cycles, "mode": "celebrity_only"}
                        ldb.create_job("auto_mine", target_file="VIP-Hunter-Job", payload=payload)
                        st.success(f"âœ… åäººç‹©çŒå·²å¯åŠ¨ (ç›®æ ‡: {cycles}äºº)ï¼")

            # --- Type 2: Auto-Pilot (Mixed) ---
            elif source_type == "ğŸ¤– å…¨è‡ªåŠ¨æœçŒ (Auto-Pilot)":
                st.info("ğŸš€ å¯åŠ¨æ··åˆæœçŒæ¨¡å¼ã€‚ç­–ç•¥ï¼šéšæœºåäºº -> æœ¬åœ°æ‰«æ -> è®ºå›æ·±æ½œ -> å…³é”®è¯æœç´¢ (Round Robin)ã€‚")
                from service.auto_miner import AutoMiner

                st.write("#### ğŸ“¡ æœç´¢æŒ‡ä»¤é›†")
                st.code("\n".join(AutoMiner.SEARCH_KEYWORDS[:3]) + "\n...", language="text")
                
                cycles = st.slider("æ‰§è¡Œå‘¨æœŸ (Cycles)", 1, 10, 3)
                
                # Configurable Local Mode
                cm = ConfigManager()
                current_local = cm.get("auto_miner_force_local", False)
                use_local_regex = st.checkbox("âš¡ çº¯æœ¬åœ°æé€Ÿæ¨¡å¼ (ä»…æ­£åˆ™)", value=current_local, help="å½±å“æœ¬åœ°æ–‡ä»¶çš„å¤„ç†æ–¹å¼ã€‚")
                
                if st.button("ğŸ”´ å¯åŠ¨æ··åˆé›†ç¾¤ (Engage Mixed Mode)", type="primary"):
                    cm.save_config("auto_miner_force_local", use_local_regex)
                    try:
                        from learning.db import LearningDB
                        ldb = LearningDB()
                    except ImportError: ldb = None
                        
                    if ldb:
                        payload = {"type": "auto_mine", "cycles": cycles, "mode": "mixed"}
                        ldb.create_job("auto_mine", target_file="Auto-Pilot-Mixed", payload=payload)
                        st.success("âœ… æ··åˆæœçŒä»»åŠ¡å·²å¯åŠ¨ï¼")

            elif source_type == "ğŸŒ Web URL (è‡ªåŠ¨æŠ“å–)":
                st.info("é€‚ç”¨äºï¼šåšå®¢æ–‡ç« ã€åäººä¼ è®°é¡µã€è®ºå›å¸–å­é¡µã€‚")
                url_input = st.text_input("ç›®æ ‡ URL", placeholder="https://www.astro.com/...")
                
                if st.button("ğŸ•·ï¸ å¯åŠ¨çŒäºº (Deploy Hunter)", type="primary", disabled=not url_input):
                    with st.status("æ­£åœ¨æ‰§è¡Œç‹©çŒä»»åŠ¡...", expanded=True) as status:
                        st.write("æ­£åœ¨è¿æ¥ç›®æ ‡æœåŠ¡å™¨...")
                        hunter = WebHunter()
                        success = hunter.hunt_from_url(url_input)
                        
                        if success:
                            status.update(label="ä»»åŠ¡å®Œæˆï¼", state="complete", expanded=False)
                            st.success("âœ… æŠ“å–æˆåŠŸï¼æ•°æ®å·²é€å…¥ã€æŒ–æ˜ååˆ†æã€‘æ¿å—ã€‚")
                        else:
                            status.update(label="ä»»åŠ¡å¤±è´¥", state="error")
                            st.error("æŠ“å–å¤±è´¥ï¼Œå¯èƒ½æ˜¯åçˆ¬è™«æ‹¦æˆªæˆ–å†…å®¹è¿‡çŸ­ã€‚")

            elif source_type == "ğŸ“ æ–‡æœ¬ç²˜è´´ (æ‰‹åŠ¨)":
                st.info("é€‚ç”¨äºï¼šå¿«é€Ÿæµ‹è¯•ã€ä»è§†é¢‘å­—å¹•å¤åˆ¶çš„ç‰‡æ®µã€‚")
                raw_text = st.text_area("ç²˜è´´å†…å®¹", height=250)
                manual_src = st.text_input("æ¥æºå¤‡æ³¨ (å¯é€‰)", placeholder="ä¾‹å¦‚ï¼šæŸæŸå¤§å¸ˆè§†é¢‘è¯¾ç¬¬3é›†")
                
                if st.button("ğŸš€ å¼€å§‹å¤„ç† (Process)", type="primary", disabled=not raw_text):
                    with st.spinner("æ­£åœ¨å‡€åŒ–ä¸æå–..."):
                        clean_text = Sanitizer.clean_text(raw_text)
                        processor.process_text(clean_text, source_url=f"Manual: {manual_src}")
                        st.success("å¤„ç†å®Œæˆï¼è¯·å‰å¾€ã€æŒ–æ˜ååˆ†æã€‘æŸ¥çœ‹ã€‚")

            elif source_type == "ğŸ“‚ æœ¬åœ°æ–‡ä»¶ (æ‰¹é‡)":
                st.info("ä»ã€å½±éŸ³ç ”ä¹ ã€‘æˆ–ã€å¤ç±å­¦ä¹ ã€‘å·²ä¸Šä¼ çš„è½¬å½•æ–‡æœ¬ä¸­æŒ–æ˜ã€‚")
                
                # Import LearningDB for job creation
                try:
                    from learning.db import LearningDB
                    ldb = LearningDB()
                except ImportError:
                    st.error("æ— æ³•åŠ è½½ LearningDBã€‚è¯·æ£€æŸ¥ learning æ¨¡å—ã€‚")
                    ldb = None
                
                if ldb:
                    book_dir = "data/books"
                    if not os.path.exists(book_dir):
                        os.makedirs(book_dir)
                    
                    files = [f for f in os.listdir(book_dir) if f.endswith(".txt")]
                    if not files:
                        st.warning("data/books ç›®å½•ä¸‹æ²¡æœ‰æ–‡æœ¬æ–‡ä»¶ã€‚è¯·å…ˆå»ã€è‡ªæˆ‘è¿›åŒ–ã€‘->ã€å½±éŸ³/å¤ç±ã€‘ä¸Šä¼ ã€‚")
                    else:
                        # --- Prepare Data for Editor ---
                        # Use session state to persist selection across reruns if needed, 
                        # but for simple batch action, reconstruction is fine.
                        
                        # --- Robust State Management ---
                        if "file_mining_list" not in st.session_state:
                            # Initial Load
                            file_data = []
                            for f in files:
                                path = os.path.join(book_dir, f)
                                size_kb = os.path.getsize(path) / 1024
                                ftype = "ğŸ¥ å½±éŸ³ç¬”è®°" if "[Video]" in f or "[Media]" in f else "ğŸ“œ å¤ç±/æ–‡æœ¬"
                                file_data.append({
                                    "Select": False,
                                    "Filename": f,
                                    "Type": ftype,
                                    "Size (KB)": round(size_kb, 1)
                                })
                            st.session_state["file_mining_list"] = file_data
                        
                        # Use data from session state
                        df_display = pd.DataFrame(st.session_state["file_mining_list"])

                        # --- Controls Toolbar ---
                        c_tool1, c_tool2, c_tool3 = st.columns([1, 1, 2])
                        
                        if c_tool1.button("âœ… å…¨é€‰"):
                            for item in st.session_state["file_mining_list"]:
                                item["Select"] = True
                            st.rerun()
                            
                        if c_tool2.button("â¬œ å…¨ä¸é€‰"):
                            for item in st.session_state["file_mining_list"]:
                                item["Select"] = False
                            st.rerun()
                            
                        sort_opt = c_tool3.selectbox("æ’åºæ–¹å¼", ["Filename", "Size (KB)", "Type"], label_visibility="collapsed")
                        
                        # --- LLM Control ---
                        st.markdown("---")
                        c_llm, c_launch = st.columns([1, 1])
                        
                        use_llm = c_llm.checkbox("ğŸ§  å¯ç”¨ DeepSeek LLM æ·±åº¦åˆ†æ (æ…¢é€Ÿä½†ç²¾å‡†)", value=False, help="è‹¥é€‰ä¸­ï¼Œå°†è°ƒç”¨äº‘ç«¯æˆ–æœ¬åœ° LLM è¿›è¡Œé€å¥åˆ†æï¼›è‹¥ä¸é€‰ï¼Œä»…ä½¿ç”¨æ­£åˆ™æé€ŸåŒ¹é…ã€‚")
                        
                        # Apply Sorting strictly for display (Session state order remains stable)
                        if sort_opt == "Size (KB)":
                            df_display = df_display.sort_values(by="Size (KB)", ascending=False)
                        elif sort_opt == "Type":
                            df_display = df_display.sort_values(by="Type")
                        else:
                            df_display = df_display.sort_values(by="Filename")
                        
                        editor_key = "file_mining_editor"
                        
                        # Actual Editor
                        edited_df = st.data_editor(
                            df_display,
                            column_config={
                                "Select": st.column_config.CheckboxColumn("é€‰æ‹©", width="small"),
                                "Filename": st.column_config.TextColumn("æ–‡ä»¶å", width="large"),
                                "Type": st.column_config.TextColumn("ç±»å‹", width="medium"),
                                "Size (KB)": st.column_config.NumberColumn("å¤§å° (KB)"),
                            },
                            disabled=["Filename", "Type", "Size (KB)"],
                            hide_index=True,
                            use_container_width=True,
                            key=editor_key
                        )
                        
                        # Process Button
                        target_files = edited_df[edited_df["Select"] == True]["Filename"].tolist()
                        
                        st.caption(f"å·²é€‰æ‹©: {len(target_files)} ä¸ªæ–‡ä»¶")
                        
                        if c_launch.button("â›ï¸ å¯åŠ¨æ·±åº¦æŒ–æ˜ä»»åŠ¡ (Start Deep Mining Job)", type="primary", disabled=len(target_files)==0):
                            # SAVE CONFIG FIRST
                            cm = ConfigManager()
                            # If use_llm is Checked, force_local should be False
                            cm.save_config("auto_miner_force_local", not use_llm)
                            
                            count = 0
                            for fname in target_files:
                                payload = {
                                    "type": "case_mine", 
                                    "filename": fname,
                                    "target_db": "cases.db"
                                }
                                ldb.create_job("case_mine", target_file=fname, payload=payload)
                                count += 1
                            
                            st.success(f"ğŸš€ å·²åˆ›å»º {count} ä¸ªåå°ä»»åŠ¡ï¼")
                            st.info(f"Worker å°†åœ¨åå°è¯»å–æ–‡ä»¶ï¼Œæå–æ¡ˆä¾‹å¹¶å­˜å…¥ CaseDBã€‚\næ¨¡å¼: {'ğŸ”¥ æ·±åº¦ LLM åˆ†æ' if use_llm else 'âš¡ æé€Ÿæ­£åˆ™åŒ¹é…'}")

        with col_op_r:
            st.subheader("2. å®æ—¶ç›‘æ§ (Monitor)")
            with st.container(border=True):
                st.metric("ä»Šæ—¥å·²æŒ–æ˜æ¡ˆä¾‹", len(case_db.get_all_cases_meta()), delta="+2")
                st.metric("å¾…å®¡æ ¸è§„åˆ™", 0) # TODO: Connect to RuleDB count
                st.markdown("---")
                st.caption("ç³»ç»Ÿæ—¥å¿—")
                st.code("System Ready...\nMiner Alpha loaded.\nCaseDB connected.", language="bash")

    # ==========================================
    # Tab 2: Post-Mining Analysis (æŒ–æ˜ååˆ†æ)
    # ==========================================
    with tab_analysis:
        sub_tab_cases, sub_tab_rules = st.tabs(["ğŸ“‚ æ¡ˆä¾‹åº“ (Case Library)", "ğŸ“œ è§„åˆ™åº“ (Rule Library)"])
        
        # --- Case Library ---
        with sub_tab_cases:
            st.markdown("### çœŸå®å…«å­—æ¡ˆä¾‹åº“")
            
            # Load Data
            metadata = case_db.get_all_cases_meta()
            if metadata:
                df_meta = pd.DataFrame(metadata)
                
                # Selection Table
                st.dataframe(
                    df_meta,
                    column_config={
                        "id": st.column_config.TextColumn("ID", width="small"),
                        "name": st.column_config.TextColumn("å§“å", width="medium"),
                        "quality_tier": st.column_config.TextColumn("è´¨é‡ç­‰çº§", width="small"),
                    },
                    use_container_width=True,
                    hide_index=True
                )
                
                col_sel, col_view = st.columns([1, 2])
                with col_sel:
                    selected_case_id = st.selectbox("é€‰æ‹©æ¡ˆä¾‹æŸ¥çœ‹è¯¦æƒ…", df_meta['id'].tolist(), format_func=lambda x: f"{x} - {df_meta[df_meta['id']==x]['name'].values[0]}")
                
                if selected_case_id:
                    case = case_db.get_case(selected_case_id)
                    with col_view:
                        with st.container(border=True):
                            c1, c2 = st.columns(2)
                            c1.markdown(f"**å§“å**: {case.get('name', 'Unknown')}")
                            c2.markdown(f"**Tier**: {case.get('quality_tier', 'N/A')}")
                            
                            # Safety check for profile
                            profile_data = case.get('profile')
                            if not profile_data:
                                # Fallback for legacy/flat data
                                profile_data = {
                                    "name": case.get('name'),
                                    "gender": case.get('gender'),
                                    "birth_year": case.get('birth_year'),
                                    "birth_date": f"{case.get('birth_year')}-{case.get('birth_month')}-{case.get('birth_day')}",
                                    "birth_time": f"{case.get('birth_hour')}:{case.get('birth_minute')}"
                                }
                            st.json(profile_data, expanded=False)
                            
                            st.markdown("#### ğŸ“… äººç”Ÿå¤§äº‹éªŒè¯é›†")
                            st.dataframe(pd.DataFrame(case['life_events']), hide_index=True)
                            
                            st.markdown("#### âœ… ç®—æ³•éªŒè¯æ“ä½œ")
                            if st.button("ğŸ§ª è¿è¡Œç‰©ç†å†…æ ¸å›æµ‹ (Run Kernel Validation)", key="btn_validate", type="primary"):
                                st.toast("æ­£åœ¨å¯åŠ¨ V32.0 ç‰©ç†å¼•æ“...", icon="ğŸ”¥")
                                time.sleep(1)
                                st.info("æ­£åœ¨è®¡ç®—æµå¹´èƒ½é‡åˆ†å¸ƒ...")
                                time.sleep(1)
                                st.warning("âš ï¸ éªŒè¯å¼•æ“å°šæœªè¿æ¥çœŸå®å†…æ ¸ (Mock Result)")
                                st.write("é¢„æµ‹ç»“æœ: 2008å¹´ [å‹åŠ›æé«˜] (åŒ¹é…åº¦ 95%)")
            else:
                st.info("æ¡ˆä¾‹åº“ä¸ºç©ºï¼Œè¯·å…ˆå»ã€æŒ–æ˜æ“ä½œã€‘è¿›è´§ã€‚")

        # --- Rule Library ---
        with sub_tab_rules:
            st.markdown("### å‘½ç†è§„åˆ™çŸ¥è¯†åº“")
            st.caption("æ­¤å¤„å­˜æ”¾ä»æ–‡æœ¬ä¸­æå–çš„ç†è®ºé€»è¾‘ (å¦‚ 'ä¼¤å®˜è§å®˜')ã€‚")
            
            conn = rule_db._get_conn()
            try:
                df_rules = pd.read_sql("SELECT * FROM rules", conn)
                st.dataframe(df_rules, use_container_width=True)
            except:
                st.info("è§„åˆ™åº“ä¸ºç©ºã€‚")
            conn.close()

if __name__ == "__main__":
    render()
