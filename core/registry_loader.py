"""
QGA æ³¨å†Œè¡¨é©±åŠ¨å™¨ (Registry Loader)
å®ç°ä»JSONæ³¨å†Œè¡¨è¯»å–é…ç½®å¹¶è‡ªåŠ¨è°ƒç”¨å¼•æ“è¿›è¡Œè®¡ç®—

åŸºäºQGA-HR V3.0è§„èŒƒï¼Œæ”¯æŒï¼š
- feature_anchorsï¼ˆè´¨å¿ƒé”šç‚¹ç³»ç»Ÿï¼‰
- pattern_recognitionï¼ˆStep 6æ ¼å±€è¯†åˆ«ï¼‰
- @configå¼•ç”¨è§£æï¼ˆFDS-V3.0é…ç½®è·¯ç”±ï¼‰
- Schema V3.0å…¼å®¹
"""

import json
from pathlib import Path
from typing import Dict, List, Optional, Any
import logging

from core.math_engine import (
    sigmoid_variant,
    tensor_normalize,
    calculate_s_balance,
    calculate_flow_factor,
    phase_change_determination,
    calculate_cosine_similarity,
    calculate_centroid,
    calculate_mahalanobis_distance,
    calculate_precision_score
)
from core.physics_engine import (
    compute_energy_flux,
    calculate_interaction_damping,
    calculate_clash_count,
    check_trigger,
    calculate_integrity_alpha,
    check_clash,
    check_combination
)
from core.math_engine import project_tensor_with_matrix
from core.trinity.core.middleware.influence_bus import InfluenceBus
from core.trinity.core.middleware.temporal_factors import TemporalInjectionFactor
from core.trinity.core.engines.structural_vibration import StructuralVibrationEngine
from core.config import config

# [FDS-LKV] åˆè§„æ€§è·¯ç”±å™¨ï¼ˆå»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–ï¼‰
_compliance_router = None

def _get_compliance_router():
    """å»¶è¿Ÿè·å–åˆè§„æ€§è·¯ç”±å™¨ï¼ˆé¿å…å¯åŠ¨æ—¶å¾ªç¯å¯¼å…¥ï¼‰"""
    global _compliance_router
    if _compliance_router is None:
        try:
            from core.compliance_router import get_compliance_router
            _compliance_router = get_compliance_router()
        except ImportError:
            logger.warning("âš ï¸ FDS-LKV åˆè§„æ€§è·¯ç”±å™¨æœªå®‰è£…ï¼Œè·³è¿‡åˆè§„æ€§æ£€æŸ¥")
            _compliance_router = None
    return _compliance_router

logger = logging.getLogger(__name__)

def count_vaults_helper(chart: List[str]) -> int:
    """Calculates the number of earth branches (vaults) in a chart."""
    vaults = {'è¾°', 'æˆŒ', 'ä¸‘', 'æœª'}
    count = 0
    for pillar in chart:
        if len(pillar) >= 2 and pillar[1] in vaults:
            count += 1
    return count


class RegistryLoader:
    """
    æ³¨å†Œè¡¨é©±åŠ¨å™¨
    
    èŒè´£ï¼š
    - è¯»å–QGA-HRæ³¨å†Œè¡¨é…ç½®
    - è‡ªåŠ¨è°ƒç”¨æ•°å­¦å’Œç‰©ç†å¼•æ“è¿›è¡Œè®¡ç®—
    - æ”¯æŒä»»æ„æ ¼å±€çš„ç®—æ³•å¤åŸ
    """
    
    def __init__(self, registry_path: Optional[Path] = None, theme_id: Optional[str] = None):
        """
        åˆå§‹åŒ–æ³¨å†Œè¡¨é©±åŠ¨å™¨
        
        Args:
            registry_path: æ³¨å†Œè¡¨æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨holographic_patternæ³¨å†Œè¡¨ï¼‰
            theme_id: ä¸»é¢˜IDï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªåŠ¨é€‰æ‹©æ³¨å†Œè¡¨è·¯å¾„ï¼‰
                - "HOLOGRAPHIC_PATTERN": ä½¿ç”¨ holographic_pattern/registry.json
                - "BAZI_FUNDAMENTAL": ä½¿ç”¨ bazi_fundamental/registry.json
                - "PATTERN_PHYSICS": ä½¿ç”¨ physical_simulation/registry.json
        """
        if registry_path is None:
            project_root = Path(__file__).resolve().parents[1]
            if theme_id == "BAZI_FUNDAMENTAL":
                registry_path = project_root / "core" / "subjects" / "bazi_fundamental" / "registry.json"
            elif theme_id == "FRAMEWORK_UTILITIES":
                registry_path = project_root / "core" / "subjects" / "framework_utilities" / "registry.json"
            elif theme_id == "PATTERN_PHYSICS":
                registry_path = project_root / "core" / "subjects" / "physical_simulation" / "registry.json"
            else:
                # é»˜è®¤ä½¿ç”¨ holographic_pattern
                registry_path = project_root / "core" / "subjects" / "holographic_pattern" / "registry.json"
        
        self.registry_path = registry_path
        self.registry = None
        self.theme_id = theme_id
        self._compliance_enabled = True  # [FDS-LKV] åˆè§„æ€§æ£€æŸ¥å¼€å…³
        self._singularity_cache = {}  # [FDS-LKV] å¥‡ç‚¹é¢„çƒ­ç¼“å­˜
        self._load_registry()
    
    def resolve_config_ref(self, ref_path: str) -> Any:
        """
        è§£æé…ç½®å¼•ç”¨è·¯å¾„ï¼ˆFDS-V3.0ï¼‰
        
        Args:
            ref_path: é…ç½®å¼•ç”¨è·¯å¾„ï¼Œæ ¼å¼ä¸º '@config.xxx.yyy.zzz' æˆ–æ™®é€šå€¼
            
        Returns:
            é…ç½®å€¼ï¼Œå¦‚æœæ˜¯éå¼•ç”¨åˆ™ç›´æ¥è¿”å›åŸå€¼
        """
        if not isinstance(ref_path, str) or not ref_path.startswith('@config.'):
            return ref_path
        
        try:
            return config.resolve_config_ref(ref_path)
        except KeyError as e:
            logger.error(f"é…ç½®å¼•ç”¨è§£æå¤±è´¥: {ref_path}, é”™è¯¯: {e}")
            raise ValueError(f"Invalid config reference: {ref_path}") from e
    
    def resolve_config_refs_in_dict(self, data: Any) -> Any:
        """
        é€’å½’è§£æå­—å…¸/åˆ—è¡¨ä¸­çš„æ‰€æœ‰@configå¼•ç”¨ï¼ˆFDS-V3.0ï¼‰
        
        Args:
            data: éœ€è¦è§£æçš„æ•°æ®ï¼ˆå¯ä»¥æ˜¯dictã€listæˆ–å…¶ä»–ç±»å‹ï¼‰
            
        Returns:
            è§£æåçš„æ•°æ®ï¼Œæ‰€æœ‰@configå¼•ç”¨éƒ½è¢«æ›¿æ¢ä¸ºå®é™…é…ç½®å€¼
        """
        if isinstance(data, dict):
            resolved = {}
            for key, value in data.items():
                # é€’å½’è®¡ç®—å·²è§£æçš„å€¼
                resolved_val = self.resolve_config_refs_in_dict(value)
                resolved[key] = resolved_val
                
                # å¦‚æœkeyæœ¬èº«åŒ…å«_refåç¼€ï¼Œä¸”å€¼æ˜¯@configå¼•ç”¨
                if key.endswith('_ref') and isinstance(value, str) and value.startswith('@config.'):
                    # åœ¨åŒåå­—æ®µï¼ˆæ— _refåç¼€ï¼‰å­˜å‚¨è§£æåçš„æ•°å­—
                    base_key = key[:-4]  # ç§»é™¤'_ref'åç¼€
                    resolved[base_key] = resolved_val
                    logger.debug(f"è§£æå¹¶æ˜ å°„ {key} -> {base_key}: {resolved_val}")
            return resolved
        elif isinstance(data, list):
            return [self.resolve_config_refs_in_dict(item) for item in data]
        elif isinstance(data, str) and data.startswith('@config.'):
            return self.resolve_config_ref(data)
        else:
            return data
    
    def _load_registry(self):
        """åŠ è½½æ³¨å†Œè¡¨"""
        try:
            with open(self.registry_path, 'r', encoding='utf-8') as f:
                self.registry = json.load(f)
            logger.info(f"âœ… å·²åŠ è½½æ³¨å†Œè¡¨: {self.registry_path}")
        except Exception as e:
            logger.error(f"åŠ è½½æ³¨å†Œè¡¨å¤±è´¥: {e}")
            self.registry = {"patterns": {}, "metadata": {}}
    
    def get_pattern(self, pattern_id: str) -> Optional[Dict]:
        """
        è·å–æ ¼å±€é…ç½®ï¼Œæ”¯æŒåµŒå¥—æŸ¥æ‰¾ (V2.5+)
        """
        if not self.registry:
            return None
        
        patterns = self.registry.get('patterns', {})
        
        # 1. ç›´æ¥æŸ¥æ‰¾
        if pattern_id in patterns:
            return patterns[pattern_id]
        
        # 2. åµŒå¥—æŸ¥æ‰¾
        for pid, data in patterns.items():
            sub_patterns_list = data.get('sub_patterns_registry') or data.get('sub_patterns') or []
            if sub_patterns_list:
                for sub in sub_patterns_list:
                    if sub.get('id') == pattern_id:
                        # è‡ªåŠ¨åˆå¹¶çˆ¶æ ¼å±€å±æ€§
                        combined = sub.copy()
                        
                        # æ ¸å¿ƒç»§æ‰¿ï¼šç‰ˆæœ¬ä¸ç‰©ç†è§„æ ¼
                        if 'version' not in combined:
                            combined['version'] = data.get('version', '2.5')
                        if 'meta_info' not in combined:
                            combined['meta_info'] = data.get('meta_info', {})
                        if 'physics_kernel' not in combined and 'physics_kernel' in data:
                            combined['physics_kernel'] = data['physics_kernel']
                        
                        # [V2.5.3] åŠ¨æ€çŠ¶æ€æ˜ å°„ç»§æ‰¿
                        if 'dynamic_states' not in combined and 'dynamic_states' in data:
                            combined['dynamic_states'] = data['dynamic_states']
                        
                        # å…ƒæ•°æ®ç»§æ‰¿
                        combined['parent_pattern'] = pid
                        if 'category' not in combined:
                            combined['category'] = data.get('category')
                        if 'subject_id' not in combined:
                            combined['subject_id'] = sub.get('id')
                        
                        return combined
        
        return None
    
    def get_pattern_by_id(self, pattern_id: str) -> Optional[Dict]:
        """
        è·å–æ ¼å±€é…ç½®ï¼ˆåˆ«åæ–¹æ³•ï¼Œä¸get_patternç›¸åŒï¼‰
        
        Args:
            pattern_id: æ ¼å±€IDï¼ˆå¦‚'A-03'ï¼‰
            
        Returns:
            æ ¼å±€é…ç½®å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        return self.get_pattern(pattern_id)
    
    # =========================================================================
    # [FDS-LKV] åˆè§„æ€§è·¯ç”±ä¸å¥‡ç‚¹é¢„çƒ­
    # =========================================================================
    
    def precheck_compliance(
        self, 
        pattern_id: str, 
        pattern_config: Dict = None,
        strict_mode: bool = False
    ) -> Dict[str, Any]:
        """
        [FDS-LKV] åˆè§„æ€§å…ˆéªŒæ£€æŸ¥ (Pre-check Protocol)
        
        æ£€ç´¢è¯­ä¹‰åº“ä¸­çš„"ä¸‰å¤§ç‰©ç†å…¬ç†"ï¼ŒéªŒè¯æ ¼å±€é…ç½®æ˜¯å¦ç¬¦åˆè§„èŒƒã€‚
        
        Args:
            pattern_id: æ ¼å±€ ID
            pattern_config: æ ¼å±€é…ç½®ï¼ˆå¦‚æœä¸º Noneï¼Œè‡ªåŠ¨ä»æ³¨å†Œè¡¨è·å–ï¼‰
            strict_mode: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆè¿è§„æ—¶æŠ›å‡ºå¼‚å¸¸ï¼‰
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸
        """
        if not self._compliance_enabled:
            return {"compliant": True, "skipped": True, "reason": "åˆè§„æ€§æ£€æŸ¥å·²ç¦ç”¨"}
        
        router = _get_compliance_router()
        if router is None:
            return {"compliant": True, "skipped": True, "reason": "åˆè§„æ€§è·¯ç”±å™¨æœªå°±ç»ª"}
        
        if pattern_config is None:
            pattern_config = self.get_pattern(pattern_id) or {}
        
        try:
            result = router.precheck_pattern(pattern_id, pattern_config, strict_mode)
            if result.get("compliant"):
                logger.debug(f"âœ… æ ¼å±€ {pattern_id} é€šè¿‡åˆè§„æ€§æ£€æŸ¥")
            else:
                logger.warning(f"âš ï¸ æ ¼å±€ {pattern_id} åˆè§„æ€§æ£€æŸ¥å‘ç°é—®é¢˜: {result.get('violations')}")
            return result
        except Exception as e:
            logger.warning(f"åˆè§„æ€§æ£€æŸ¥å¼‚å¸¸: {e}")
            return {"compliant": True, "skipped": True, "error": str(e)}
    
    def warmup_singularities(self, pattern_id: str) -> Dict[str, Any]:
        """
        [FDS-LKV] å¥‡ç‚¹é¢„çƒ­ (Singularity Warm-up)
        
        ä»å¥‡ç‚¹åº“é¢„å–ä¸æŒ‡å®šæ ¼å±€ç›¸å…³çš„å¥‡ç‚¹æ ·æœ¬ï¼Œç¼“å­˜åˆ°å†…å­˜ä¸­åŠ é€Ÿåç»­ KNN æ£€ç´¢ã€‚
        
        Args:
            pattern_id: æ ¼å±€ ID
            
        Returns:
            é¢„çƒ­ç»“æœ
        """
        if pattern_id in self._singularity_cache:
            return {"cached": True, "count": len(self._singularity_cache[pattern_id])}
        
        router = _get_compliance_router()
        if router is None:
            return {"cached": False, "error": "åˆè§„æ€§è·¯ç”±å™¨æœªå°±ç»ª"}
        
        try:
            from core.vault_manager import get_vault_manager
            vault = get_vault_manager()
            
            # æ£€ç´¢è¯¥æ ¼å±€çš„æ‰€æœ‰å¥‡ç‚¹
            results = vault.singularity_vault.get(
                where={"pattern_id": pattern_id},
                include=["embeddings", "metadatas"]
            )
            
            if results and results.get("ids"):
                benchmarks = []
                embeddings = results.get("embeddings")
                metadatas = results.get("metadatas")
                for i, case_id in enumerate(results["ids"]):
                    tensor = None
                    if embeddings is not None and len(embeddings) > i:
                        tensor = list(embeddings[i]) if hasattr(embeddings[i], 'tolist') else embeddings[i]
                    meta = metadatas[i] if metadatas is not None and len(metadatas) > i else {}
                    benchmarks.append({
                        "case_id": case_id,
                        "tensor": tensor,
                        "metadata": meta
                    })
                self._singularity_cache[pattern_id] = benchmarks
                logger.info(f"ğŸ”¥ å¥‡ç‚¹é¢„çƒ­å®Œæˆ: {pattern_id} ({len(benchmarks)} æ ·æœ¬)")
                return {"cached": True, "count": len(benchmarks)}
            else:
                self._singularity_cache[pattern_id] = []
                return {"cached": True, "count": 0}
                
        except Exception as e:
            logger.warning(f"å¥‡ç‚¹é¢„çƒ­å¤±è´¥: {e}")
            return {"cached": False, "error": str(e)}
    
    def traceback_singularity(
        self, 
        tensor_5d: List[float],
        mahalanobis_distance: float,
        pattern_id: str = None,
        threshold: float = 2.5
    ) -> Optional[Dict[str, Any]]:
        """
        [FDS-LKV] å¥‡ç‚¹æº¯æº (Trace-back Protocol)
        
        å½“é©¬æ°è·ç¦»è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œæ£€ç´¢æœ€è¿‘çš„å¥‡ç‚¹æ ·æœ¬ã€‚
        
        Args:
            tensor_5d: å½“å‰å…«å­—çš„ 5D å¼ é‡
            mahalanobis_distance: è®¡ç®—å¾—åˆ°çš„é©¬æ°è·ç¦»
            pattern_id: æ ¼å±€ IDï¼ˆå¯é€‰ï¼Œç”¨äºè¿‡æ»¤ï¼‰
            threshold: è§¦å‘é˜ˆå€¼
            
        Returns:
            æ£€ç´¢ç»“æœï¼ˆå¦‚æœæœªè§¦å‘åˆ™è¿”å› Noneï¼‰
        """
        router = _get_compliance_router()
        if router is None:
            return None
        
        return router.traceback_singularity(
            tensor_5d=tensor_5d,
            mahalanobis_distance=mahalanobis_distance,
            threshold=threshold,
            pattern_filter=pattern_id
        )

    
    def get_feature_anchors(self, pattern_id: str) -> Optional[Dict]:
        """
        è·å–æ ¼å±€çš„feature_anchorsï¼ˆV2.0æ–°å¢ï¼‰
        
        Args:
            pattern_id: æ ¼å±€IDï¼ˆå¦‚'A-03'ï¼‰
            
        Returns:
            feature_anchorså­—å…¸ï¼ŒåŒ…å«standard_centroidå’Œsingularity_centroids
            å¦‚æœä¸å­˜åœ¨æˆ–ç‰ˆæœ¬ä¸æ˜¯V2.0ï¼Œè¿”å›None
        """
        pattern = self.get_pattern(pattern_id)
        if not pattern:
            return None
        
        # æ£€æŸ¥ç‰ˆæœ¬
        version = pattern.get('version')
        if not version:
            version = pattern.get('meta_info', {}).get('version', '1.0')
            
        # æ”¯æŒV2.0+å’ŒV3.0
        if not (version.startswith('2.') or version.startswith('3.')):
            logger.warning(f"æ ¼å±€ {pattern_id} ç‰ˆæœ¬ä¸º {version}ï¼Œä¸æ”¯æŒfeature_anchorsï¼ˆéœ€è¦V2.0+ï¼‰")
            return None
        
        # å…¼å®¹æ€§é€‚é…ï¼šæ£€æŸ¥æ˜¯å¦æœ‰sub_patterns/sub_patterns_registry (Schema V2.5/V3.0)
        sub_patterns = pattern.get('sub_patterns_registry') or pattern.get('sub_patterns')
        if sub_patterns:
            anchors = {'singularity_centroids': []}
            for sp in sub_patterns:
                # æ‰å¹³åŒ– manifold_data æˆ– manifold_stats (V3.0ä½¿ç”¨manifold_data)
                stats = sp.get('manifold_data', {}) or sp.get('manifold_stats', {})
                # å¤åˆ¶spå†…å®¹åˆ°anchor
                anchor = sp.copy()
                # å¦‚æœstatsæ˜¯dictï¼Œæ›´æ–°åˆ°anchorä¸­ï¼ˆmean_vector, covariance_matrix, thresholdsç­‰ï¼‰
                if isinstance(stats, dict):
                    anchor.update(stats) # mean_vector, covariance_matrix, thresholds ç­‰ä¸Šæµ®
                anchor.pop('manifold_stats', None)
                anchor.pop('manifold_data', None)  # æ¸…ç†åŸå§‹å­—æ®µ
                
                # [V3.0] è§£æthresholdsä¸­çš„é…ç½®å¼•ç”¨
                if 'thresholds' in anchor and isinstance(anchor['thresholds'], dict):
                    resolved_thresholds = self.resolve_config_refs_in_dict(anchor['thresholds'])
                    anchor['thresholds'] = resolved_thresholds
                
                # æ˜ å°„ vector (å…¼å®¹æ—§ç‰ˆä»£ç )
                if 'mean_vector' in anchor:
                    anchor['vector'] = anchor['mean_vector']
                
                # åˆ†ç±»æ˜ å°„
                sp_id = sp.get('id', '')
                if 'STANDARD' in sp_id or sp.get('population_priority') == 'Tier A':
                    anchors['standard_manifold'] = anchor
                else:
                    # ä»»ä½•éæ ‡å‡†çš„éƒ½è§†ä¸ºå¥‡ç‚¹/æ¿€æ´»æ€
                    anchors['singularity_centroids'].append(anchor)
                    # å¦å¤–ï¼Œç‰¹ä¾‹æ˜ å°„: SP_A03_VAULT -> activated_manifold
                    if 'VAULT' in sp_id or 'ACTIVATED' in sp_id:
                        anchors['activated_manifold'] = anchor
                        # ç¡®ä¿ sub_id å­˜åœ¨ (ç”¨äº pattern_recognition)
                        anchor['sub_id'] = sp_id
            
            return anchors

        # [V2.5/V3.0 Leaf Node Fix] å¦‚æœæœ¬èº«å°±æ˜¯å­æ ¼å±€ï¼Œå¯èƒ½ç›´æ¥æŒæœ‰ manifold_data æˆ– manifold_stats
        manifold_data = pattern.get('manifold_data') or pattern.get('manifold_stats')
        if manifold_data:
            anchor = pattern.copy()
            if isinstance(manifold_data, dict):
                anchor.update(manifold_data)
            anchor.pop('manifold_stats', None)
            anchor.pop('manifold_data', None)  # æ¸…ç†åŸå§‹å­—æ®µ
            
            # [V3.0] è§£æthresholdsä¸­çš„é…ç½®å¼•ç”¨
            if 'thresholds' in anchor and isinstance(anchor['thresholds'], dict):
                resolved_thresholds = self.resolve_config_refs_in_dict(anchor['thresholds'])
                anchor['thresholds'] = resolved_thresholds
            if 'mean_vector' in anchor:
                anchor['vector'] = anchor['mean_vector']
            
            # åˆ¤æ–­å®ƒæ˜¯å“ªç§æµå½¢
            sp_id = pattern.get('id', '')
            if 'VAULT' in sp_id or 'ACTIVATED' in sp_id:
                return {
                    'activated_manifold': anchor,
                    'standard_manifold': anchor, # å…œåº•ï¼Œé˜²æ­¢ recognition æ‰¾ä¸åˆ°åŸºå‡†
                    'singularity_centroids': [anchor]
                }
            else:
                return {
                    'standard_manifold': anchor,
                    'singularity_centroids': []
                }

        return pattern.get('feature_anchors')
    
    def pattern_recognition(
        self,
        current_tensor: Dict[str, float],
        pattern_id: str,
        dynamic_state: Optional[str] = None,
        sai: float = 1.0
    ) -> Dict[str, Any]:
        """
        åŠ¨æ€æ ¼å±€è¯†åˆ«ï¼ˆStep 6ï¼‰
        
        åŸºäºç©ºé—´ç›¸ä¼¼åº¦çš„è‡ªåŠ¨å¸é™„æœºåˆ¶ï¼Œåˆ¤æ–­å½“å‰å…«å­—æ˜¯å¦å±äºæŒ‡å®šæ ¼å±€
        æ”¯æŒå¤šæ€è§‚æµ‹ï¼šæ ¹æ® dynamic_state è‡ªåŠ¨åˆ‡æ¢é”šç‚¹åŸºå‡† (V2.3)
        [V1.5 Upgrade] å¼•å…¥é©¬æ°è·ç¦» (Mahalanobis) ä¸æ¦‚ç‡å¯†åº¦ (PDF) è¯„åˆ†
        
        Args:
            current_tensor: å½“å‰å…«å­—çš„5ç»´æŠ•å½±å€¼ï¼ˆåŸå±€åŸºæ€ï¼Œå¿…é¡»å½’ä¸€åŒ–ï¼‰
            pattern_id: æ ¼å±€IDï¼ˆå¦‚'A-03'ï¼‰
            dynamic_state: å½“å‰åŠ¨åŠ›å­¦çŠ¶æ€ (å¦‚ 'STABLE', 'ACTIVATED')
            sai: ç³»ç»Ÿå¯¹é½æŒ‡æ•°ï¼ˆèƒ½é‡å¼ºåº¦ï¼‰
            
        Returns:
            è¯†åˆ«ç»“æœå­—å…¸
        """
        # 1. è·å–æ ¼å±€é…ç½®å’Œfeature_anchors
        pattern = self.get_pattern(pattern_id)
        if not pattern:
            return {
                'matched': False,
                'pattern_type': 'BROKEN',
                'similarity': 0.0,
                'anchor_id': None,
                'resonance': False,
                'description': f'æ ¼å±€ {pattern_id} ä¸å­˜åœ¨'
            }
        
        feature_anchors = self.get_feature_anchors(pattern_id)
        if not feature_anchors:
            return {
                'matched': False,
                'pattern_type': 'BROKEN',
                'similarity': 0.0,
                'anchor_id': None,
                'resonance': False,
                'description': f'æ ¼å±€ {pattern_id} ç¼ºå°‘feature_anchorsï¼ˆéœ€è¦V2.0+ï¼‰'
            }
        
        # 2. éªŒè¯current_tensorå·²å½’ä¸€åŒ–
        total = sum(abs(v) for v in current_tensor.values())
        if abs(total - 1.0) > 0.01:
            logger.warning(f"current_tensoræœªå½’ä¸€åŒ–ï¼ˆæ€»å’Œ={total:.6f}ï¼‰ï¼Œè‡ªåŠ¨å½’ä¸€åŒ–")
            current_tensor = tensor_normalize(current_tensor)
        
        # 3. è®¡ç®—ä¸ç›®æ ‡é”šç‚¹çš„ç›¸ä¼¼åº¦ (æµå½¢è·¯ç”± V2.4)
        target_manifold_id = 'standard_manifold'
        manifold = feature_anchors.get('standard_manifold')
        
        # [V2.4 Manifold Protocol] 
        # æ ¹æ® dynamic_state åˆ‡æ¢è§‚æµ‹æµå½¢
        if dynamic_state in ['ACTIVATED', 'TRANSFORMED', 'VOLATILE']:
            activated_manifold = feature_anchors.get('activated_manifold')
            if activated_manifold:
                manifold = activated_manifold
                target_manifold_id = 'activated_manifold'
                logger.info(f"Observer: Switching to 'activated_manifold' for {pattern_id} due to Phase Transition.")

        if not manifold:
            return {
                'matched': False,
                'pattern_type': 'BROKEN',
                'similarity': 0.0,
                'anchor_id': None,
                'resonance': False,
                'description': f'æ ¼å±€ {pattern_id} ç¼ºå°‘è§‚æµ‹æµå½¢ ({target_manifold_id})'
            }
        
        mean_vector = manifold.get('mean_vector', manifold.get('vector', {})) # å…¼å®¹æ—§ç‰ˆ
        # è·å–é˜ˆå€¼é…ç½®ï¼šä¼˜å…ˆä»manifold.thresholdsï¼Œå…¶æ¬¡ä»feature_anchorsæ ¹çº§ï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
        thresholds = manifold.get('thresholds', {})
        # å¦‚æœmanifoldä¸­æ²¡æœ‰thresholdsï¼Œå°è¯•ä»feature_anchorsæ ¹çº§è·å–
        if not thresholds:
            thresholds = feature_anchors.get('thresholds', {})
        
        # [V3.0] ç¡®ä¿thresholdsä¸­çš„é…ç½®å¼•ç”¨å·²è§£æï¼ˆå¦‚æœä¹‹å‰æœªè§£æï¼‰
        if isinstance(thresholds, dict):
            thresholds = self.resolve_config_refs_in_dict(thresholds)
        
        # V3.1ä¿®æ­£ï¼šæé«˜åŒ¹é…é˜ˆå€¼è‡³0.7ï¼Œé¿å…æ³›åŒ–è¿‡åº¦ï¼Œå°†æˆæ ¼ç‡æ§åˆ¶åœ¨åˆç†åŒºé—´(10-18%)
        match_threshold = thresholds.get('match_threshold', manifold.get('match_threshold', 0.7))
        
        # è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥åæ–¹å·®çŸ©é˜µæ˜¯å¦å­˜åœ¨
        cov = manifold.get('covariance_matrix')
        if not cov:
            logger.warning(f"âš ï¸ æ ¼å±€ {pattern_id} çš„æµå½¢ {target_manifold_id} ç¼ºå°‘ covariance_matrixï¼Œå°†ä½¿ç”¨æ¬§å¼è·ç¦»")
        
        # [V1.5 Fix] å¼ºåˆ¶å¯¹é½ç‰¹å¾é”šç‚¹çš„å°ºåº¦ (Scale Alignment)
        # å¦‚æœç‰¹å¾é”šç‚¹çš„æ€»åƒç´ ä¸ä¸º1.0ï¼Œåˆ™è¿›è¡Œå½’ä¸€åŒ–ï¼Œç¡®ä¿é©¬æ°è·ç¦»è®¡ç®—åœ¨åŒä¸€ç‰©ç†ç©ºé—´
        ref_total = sum(abs(v) for v in mean_vector.values())
        if abs(ref_total - 1.0) > 0.05:
            logger.info(f"Observer: Normalizing mean_vector scale ({ref_total:.4f} -> 1.0)")
            mean_vector = tensor_normalize(mean_vector)

        # 1. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ (Direction)
        standard_similarity = calculate_cosine_similarity(current_tensor, mean_vector)
        
        # 2. [V1.5] è®¡ç®—é©¬æ°è·ç¦» (Statistical Distribution)
        m_dist = 0.0
        precision_score = standard_similarity 
        
        import numpy as np
        inv_cov = manifold.get('inverse_covariance')
        cov = manifold.get('covariance_matrix')
        
        inv_cov_np = np.array(inv_cov) if inv_cov else None
        cov_np = np.array(cov) if cov else None

        if inv_cov_np is not None or cov_np is not None:
            m_dist = calculate_mahalanobis_distance(
                current_tensor, 
                mean_vector, 
                covariance_matrix=cov_np, 
                inverse_covariance=inv_cov_np
            )
            
            # 3. [FDS-V3.0] è®¡ç®—ç²¾å¯†è¯„åˆ† (Precision Score)
            precision_score = calculate_precision_score(standard_similarity, m_dist, sai)
            logger.info(f"FDS-V3.0 Precision Check: Similarity={standard_similarity:.4f}, M-Dist={m_dist:.4f}, Final Score={precision_score:.4f}")

        # 4. èƒ½é‡é—¨æ§ (SAI Gating)
        # [V3.0] æ”¯æŒä»thresholdsè·å–ï¼Œæˆ–ä»max_mahalanobis_dist_refé…ç½®å¼•ç”¨è§£æ
        min_sai = thresholds.get('min_sai_gating', 0.5)
        # max_mahalanobis_dist_ref åº”è¯¥å·²ç»åœ¨resolve_config_refs_in_dictä¸­è§£æ
        max_m_dist = thresholds.get('max_mahalanobis_dist', thresholds.get('max_mahalanobis_dist_ref', 3.0))
        
        is_matched = precision_score > match_threshold
        
        # V2.4 ç²¾å¯†åˆ¤å®šï¼šå¿…é¡»æ»¡è¶³é©¬æ°è·ç¦»ä¸èƒ½é‡é—¨æ§çº¦æŸ
        if m_dist > max_m_dist:
            logger.warning(f"Precision Gating: M-Dist {m_dist:.4f} exceeds threshold {max_m_dist}")
            is_matched = False
            
        if sai < min_sai:
            logger.warning(f"SAI Gating: SAI {sai:.4f} below threshold {min_sai}")
            is_matched = False
            
        # 4. åˆ¤å®šå†³ç­– (Decision Logic V2.4)
        perfect_threshold = thresholds.get('perfect_threshold', 0.92)
        
        # Check for singularities first
        singularity_centroids = feature_anchors.get('singularity_centroids', [])
        best_singularity = None
        best_singularity_sim = 0.0
        
        for singularity in singularity_centroids:
            sing_vec = singularity.get('vector', {})
            sim = calculate_cosine_similarity(current_tensor, sing_vec)
            if sim > best_singularity_sim:
                best_singularity_sim = sim
                best_singularity = singularity
        
        if best_singularity and best_singularity_sim > 0.90:
            if best_singularity_sim > standard_similarity + 0.03:
                return {
                    'matched': True,
                    'pattern_type': 'SINGULARITY',
                    'similarity': best_singularity_sim,
                    'anchor_id': best_singularity.get('sub_id', 'unknown'),
                    'resonance': best_singularity_sim > perfect_threshold,
                    'description': f"é«˜åº¦åŒ¹é…å¥‡ç‚¹å˜ä½“ {best_singularity.get('sub_id', 'unknown')}",
                    'risk_level': best_singularity.get('risk_level', 'UNKNOWN'),
                    'special_instruction': best_singularity.get('special_instruction')
                }
        
        # Final Match Decision
        if is_matched:
            p_tag = 'STANDARD' if target_manifold_id == 'standard_manifold' else 'ACTIVATED'
            return {
                'matched': True,
                'pattern_type': p_tag,
                'similarity': standard_similarity,
                'mahalanobis_dist': m_dist,
                'precision_score': precision_score,
                'anchor_id': target_manifold_id,
                'resonance': precision_score > perfect_threshold,
                'description': f"ç²¾å¯†è§‚æµ‹åŒ¹é… ({p_tag})ï¼Œè¯„åˆ† {precision_score:.4f}",
                'risk_level': None,
                'special_instruction': None
            }
        
        # ç ´æ ¼ (Broken) vs è¾¹ç¼˜ (Marginal)
        # V3.1ä¿®æ­£ï¼šç»Ÿä¸€ä½¿ç”¨match_thresholdåˆ¤æ–­ï¼Œé¿å…ç¡¬ç¼–ç 
        if precision_score < match_threshold:
            return {
                'matched': False,
                'pattern_type': 'BROKEN',
                'similarity': standard_similarity,
                'mahalanobis_dist': m_dist,
                'precision_score': precision_score,
                'anchor_id': None,
                'resonance': False,
                'description': f"ç‰©ç†ç ´æ ¼ï¼Œè¯„åˆ† {precision_score:.4f} < {match_threshold:.2f}",
                'risk_level': None,
                'special_instruction': None
            }
        
        return {
            'matched': False,
            'pattern_type': 'MARGINAL',
            'similarity': standard_similarity,
            'mahalanobis_dist': m_dist,
            'precision_score': precision_score,
            'anchor_id': None,
            'resonance': False,
            'description': f"è¾¹ç¼˜çŠ¶æ€ï¼Œè¯„åˆ† {precision_score:.4f}",
            'risk_level': None,
            'special_instruction': None
        }
    
    def calculate_tensor_projection_from_registry(
        self,
        pattern_id: str,
        chart: List[str],
        day_master: str,
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ä»æ³¨å†Œè¡¨è¯»å–é…ç½®å¹¶è®¡ç®—äº”ç»´å¼ é‡æŠ•å½±
        
        è¿™æ˜¯æ ¸å¿ƒå‡½æ•°ï¼šå®ç°100%ç®—æ³•å¤åŸ
        
        Args:
            pattern_id: æ ¼å±€IDï¼ˆå¦‚'A-03'ï¼‰
            chart: å››æŸ±å…«å­—
            day_master: æ—¥ä¸»
            context: ä¸Šä¸‹æ–‡ï¼ˆå¤§è¿ã€æµå¹´ç­‰ï¼Œå¯é€‰ï¼‰
            
        Returns:
            è®¡ç®—ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - projection: äº”ç»´æŠ•å½± {'E': float, 'O': float, 'M': float, 'S': float, 'R': float}
            - sai: ç³»ç»Ÿå¯¹é½æŒ‡æ•°
            - energies: åŸºç¡€èƒ½é‡ {'E_blade': float, 'E_kill': float, 'E_seal': float}
            - s_balance: å¹³è¡¡åº¦
            - phase_change: ç›¸å˜çŠ¶æ€
        """
        # 1. è·å–æ ¼å±€é…ç½®
        pattern = self.get_pattern(pattern_id)
        if not pattern:
            return {'error': f'æ ¼å±€ {pattern_id} ä¸å­˜åœ¨'}
        
        # æ£€æŸ¥ç‰ˆæœ¬ (ä¼˜å…ˆæ£€æŸ¥rootï¼Œå…¶æ¬¡æ£€æŸ¥meta_info)
        version = pattern.get('version')
        if not version:
            version = pattern.get('meta_info', {}).get('version', '1.0')
            
        is_v2 = str(version).startswith('2.')
        is_v3 = str(version).startswith('3.')
        has_matrix = pattern.get('physics_kernel', {}).get('transfer_matrix') is not None
        
        # [V3.0] å¦‚æœæ˜¯V3.0ï¼Œå…ˆè§£ææ‰€æœ‰@configå¼•ç”¨
        if is_v3:
            pattern = self.resolve_config_refs_in_dict(pattern)
        
        # V2.1+/V1.5+/V3.0+: ä½¿ç”¨transfer_matrix (Protocol V2.1, V2.2, V2.3, V2.5+, V3.0)
        if is_v2 or is_v3 or str(version) >= '1.5' or has_matrix:
            # [V2.5] Pattern Routing Protocol
            active_pattern = pattern
            sub_id = None
            
            router = pattern.get('matching_router', {})
            if router and router.get('strategies'):
                # Execute routing logic
                for strategy in router['strategies']:
                    target_id = strategy.get('target')
                    logic = strategy.get('logic', '')
                    
                    if strategy.get('priority') == 3 and logic == 'default':
                        # Standard Fallback
                        break
                    
                    # Compute preliminary projection (V1.5 Heuristic)
                    bj = compute_energy_flux(chart, day_master, "æ¯”è‚©")
                    jc = compute_energy_flux(chart, day_master, "åŠ«è´¢")
                    zy = compute_energy_flux(chart, day_master, "æ­£å°")
                    py = compute_energy_flux(chart, day_master, "åå°")
                    zc = compute_energy_flux(chart, day_master, "æ­£è´¢")
                    pc = compute_energy_flux(chart, day_master, "åè´¢")
                    
                    # E = bj + jc + 0.8*resource
                    # M = zc + pc
                    # E = bj + jc + 0.8*resource
                    # M = zc + pc
                    e_est = bj + jc + 0.5 * (zy + py)
                    m_est = zc + pc
                    
                    # O = dg + qg (Direct Officer + Seven Killings)
                    dg = compute_energy_flux(chart, day_master, "æ­£å®˜")
                    qg = compute_energy_flux(chart, day_master, "ä¸ƒæ€")
                    o_est = dg + qg

                    # S & R Estimation (V2.4)
                    clash_cnt = calculate_clash_count(chart)
                    s_est = qg + 0.8 * clash_cnt - 0.5 * (zy + py) # Approx from D-02 Kernel

                    # R Estimation
                    # Simple combination count helper
                    comb_cnt = 0
                    branches = [p[1] for p in chart]
                    for i in range(len(branches)):
                        for j in range(i+1, len(branches)):
                            from core.physics_engine import check_combination # Ensure import availability
                            if check_combination(branches[i], branches[j]):
                                comb_cnt += 1
                                
                    r_est = comb_cnt * 1.0 + bj * 0.5 + jc * 0.3 # Approx from D-02 Kernel_Row_R
                    
                    v_count = count_vaults_helper(chart)
                    
                    match = False
                    
                    # Protocol V2.5/V3.0: Support JSON Logic
                    if isinstance(logic, dict) and logic.get("rules"):
                        # V3.0 format: logic = {"condition": "AND", "rules": [...]}
                        rules = logic.get("rules", [])
                        condition_type = logic.get("condition", "AND").upper()
                        conditions_met = []
                        
                        for cond in rules:
                            axis = cond.get("axis")
                            op = cond.get("operator")
                            
                            # [V3.0] æ”¯æŒparam_refå¼•ç”¨é…ç½®ï¼Œfallbackåˆ°value
                            val = None
                            if "param_ref" in cond:
                                val = self.resolve_config_ref(cond["param_ref"])
                            elif "value" in cond:
                                val = cond["value"]
                            else:
                                logger.warning(f"è·¯ç”±è§„åˆ™ç¼ºå°‘valueæˆ–param_ref: {cond}")
                                continue
                            
                            current_val = 0.0
                            if axis == "E": current_val = e_est
                            elif axis == "M": current_val = m_est
                            elif axis == "O": current_val = o_est
                            elif axis == "S": current_val = s_est
                            elif axis == "R": current_val = r_est
                            
                            cond_result = False
                            if op == "gt": cond_result = current_val > val
                            elif op == "gte": cond_result = current_val >= val
                            elif op == "lt": cond_result = current_val < val
                            elif op == "lte": cond_result = current_val <= val
                            elif op == "eq": cond_result = abs(current_val - val) < 0.01
                            
                            conditions_met.append(cond_result)
                        
                        # æ ¹æ®conditionç±»å‹åˆ¤æ–­
                        if condition_type == "AND":
                            match = all(conditions_met) if conditions_met else False
                        elif condition_type == "OR":
                            match = any(conditions_met) if conditions_met else False
                        else:
                            match = all(conditions_met) if conditions_met else False  # é»˜è®¤AND
                            
                    elif isinstance(logic, list):
                        # Legacy V2.5 format: logic = [{...}, {...}]
                        conditions_met = True
                        for cond in logic:
                            axis = cond.get("axis")
                            op = cond.get("operator")
                            val = cond.get("value", 0.0)
                            
                            current_val = 0.0
                            if axis == "E": current_val = e_est
                            elif axis == "M": current_val = m_est
                            elif axis == "O": current_val = o_est
                            elif axis == "S": current_val = s_est
                            elif axis == "R": current_val = r_est
                            
                            if op == "gt" and not (current_val > val): conditions_met = False
                            elif op == "gte" and not (current_val >= val): conditions_met = False
                            elif op == "lt" and not (current_val < val): conditions_met = False
                            elif op == "lte" and not (current_val <= val): conditions_met = False
                            
                            if not conditions_met: break
                        
                        match = conditions_met

                    # Legacy String Logic
                    elif isinstance(logic, str):
                        # D-01 Logic
                        if "E < 0.15" in logic and e_est < 0.20 and m_est > 0.8: match = True
                        if "vault_count >= 3" in logic and v_count >= 3: match = True
                        
                        # A-03 Logic (FDS-V1.5.1)
                        if "vault_count >= 2" in logic and v_count >= 2: match = True
                        
                        if "E < 0.35" in logic and "O > 0.55" in logic:
                             # SP_A03_OVERKILL
                             if e_est < 0.40 and o_est > 0.50: match = True # Relaxed slightly for heuristics
                        
                        if "E > 0.65" in logic and "O < 0.25" in logic:
                             # SP_A03_NO_CONTROL
                             if e_est > 0.60 and o_est < 0.30: match = True
                    
                    if match:
                        sub_patterns = pattern.get('sub_patterns_registry') or pattern.get('sub_patterns') or []
                        for sp in sub_patterns:
                            if sp.get('id') == target_id:
                                active_pattern = sp
                                sub_id = target_id
                                # Apply matrix_override immediately for accurate final calculation
                                override = sp.get('matrix_override', {})
                                if override.get('transfer_matrix'):
                                    transfer_matrix = override['transfer_matrix']
                                logger.info(f"Router redirection triggered: {pattern_id} -> {sub_id}")
                                break
                        if sub_id: break

            physics_kernel = pattern.get('physics_kernel', {})
            # [V2.5] Support nested matrix_override
            transfer_matrix = active_pattern.get('matrix_override', {}).get('transfer_matrix') or \
                              physics_kernel.get('transfer_matrix')
            
            if transfer_matrix:
                res = self._calculate_with_transfer_matrix(
                    pattern_id, chart, day_master, transfer_matrix, context
                )
                if sub_id: res['sub_id'] = sub_id
                return res
        
        # V2.0/V1.0: ä½¿ç”¨æ—§çš„tensor_operatoré€»è¾‘
        tensor_operator = pattern.get('tensor_operator', {})
        if not tensor_operator:
            return {'error': f'æ ¼å±€ {pattern_id} ç¼ºå°‘tensor_operatoré…ç½®'}
        
        # 2. è·å–æƒé‡ï¼ˆV2.0ä¼˜å…ˆä½¿ç”¨feature_anchors.standard_centroid.vectorï¼Œå¦åˆ™ä½¿ç”¨tensor_operator.weightsï¼‰
        weights = None
        if is_v2:
            feature_anchors = self.get_feature_anchors(pattern_id)
            if feature_anchors and feature_anchors.get('standard_centroid'):
                weights = feature_anchors['standard_centroid'].get('vector')
                logger.debug(f"ä½¿ç”¨V2.0 feature_anchors.standard_centroid.vectorä½œä¸ºæƒé‡")
        
        if not weights:
            weights = tensor_operator.get('weights', {})
            if not weights:
                return {'error': f'æ ¼å±€ {pattern_id} ç¼ºå°‘æƒé‡é…ç½®'}
        
        # 3. éªŒè¯å½’ä¸€åŒ–
        total = sum(abs(v) for v in weights.values())
        if abs(total - 1.0) > 0.01:
            weights = tensor_normalize(weights)
            logger.warning(f"æ ¼å±€ {pattern_id} æƒé‡æœªå½’ä¸€åŒ–ï¼ˆæ€»å’Œ={total:.6f}ï¼‰ï¼Œå·²è‡ªåŠ¨å½’ä¸€åŒ–")
        
        # 4. è®¡ç®—åŸºç¡€èƒ½é‡ï¼ˆä»æ³¨å†Œè¡¨çš„æ ¸å¿ƒæ–¹ç¨‹è·å–å˜é‡ï¼‰
        core_equation = tensor_operator.get('core_equation', '')
        
        # è§£ææ ¸å¿ƒæ–¹ç¨‹ï¼Œæå–éœ€è¦çš„èƒ½é‡ç±»å‹
        # ä¾‹å¦‚ï¼šS_balance = E_blade / E_kill
        energies = {}
        
        if 'E_blade' in core_equation or 'blade' in core_equation.lower():
            # è®¡ç®—ç¾Šåˆƒèƒ½é‡
            energies['E_blade'] = compute_energy_flux(chart, day_master, 'ç¾Šåˆƒ')
        
        if 'E_kill' in core_equation or 'kill' in core_equation.lower():
            # è®¡ç®—ä¸ƒæ€èƒ½é‡
            energies['E_kill'] = compute_energy_flux(chart, day_master, 'ä¸ƒæ€')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰flow_factoréœ€è¦E_seal
        flow_factor = tensor_operator.get('flow_factor', {})
        if flow_factor and 'E_seal' in flow_factor.get('formula', ''):
            # è®¡ç®—å°æ˜Ÿèƒ½é‡ï¼ˆæ­£å°+åå°ï¼‰
            energies['E_seal'] = (
                compute_energy_flux(chart, day_master, 'æ­£å°') +
                compute_energy_flux(chart, day_master, 'åå°')
            )
        
        # 5. è®¡ç®—æ ¸å¿ƒæ–¹ç¨‹ï¼ˆå¦‚S_balanceï¼‰
        s_balance = None
        if 'E_blade' in energies and 'E_kill' in energies:
            s_balance = calculate_s_balance(energies['E_blade'], energies['E_kill'])
        
        # 6. è®¡ç®—Flow Factorï¼ˆå¦‚æœé€‚ç”¨ï¼‰
        s_base = None
        if 'E_seal' in energies and flow_factor:
            # è¿™é‡Œéœ€è¦å…ˆè®¡ç®—åŸºç¡€åº”åŠ›ï¼Œç®€åŒ–å¤„ç†
            clash_count = calculate_clash_count(chart)
            s_base = abs(energies.get('E_blade', 0) - energies.get('E_kill', 0)) + 0.5 * clash_count
            s_risk = calculate_flow_factor(s_base, energies['E_seal'])
        else:
            s_risk = None
        
        # 7. è®¡ç®—SAIï¼ˆç³»ç»Ÿå¯¹é½æŒ‡æ•°ï¼‰
        # ç®€åŒ–ï¼šä½¿ç”¨åŸºç¡€èƒ½é‡è®¡ç®—SAI
        # å®é™…åº”è¯¥è°ƒç”¨æ¡†æ¶çš„arbitrate_baziï¼Œè¿™é‡Œå…ˆç®€åŒ–
        sai = sum(energies.values()) * 10.0  # ä¸´æ—¶è®¡ç®—ï¼Œå®é™…åº”ä»æ¡†æ¶è·å–
        
        # 8. è®¡ç®—äº”ç»´æŠ•å½±
        projection = {
            'E': sai * weights.get('E', 0.0),
            'O': sai * weights.get('O', 0.0),
            'M': sai * weights.get('M', 0.0),
            'S': sai * weights.get('S', 0.0),
            'R': sai * weights.get('R', 0.0)
        }
        
        # 9. ç›¸å˜åˆ¤å®šï¼ˆå¦‚æœé…ç½®äº†æ¿€æ´»å‡½æ•°ï¼‰
        activation = tensor_operator.get('activation_function', {})
        phase_change = None
        dynamic_state = "STABLE"
        
        # [V2.5 Phase Transition Logic]
        # é¦–å…ˆæ„å»ºå®Œæ•´çš„Contextç”¨äºçŠ¶æ€æ£€æŸ¥
        day_branch = chart[2][1] if len(chart) > 2 and len(chart[2]) > 1 else ""
        luck_pillar = context.get('luck_pillar', "") if context else ""
        year_pillar = context.get('year_pillar', "") if context else ""
        
        # è°ƒç”¨ _check_pattern_state è·å–åŠ¨åŠ›å­¦çŠ¶æ€
        # Mock alpha=1.0 for initial check
        dynamic_result = self._check_pattern_state(
            pattern, chart, day_master, day_branch, luck_pillar, year_pillar, 1.0
        )
        
        if dynamic_result:
            dynamic_state = dynamic_result.get('state', 'STABLE')
            phase_change = dynamic_result # ä¿å­˜å®Œæ•´ç»“æœ
            logger.info(f"Dynamic State Determined: {dynamic_state} (Trigger: {dynamic_result.get('trigger')})")
        
        if activation and not phase_change:
            threshold = activation.get('parameters', {}).get('collapse_threshold', 0.8)
            # ç®€åŒ–ï¼šä½¿ç”¨S_balanceä½œä¸ºèƒ½é‡æŒ‡æ ‡
            if s_balance:
                normalized_energy = min(s_balance / 2.0, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
                phase_change_val = phase_change_determination(
                    normalized_energy,
                    threshold=threshold,
                    trigger=False  # è¿™é‡Œéœ€è¦æ ¹æ®contextåˆ¤æ–­æ˜¯å¦æœ‰è§¦å‘
                )
                if phase_change_val:
                     phase_change = {'state': phase_change_val}

        # 10. V2.0: å¦‚æœå­˜åœ¨feature_anchorsï¼Œæ‰§è¡Œæ ¼å±€è¯†åˆ«
        recognition_result = None
        if is_v2:
            # å½’ä¸€åŒ–projectionä½œä¸ºcurrent_tensorï¼ˆç”¨äºæ ¼å±€è¯†åˆ«ï¼‰
            normalized_projection = tensor_normalize(projection)
            # [Fix] Pass dynamic_state to enable Manifold Switching
            recognition_result = self.pattern_recognition(
                normalized_projection, 
                pattern_id, 
                dynamic_state=dynamic_state,
                sai=sai
            )
        
        result = {
            'pattern_id': pattern_id,
            'pattern_name': pattern.get('name', pattern_id),
            'version': version,
            'projection': projection,
            'sai': sai,
            'energies': energies,
            's_balance': s_balance,
            's_risk': s_risk,
            'phase_change': phase_change,
            'weights': weights
        }
        
        # æ·»åŠ V2.0è¯†åˆ«ç»“æœ
        if recognition_result:
            result['recognition'] = recognition_result
        
        return result
    
    def simulate_dynamic_event(
        self,
        pattern_id: str,
        chart: List[str],
        day_master: str,
        event_type: str = 'clash',
        event_params: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        æ¨¡æ‹ŸåŠ¨æ€äº‹ä»¶ï¼ˆå¦‚æµå¹´å†²åˆƒï¼‰
        
        Args:
            pattern_id: æ ¼å±€ID
            chart: å››æŸ±å…«å­—
            day_master: æ—¥ä¸»
            event_type: äº‹ä»¶ç±»å‹ï¼ˆå¦‚'clash'ï¼‰
            event_params: äº‹ä»¶å‚æ•°ï¼ˆå¦‚{'clash_branch': 'å­'}ï¼‰
            
        Returns:
            ä»¿çœŸç»“æœå­—å…¸
        """
        pattern = self.get_pattern(pattern_id)
        if not pattern:
            return {'error': f'æ ¼å±€ {pattern_id} ä¸å­˜åœ¨'}
        
        kinetic_evolution = pattern.get('kinetic_evolution', {})
        dynamic_sim = kinetic_evolution.get('dynamic_simulation', {})
        
        if not dynamic_sim:
            return {'error': f'æ ¼å±€ {pattern_id} ç¼ºå°‘dynamic_simulationé…ç½®'}
        
        # è·å–lambdaç³»æ•°
        lambda_coefficients = dynamic_sim.get('lambda_coefficients', {})
        fracture_threshold = dynamic_sim.get('fracture_threshold', 50.0)
        
        # è®¡ç®—åŸºç¡€åº”åŠ›ï¼ˆç®€åŒ–ï¼šä»projectionè·å–ï¼‰
        result = self.calculate_tensor_projection_from_registry(pattern_id, chart, day_master)
        s_base = result['projection'].get('S', 0.0)
        
        # æ ¹æ®äº‹ä»¶ç±»å‹è®¡ç®—lambda
        if event_type == 'clash' and event_params:
            month_branch = chart[1][1]  # æœˆæ”¯
            clash_branch = event_params.get('clash_branch')
            
            if clash_branch:
                # æå–lambdaç³»æ•°å€¼ï¼ˆä»åµŒå¥—å­—å…¸ä¸­æå–ï¼‰
                lambda_dict = {}
                if isinstance(lambda_coefficients, dict):
                    for key, value in lambda_coefficients.items():
                        if isinstance(value, dict):
                            lambda_dict[key] = value.get('value', 1.8)
                        else:
                            lambda_dict[key] = value
                
                lambda_val = calculate_interaction_damping(
                    chart,
                    month_branch,
                    clash_branch,
                    lambda_dict
                )
                
                # è®¡ç®—æ–°åº”åŠ›
                s_new = s_base * lambda_val
                is_collapse = s_new >= fracture_threshold
                
                return {
                    'pattern_id': pattern_id,
                    'event_type': event_type,
                    's_base': s_base,
                    'lambda': lambda_val,
                    's_new': s_new,
                    'fracture_threshold': fracture_threshold,
                    'is_collapse': is_collapse,
                    'status': 'COLLAPSE' if is_collapse else 'SURVIVAL'
                }
        
        return {'error': 'ä¸æ”¯æŒçš„äº‹ä»¶ç±»å‹æˆ–ç¼ºå°‘å¿…è¦å‚æ•°'}
    
    def _check_pattern_state(
        self,
        pattern: Dict[str, Any],
        chart: List[str],
        day_master: str,
        day_branch: str,
        luck_pillar: str,
        year_pillar: str,
        alpha: float
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥æˆæ ¼/ç ´æ ¼çŠ¶æ€ï¼ˆFDS-V1.4ï¼‰
        
        Args:
            pattern: æ ¼å±€é…ç½®
            chart: å››æŸ±å…«å­—
            day_master: æ—¥ä¸»
            day_branch: æ—¥æ”¯
            luck_pillar: å¤§è¿å¹²æ”¯
            year_pillar: æµå¹´å¹²æ”¯
            alpha: ç»“æ„å®Œæ•´æ€§alphaå€¼
            
        Returns:
            æ ¼å±€çŠ¶æ€å­—å…¸ï¼ŒåŒ…å«stateã€alphaã€matrixç­‰
        """
        dynamic_states = pattern.get('dynamic_states', {})
        collapse_rules = dynamic_states.get('collapse_rules', [])
        crystallization_rules = dynamic_states.get('crystallization_rules', [])
        # [V3.0] å¤„ç†integrity_thresholdå¼•ç”¨
        integrity_threshold_ref = pattern.get('physics_kernel', {}).get('integrity_threshold_ref')
        if integrity_threshold_ref:
            integrity_threshold = self.resolve_config_ref(integrity_threshold_ref)
        else:
            integrity_threshold = pattern.get('physics_kernel', {}).get('integrity_threshold', 0.45)
        
        # æ„å»ºcontext
        energy_flux = {
            "wealth": compute_energy_flux(chart, day_master, "åè´¢") + 
                      compute_energy_flux(chart, day_master, "æ­£è´¢"),
            "resource": compute_energy_flux(chart, day_master, "æ­£å°") + 
                       compute_energy_flux(chart, day_master, "åå°")
        }
        
        context = {
            "chart": chart,
            "day_master": day_master,
            "day_branch": day_branch,
            "luck_pillar": luck_pillar,
            "year_pillar": year_pillar,
            "energy_flux": energy_flux
        }
        
        # æ£€æŸ¥ç ´æ ¼æ¡ä»¶
        for rule in collapse_rules:
            trigger_name = rule.get('trigger')
            if trigger_name and check_trigger(trigger_name, context):
                # [V2.3] Check for exceptions
                exceptions = rule.get('exceptions', [])
                for exc in exceptions:
                    if self._check_exception(exc, context):
                        override = exc.get('override_state', {})
                        return {
                            "state": override.get('state', "ACTIVATED"),
                            "alpha": alpha,
                            "matrix": pattern.get('id'),
                            "trigger": trigger_name,
                            "exception": exc.get('name'),
                            "tensor_modifier": override.get('tensor_modifier'),
                            "centroid_ref": override.get('centroid_ref')
                        }
                
                return {
                    "state": rule.get('default_action', "COLLAPSED"),
                    "alpha": alpha,
                    "matrix": rule.get('fallback_matrix', 'Standard'),
                    "trigger": trigger_name,
                    "action": rule.get('action')
                }
        
        # æ£€æŸ¥æˆæ ¼æ¡ä»¶
        for rule in crystallization_rules:
            condition_name = rule.get('condition')
            if condition_name and check_trigger(condition_name, context):
                return {
                    "state": "CRYSTALLIZED",
                    "alpha": alpha,
                    "matrix": rule.get('target_matrix', pattern.get('id')),
                    "trigger": condition_name,
                    "action": rule.get('action'),
                    "validity": rule.get('validity', 'Permanent')
                }
        
        # æ ¹æ®alphaåˆ¤æ–­
        if alpha < integrity_threshold:
            return {
                "state": "COLLAPSED",
                "alpha": alpha,
                "matrix": "Standard",
                "trigger": "Low_Integrity"
            }
        
        return {
            "state": "STABLE",
            "alpha": alpha,
            "matrix": pattern.get('id', 'Standard')
        }

    def _check_exception(self, exception_def: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """
        [V2.3] æ£€æŸ¥å¼‚å¸¸è±å…æ¡ä»¶
        """
        conditions = exception_def.get('conditions', [])
        logic = exception_def.get('logic', 'AND')
        
        results = []
        for cond in conditions:
            operator = cond.get('operator')
            if operator == "call_physics":
                # è°ƒç”¨ç‰©ç†å¼•æ“ç®—å­
                func_name = cond.get('function')
                args_keys = cond.get('args', [])
                
                # è§£æå‚æ•°
                args = []
                for key in args_keys:
                    if key == "$day_branch":
                        args.append(context.get('day_branch'))
                    elif key == "$year_branch":
                        year_pillar = context.get('year_pillar')
                        args.append(year_pillar[1] if year_pillar and len(year_pillar) >= 2 else "")
                    else:
                        args.append(context.get(key.lstrip('$')))
                
                # æ‰§è¡Œè°ƒç”¨
                import core.physics_engine as physics
                if hasattr(physics, func_name):
                    func = getattr(physics, func_name)
                    res = func(*args)
                    
                    # æ£€æŸ¥æœŸæœ›å€¼
                    expect = cond.get('expect', {})
                    match = True
                    for k, v in expect.items():
                        if isinstance(v, dict):
                            if "gt" in v and not (res.get(k, 0) > v["gt"]): match = False
                            if "lt" in v and not (res.get(k, 0) < v["lt"]): match = False
                        elif res.get(k) != v:
                            match = False
                    results.append(match)
                else:
                    results.append(False)
        
        if not results:
            return False
            
        if logic == 'AND':
            return all(results)
        return any(results)
    
    def _calculate_with_transfer_matrix(
        self,
        pattern_id: str,
        chart: List[str],
        day_master: str,
        transfer_matrix: Dict[str, Dict[str, float]],
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨transfer_matrixè®¡ç®—äº”ç»´å¼ é‡æŠ•å½±ï¼ˆV2.1ä¸“ç”¨ï¼‰
        
        Args:
            pattern_id: æ ¼å±€ID
            chart: å››æŸ±å…«å­—
            day_master: æ—¥ä¸»
            transfer_matrix: 5x5è½¬æ¢çŸ©é˜µ
            context: ä¸Šä¸‹æ–‡ï¼ˆå¤§è¿ã€æµå¹´ç­‰ï¼Œå¯é€‰ï¼‰
            
        Returns:
            è®¡ç®—ç»“æœå­—å…¸ï¼ŒåŒ…å«projectionã€saiç­‰
        """
        bj = compute_energy_flux(chart, day_master, "æ¯”è‚©")
        jc = compute_energy_flux(chart, day_master, "åŠ«è´¢")
        ss = compute_energy_flux(chart, day_master, "é£Ÿç¥")
        sg = compute_energy_flux(chart, day_master, "ä¼¤å®˜")
        pc = compute_energy_flux(chart, day_master, "åè´¢")
        zc = compute_energy_flux(chart, day_master, "æ­£è´¢")
        qs = compute_energy_flux(chart, day_master, "ä¸ƒæ€")
        zg = compute_energy_flux(chart, day_master, "æ­£å®˜")
        py = compute_energy_flux(chart, day_master, "åå°")
        zy = compute_energy_flux(chart, day_master, "æ­£å°")

        frequency_vector = {
            "bi_jian": bj,
            "jie_cai": jc,
            "shi_shen": ss,
            "shang_guan": sg,
            "pian_cai": pc,
            "zheng_cai": zc,
            "qi_sha": qs,
            "zheng_guan": zg,
            "pian_yin": py,
            "zheng_yin": zy,
            # [LEGACY COMPAT] ä¿æŒèšåˆå­—æ®µ
            "parallel": bj + jc,
            "resource": zy + py,
            "power": zg + qs,
            "wealth": zc + pc,
            "output": ss + sg
        }
        
        # 2. [V1.4] Use InfluenceBus for Environmental Arbitration (No Hardcoding)
        bus = InfluenceBus()
        bus.register(TemporalInjectionFactor())
        
        # Prepare context for the bus
        context = context or {}
        context['day_master'] = day_master
        
        # Convert frequency_vector to waves_dict for bus protocol
        waves_dict = {k: type('Wave', (), {'amplitude': v}) for k, v in frequency_vector.items()}
        
        # Arbitrate!
        from core.trinity.core.unified_arbitrator_master import QuantumUniversalFramework
        framework = QuantumUniversalFramework()
        
        binfo = {'day_master': day_master}
        arbitration_res = framework.arbitrate_bazi(chart, binfo, context)
        
        # Get true physical SAI
        physics = arbitration_res.get('physics', {})
        stress = physics.get('stress', {})
        sai_framework = stress.get('SAI', 0.0)
        
        verdict = bus.arbitrate_environment(waves_dict, context)
        
        # [V1.4 Fusion] Calculate Interaction Energies (Clash/Comb)
        clash_energy = calculate_clash_count(chart) * 0.5 # Basic mapping
        # MOD_15: Use Vibration Engine to check impedance
        stems = [p[0] for p in chart]
        branches = [p[1] for p in chart]
        vib_engine = StructuralVibrationEngine(day_master)
        v_metrics = vib_engine.calculate_vibration_metrics(stems, branches, context)
        
        # Adjust clash energy based on system entropy/impedance
        # Higher impedance = More "brittle" clash impact
        impedance = v_metrics.get('impedance_magnitude', 1.0)
        clash_energy *= (1.0 + (impedance - 1.0) * 0.2)
        
        # [FDS-V1.5.2 Critical Fix] Compute Yang_Ren energy separately 
        # Yang_Ren is NOT a ten-god but Rob_Wealth at Emperor position
        yang_ren_energy = compute_energy_flux(chart, day_master, "ç¾Šåˆƒ")
        
        # Update frequency_vector with arbitrated values + interactions
        frequency_vector = {
            "bi_jian": bj, "jie_cai": jc, "shi_shen": ss, "shang_guan": sg,
            "pian_cai": pc, "zheng_cai": zc, "qi_sha": qs, "zheng_guan": zg,
            "pian_yin": py, "zheng_yin": zy,
            # [FDS-V1.5 Spec Support]
            "Day_Master": bj,
            "Rob_Wealth": jc,
            "Food": ss,
            "Injuries": sg,
            "Indirect_Wealth": pc,
            "Direct_Wealth": zc,
            "Seven_Killings": qs,
            "Direct_Officer": zg,
            "Resource": zy + py, # Spec often aggregates
            "Parallel": bj + jc,
            "vault_count": count_vaults_helper(chart),
            "clash": round(clash_energy, 4),
            "combination": 0.0,
            # [LEGACY COMPAT] Restored
            "parallel": bj + jc,
            "resource": zy + py,
            "power": zg + qs,
            "wealth": zc + pc,
            "output": ss + sg,
            # [FDS-V1.5.2 A-03 Matrix Compatibility]
            # æ·»åŠ  transfer_matrix æ‰€éœ€çš„æ‰€æœ‰é”®å
            "Yang_Ren": yang_ren_energy,      # ç¾Šåˆƒ (å…³é”®ï¼A-03 æ ¼å±€æ ¸å¿ƒ)
            "Friend": bj,                      # æ¯”è‚© (åŒç±»)
            "Eating_God": ss,                  # é£Ÿç¥
            "Hurting_Officer": sg,             # ä¼¤å®˜
            "Indirect_Resource": py,           # åå°
            "Direct_Resource": zy,             # æ­£å°
            "Clash": round(clash_energy, 4),   # å†² (å¤§å†™ç‰ˆæœ¬)
            "Combination": 0.0,                # åˆ (å¤§å†™ç‰ˆæœ¬)
            "Wealth": zc + pc                  # è´¢ (èšåˆ)
        }
        
        injection_logs = verdict.get('logs', {})
        
        # 3. ä½¿ç”¨transfer_matrixè¿›è¡ŒçŸ©é˜µæŠ•å½±
        # [V2.2 Policy] First, check for tensor_dynamics configuration
        pattern = self.get_pattern(pattern_id)
        physics_kernel = pattern.get('physics_kernel', {}) if pattern else {}
        dynamics_config = physics_kernel.get('tensor_dynamics')
        
        # Apply Input Transform (if any)
        processed_input = frequency_vector
        if dynamics_config and dynamics_config.get('activation_function') == "tanh_saturation":
            # [V2.2] Tanh Saturation applies BEFORE matrix projection as a gain control
            params = dynamics_config.get('parameters', {})
            # [V3.0] å¤„ç†k_factorå¼•ç”¨
            k_factor_ref = params.get('k_factor_ref')
            if k_factor_ref:
                k_val = self.resolve_config_ref(k_factor_ref)
            else:
                k_val = params.get('k_factor', 3.0)
            
            from core.math_engine import apply_saturation_layer
            processed_input = {
                k: apply_saturation_layer(v, k_val) 
                for k, v in frequency_vector.items()
            }
            logger.debug(f"Applied tanh_saturation (k={k_val}) to input vector")

        # Core Projection
        projection = project_tensor_with_matrix(processed_input, transfer_matrix)
        
        # 4. å½’ä¸€åŒ–æŠ•å½±ï¼ˆç”¨äºæ ¼å±€è¯†åˆ«ï¼‰
        normalized_projection = tensor_normalize(projection)
        
        # 5. è®¡ç®—SAIï¼ˆç³»ç»Ÿå¯¹é½æŒ‡æ•°ï¼‰
        # SAI ä¼˜å…ˆä½¿ç”¨æ¡†æ¶è®¡ç®—çš„çœŸå®å¯¹é½åŠ›
        if sai_framework > 0:
            sai = sai_framework
            logger.debug(f"ä½¿ç”¨æ¡†æ¶SAI: {sai:.4f}")
        else:
            # SAI = æŠ•å½±å‘é‡çš„æ¨¡é•¿ï¼ˆL2èŒƒæ•°ï¼‰ä½œä¸ºç‰©ç†å¼ºåº¦è¡¥å¿
            import math
            sai_l2 = math.sqrt(sum(v ** 2 for v in projection.values()))
            sai = max(sai_l2, 1.0) # å…œåº•ä¿æŠ¤
            logger.debug(f"æ¡†æ¶SAIç¼ºå¤±ï¼Œä½¿ç”¨L2æ¨¡é•¿è¡¥å¿: {sai:.4f}")
        
        # 6. è·å–æ ¼å±€ä¿¡æ¯
        pattern = self.get_pattern(pattern_id)
        pattern_name = pattern.get('name', pattern_id) if pattern else pattern_id
        
        # 7. è®¡ç®—ç»“æ„å®Œæ•´æ€§alphaï¼ˆå¦‚æœéœ€è¦ï¼‰
        day_branch = chart[2][1] if len(chart) > 2 and len(chart[2]) >= 2 else ""
        luck_pillar = context.get('luck_pillar', '') if context else ''
        year_pillar = context.get('annual_pillar', '') if context else ''
        
        energy_flux = {
            "wealth": frequency_vector['wealth'],
            "resource": frequency_vector['resource'],
            "power": frequency_vector['power'],
            "parallel": frequency_vector['parallel'],
            "output": frequency_vector['output'],
            "E_blade": compute_energy_flux(chart, day_master, "ç¾Šåˆƒ"),
            "E_kill": compute_energy_flux(chart, day_master, "ä¸ƒæ€")
        }
        
        flux_events = []
        if year_pillar and len(year_pillar) >= 2:
            year_branch = year_pillar[1]
            if check_clash(day_branch, year_branch):
                flux_events.append("Day_Branch_Clash")
            if check_combination(day_branch, year_branch):
                flux_events.append("Blade_Combined_Transformation")
        
        alpha = calculate_integrity_alpha(
            natal_chart=chart,
            day_master=day_master,
            day_branch=day_branch,
            flux_events=flux_events,
            luck_pillar=luck_pillar,
            year_pillar=year_pillar,
            energy_flux=energy_flux
        )
        
        # 8. æ£€æŸ¥æˆæ ¼/ç ´æ ¼çŠ¶æ€ (Step 4)
        pattern_state = None
        if pattern:
            pattern_state = self._check_pattern_state(
                pattern, chart, day_master, day_branch,
                luck_pillar, year_pillar, alpha
            )
        
        # 9. æ ¼å±€è¯†åˆ« (Step 6) - æ³¨å…¥å½“å‰çŠ¶æ€ä¸èƒ½é‡å¼ºåº¦ [V1.5]
        dynamic_state = pattern_state.get('state') if pattern_state else 'STABLE'
        recognition_result = self.pattern_recognition(
            normalized_projection, pattern_id, dynamic_state=dynamic_state, sai=sai
        )
            
        # [V2.3] Apply Tensor Modifiers if state is ACTIVATED
        if pattern_state and pattern_state.get('state') == "ACTIVATED":
            modifier = pattern_state.get('tensor_modifier', {})
            for axis, factor in modifier.items():
                if axis in projection:
                    projection[axis] *= factor
            
            # Recalculate normalized projection and SAI after modification
            normalized_projection = tensor_normalize(projection)
            sai = math.sqrt(sum(v ** 2 for v in projection.values()))
            logger.info(f"Applied V2.3 Tensor Modifiers: {modifier}, New SAI: {sai:.4f}")

        result = {
            'pattern_id': pattern_id,
            'pattern_name': pattern_name,
            'version': '2.5',
            'projection': normalized_projection,
            'raw_projection': projection,
            'sai': sai,
            'frequency_vector': frequency_vector,
            'alpha': alpha,
            'recognition': recognition_result,
            'pattern_state': pattern_state,
            'transfer_matrix': transfer_matrix
        }

        # [V2.5] åŠ¨æ€ç›¸å˜å¤„ç†å™¨ (Phase Transition Processor)
        context_for_trigger = {
            "chart": chart,
            "day_master": day_master,
            "day_branch": day_branch,
            "luck_pillar": luck_pillar,
            "year_pillar": year_pillar,
            "flux_events": flux_events,
            "energy_flux": energy_flux
        }
        
        dynamic_rules = pattern.get('dynamic_states', {})
        if dynamic_rules:
            # 1. æ£€æŸ¥å´©å¡Œè§„åˆ™
            for rule in dynamic_rules.get('collapse_rules', []):
                if check_trigger(rule.get('trigger'), context_for_trigger):
                    result['recognition']['pattern_type'] = rule.get('default_action', 'COLLAPSED')
                    result['recognition']['matched'] = False
                    result['recognition']['description'] = f"âš ï¸ {rule.get('action', 'ç»“æ„å´©å¡Œ')}"
                    result['phase_change'] = 'COLLAPSE'
                    break
            
            # 2. æ£€æŸ¥æ™¶åŒ–è§„åˆ™ (å¦‚æœæœªå´©å¡Œ)
            if result.get('phase_change') != 'COLLAPSE':
                for rule in dynamic_rules.get('crystallization_rules', []):
                    if check_trigger(rule.get('condition'), context_for_trigger):
                        result['recognition']['pattern_type'] = 'CRYSTALLIZED'
                        result['recognition']['matched'] = True
                        # æ™¶åŒ–æ€å¤§å¹…æå‡Precision Scoreä½œä¸ºæ˜¾ç¤º
                        p_score = result['recognition'].get('precision_score', 0)
                        result['recognition']['precision_score'] = max(0.96, p_score)
                        result['recognition']['description'] = f"ğŸ’ {rule.get('action', 'æè‡´æˆæ ¼')}"
                        result['phase_change'] = 'CRYSTALLIZATION'
                        break
        
        return result

