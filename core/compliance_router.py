"""
FDS-LKV åˆè§„æ€§è·¯ç”±å™¨ (Compliance Router)
========================================
è´Ÿè´£åœ¨é¢„æµ‹æµç¨‹ä¸­ä»‹å…¥çŸ¥è¯†åº“ï¼Œæ‰§è¡Œå…ˆéªŒæ£€æŸ¥å’Œå¥‡ç‚¹æº¯æºã€‚

Version: 1.0
Compliance: FDS-LKV Spec V1.0
"""

import logging
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)


class PhysicsAxiomViolation(Exception):
    """ç‰©ç†å…¬ç†è¿è§„å¼‚å¸¸"""
    
    def __init__(self, pattern_id: str, violations: List[str]):
        self.pattern_id = pattern_id
        self.violations = violations
        message = f"æ ¼å±€ {pattern_id} è¿åç‰©ç†å…¬ç†: {', '.join(violations)}"
        super().__init__(message)


class ComplianceRouter:
    """
    åˆè§„æ€§è·¯ç”±å™¨
    
    è´Ÿè´£:
    1. å…ˆéªŒæ£€æŸ¥ (Pre-check): åŠ è½½ registry.json æ—¶éªŒè¯ç‰©ç†å…¬ç†
    2. å¥‡ç‚¹æº¯æº (Trace-back): é©¬æ°è·ç¦»è¶…é˜ˆå€¼æ—¶æ£€ç´¢æœ€è¿‘é‚»
    """
    
    def __init__(self, vault_manager=None):
        """
        åˆå§‹åŒ–åˆè§„æ€§è·¯ç”±å™¨
        
        Args:
            vault_manager: VaultManager å®ä¾‹ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™å»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        """
        self._vault_manager = vault_manager
        self._initialized = False
    
    def _get_vault(self):
        """å»¶è¿Ÿè·å– VaultManager"""
        if self._vault_manager is None:
            from core.vault_manager import get_vault_manager
            self._vault_manager = get_vault_manager()
            self._initialized = True
        return self._vault_manager
    
    def precheck_pattern(
        self, 
        pattern_id: str, 
        pattern_config: Dict[str, Any],
        strict_mode: bool = False
    ) -> Dict[str, Any]:
        """
        å…ˆéªŒæ£€æŸ¥åè®® (Pre-check Protocol)
        
        åœ¨åŠ è½½æ ¼å±€é…ç½®æ—¶æ‰§è¡Œåˆè§„æ€§éªŒè¯ã€‚
        
        Args:
            pattern_id: æ ¼å±€ ID (å¦‚ 'A-03')
            pattern_config: æ ¼å±€é…ç½®å­—å…¸
            strict_mode: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆè¿è§„æ—¶æŠ›å‡ºå¼‚å¸¸ï¼‰
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸
        """
        vault = self._get_vault()
        
        # æ‰§è¡Œåˆè§„æ€§æ£€æŸ¥
        result = vault.check_physics_compliance(pattern_config)
        result["pattern_id"] = pattern_id
        
        # ä¸¥æ ¼æ¨¡å¼ä¸‹ï¼Œè¿è§„æ—¶æŠ›å‡ºå¼‚å¸¸
        if strict_mode and not result["compliant"]:
            raise PhysicsAxiomViolation(pattern_id, result["violations"])
        
        return result
    
    def traceback_singularity(
        self, 
        tensor_5d: List[float],
        mahalanobis_distance: float,
        threshold: float = 2.5,
        n_results: int = 3,
        pattern_filter: str = None
    ) -> Optional[Dict[str, Any]]:
        """
        å¥‡ç‚¹æº¯æºåè®® (Trace-back Protocol)
        
        å½“é©¬æ°è·ç¦»è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œæ£€ç´¢æœ€è¿‘çš„å¥‡ç‚¹æ ·æœ¬ã€‚
        
        Args:
            tensor_5d: å½“å‰å…«å­—çš„ 5D å¼ é‡ [E, O, M, S, R]
            mahalanobis_distance: è®¡ç®—å¾—åˆ°çš„é©¬æ°è·ç¦»
            threshold: è§¦å‘é˜ˆå€¼
            n_results: è¿”å›ç»“æœæ•°é‡
            pattern_filter: å¯é€‰çš„æ ¼å±€è¿‡æ»¤å™¨ (å¦‚ 'A-03')
            
        Returns:
            æ£€ç´¢ç»“æœï¼ˆå¦‚æœæœªè§¦å‘åˆ™è¿”å› Noneï¼‰
        """
        # æ£€æŸ¥æ˜¯å¦è§¦å‘æº¯æº
        if mahalanobis_distance < threshold:
            logger.debug(f"é©¬æ°è·ç¦» {mahalanobis_distance:.4f} < é˜ˆå€¼ {threshold}ï¼Œä¸è§¦å‘æº¯æº")
            return None
        
        logger.info(f"ğŸ” è§¦å‘å¥‡ç‚¹æº¯æº: D_M = {mahalanobis_distance:.4f} > {threshold}")
        
        vault = self._get_vault()
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        where_filter = None
        if pattern_filter:
            where_filter = {"pattern_id": pattern_filter}
        
        # æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
        results = vault.query_singularities(
            tensor=tensor_5d,
            n_results=n_results,
            where=where_filter
        )
        
        if not results.get("ids"):
            logger.warning("âš ï¸ å¥‡ç‚¹åº“ä¸­æœªæ‰¾åˆ°åŒ¹é…æ ·æœ¬")
            return None
        
        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        traceback_result = {
            "triggered": True,
            "mahalanobis_distance": mahalanobis_distance,
            "query_tensor": tensor_5d,
            "matches": []
        }
        
        for i, case_id in enumerate(results["ids"]):
            match = {
                "case_id": case_id,
                "distance": results["distances"][i] if i < len(results["distances"]) else None,
                "metadata": results["metadatas"][i] if i < len(results["metadatas"]) else {},
                "tensor": results["embeddings"][i] if i < len(results["embeddings"]) else None
            }
            traceback_result["matches"].append(match)
        
        logger.info(f"âœ… å¥‡ç‚¹æº¯æºå®Œæˆ: æ‰¾åˆ° {len(traceback_result['matches'])} ä¸ªåŒ¹é…")
        
        return traceback_result
    
    def query_axiom(self, axiom_query: str, n_results: int = 1) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ç‰¹å®šå…¬ç†è§„èŒƒ
        
        Args:
            axiom_query: æŸ¥è¯¢æ–‡æœ¬ (å¦‚ "ç¬¦å·å®ˆæ’å…¬ç†")
            n_results: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æ£€ç´¢ç»“æœ
        """
        vault = self._get_vault()
        return vault.query_semantics(query=axiom_query, n_results=n_results)
    
    def assess_match(
        self,
        tensor_5d: List[float],
        pattern_id: str,
        mahalanobis_distance: float,
        cosine_similarity: float = 0.0,
        precision_score: float = 0.0,
        generate_report: bool = True
    ) -> Dict[str, Any]:
        """
        å»åˆåº¦ç»¼åˆè¯„ä¼° (Assess Match Protocol)
        
        å®ç°"è¯­ä¹‰+ç‰©ç†"åŒé‡åˆ¤å®šï¼š
        1. ç‰©ç†å¯¹æ¯”ï¼ˆç¬¬ä¸€é“é—¨ï¼‰ï¼šéªŒè¯ä¸æ ‡å‡†æµå½¢çš„è·ç¦»
        2. å¥‡ç‚¹ç›¸ä¼¼åº¦ï¼ˆç¬¬äºŒé“é—¨ï¼‰ï¼šå¦‚æœåç¦»æ ‡å‡†ï¼Œæ£€ç´¢æœ€è¿‘å¥‡ç‚¹
        3. è¯­ä¹‰åˆè§„ï¼ˆç¬¬ä¸‰é“é—¨ï¼‰ï¼šæ£€ç´¢ç›¸å…³è§„èŒƒéªŒè¯åˆè§„æ€§
        
        Args:
            tensor_5d: å½“å‰å…«å­—çš„ 5D å¼ é‡ [E, O, M, S, R]
            pattern_id: ç›®æ ‡æ ¼å±€ ID
            mahalanobis_distance: é©¬æ°è·ç¦»
            cosine_similarity: ä½™å¼¦ç›¸ä¼¼åº¦
            precision_score: ç²¾å¯†è¯„åˆ†
            generate_report: æ˜¯å¦ç”Ÿæˆè¯¦ç»†å®¡è®¡æŠ¥å‘Š
            
        Returns:
            å»åˆåº¦å®¡è®¡æŠ¥å‘Š
        """
        vault = self._get_vault()
        
        result = {
            "pattern_id": pattern_id,
            "tensor": tensor_5d,
            "assessment": {
                "physical_match": False,
                "singularity_match": False,
                "semantic_compliant": False
            },
            "conclusion": "UNKNOWN",
            "confidence": 0.0,
            "report": "",
            "matched_singularity": None,
            "matched_axioms": []
        }
        
        # ============================================================
        # ç¬¬ä¸€é“é—¨ï¼šç‰©ç†å¯¹æ¯”
        # ============================================================
        physical_threshold = 2.5  # é©¬æ°è·ç¦»é˜ˆå€¼
        similarity_threshold = 0.7  # ç›¸ä¼¼åº¦é˜ˆå€¼
        
        if mahalanobis_distance < physical_threshold and cosine_similarity > similarity_threshold:
            result["assessment"]["physical_match"] = True
            result["conclusion"] = "STANDARD_MATCH"
            result["confidence"] = min(0.95, precision_score + 0.1)
            
            if generate_report:
                result["report"] = self._generate_standard_report(
                    tensor_5d, pattern_id, mahalanobis_distance, cosine_similarity
                )
            
            logger.info(f"âœ… ç¬¬ä¸€é“é—¨é€šè¿‡: {pattern_id} æ ‡å‡†åŒ¹é…")
            return result
        
        # ============================================================
        # ç¬¬äºŒé“é—¨ï¼šå¥‡ç‚¹ç›¸ä¼¼åº¦
        # ============================================================
        traceback = self.traceback_singularity(
            tensor_5d=tensor_5d,
            mahalanobis_distance=mahalanobis_distance,
            threshold=1.5,  # é™ä½é˜ˆå€¼ä»¥ä¾¿æ£€ç´¢
            pattern_filter=pattern_id
        )
        
        if traceback and traceback.get("matches"):
            nearest = traceback["matches"][0]
            nearest_distance = nearest.get("distance", float('inf'))
            
            # å¦‚æœä¸å¥‡ç‚¹è·ç¦»è¶³å¤Ÿè¿‘ï¼ˆè·ç¦» < 0.1 è¡¨ç¤ºé«˜åº¦ç›¸ä¼¼ï¼‰
            if nearest_distance < 0.1:
                result["assessment"]["singularity_match"] = True
                result["matched_singularity"] = nearest
                result["conclusion"] = "SINGULARITY_MATCH"
                result["confidence"] = max(0.85, 1.0 - nearest_distance * 5)
                
                if generate_report:
                    result["report"] = self._generate_singularity_report(
                        tensor_5d, pattern_id, nearest, traceback["matches"]
                    )
                
                logger.info(f"âœ… ç¬¬äºŒé“é—¨é€šè¿‡: {pattern_id} å¥‡ç‚¹åŒ¹é… ({nearest['case_id']})")
                return result
        
        # ============================================================
        # ç¬¬ä¸‰é“é—¨ï¼šè¯­ä¹‰åˆè§„æ£€æŸ¥
        # ============================================================
        try:
            # æ£€ç´¢ç›¸å…³å…¬ç†
            axiom_query = f"{pattern_id} ç‰©ç†å…¬ç† å®‰å…¨é—¨æ§ å…¥æ ¼æ¡ä»¶"
            axiom_results = vault.query_semantics(axiom_query, n_results=3)
            result["matched_axioms"] = axiom_results.get("ids", [])
            
            # ç®€åŒ–åˆè§„åˆ¤æ–­ï¼šå¦‚æœæœ‰åŒ¹é…çš„å…¬ç†ï¼Œè®¤ä¸ºè¯­ä¹‰å±‚æœ‰ç›¸å…³å®šä¹‰
            if result["matched_axioms"]:
                result["assessment"]["semantic_compliant"] = True
        except Exception as e:
            logger.warning(f"è¯­ä¹‰æ£€ç´¢å¤±è´¥: {e}")
        
        # ============================================================
        # ç»¼åˆåˆ¤å®š
        # ============================================================
        if result["assessment"]["semantic_compliant"] and precision_score > 0.5:
            result["conclusion"] = "MARGINAL_MATCH"
            result["confidence"] = precision_score
            
            if generate_report:
                result["report"] = self._generate_marginal_report(
                    tensor_5d, pattern_id, mahalanobis_distance, 
                    traceback, result["matched_axioms"]
                )
        else:
            result["conclusion"] = "NO_MATCH"
            result["confidence"] = precision_score
            
            if generate_report:
                result["report"] = self._generate_rejection_report(
                    tensor_5d, pattern_id, mahalanobis_distance
                )
        
        return result
    
    def _generate_standard_report(
        self, tensor: List[float], pattern_id: str, 
        m_dist: float, cos_sim: float
    ) -> str:
        """ç”Ÿæˆæ ‡å‡†åŒ¹é…æŠ¥å‘Š (QGA-VV ä¸‰æ®µå¼)"""
        E, O, M, S, R = tensor
        
        # ç‰©ç†æ€æè¿°
        e_state = "å……æ²›" if E > 0.6 else "é€‚ä¸­" if E > 0.3 else "åå¼±"
        o_state = "é«˜ç¨€" if O > 0.5 else "ä¸­ç­‰" if O > 0.25 else "åä½"
        m_state = "ä¸°åš" if M > 0.4 else "å¹³ç¨³" if M > 0.2 else "åå¼±"
        s_state = "æ¿€å‹" if S > 0.6 else "å¯æ§" if S > 0.3 else "å¹³ç¨³"
        r_state = "ç´§å¯†" if R > 0.5 else "ä¸­ç­‰" if R > 0.25 else "è¾ƒç–"
        
        # æ£€ç´¢è¯­ä¹‰å…¬ç†
        axiom_ref = ""
        try:
            vault = self._get_vault()
            axiom_result = vault.query_semantics(f"{pattern_id} æˆæ ¼æ¡ä»¶ ç‰©ç†å…¬ç†", n_results=1)
            if axiom_result.get("ids"):
                axiom_ref = f"ç¬¦åˆ {axiom_result['ids'][0]} ä¸­çš„æ ‡å‡†æµå½¢å®šä¹‰"
        except:
            axiom_ref = f"ç¬¦åˆ {pattern_id} æ ‡å‡†æµå½¢å®šä¹‰"
        
        return f"""ã€ååˆåº¦å®¡è®¡æŠ¥å‘Šã€‘
æ ¼å±€: {pattern_id}
åˆ¤å®š: âœ… æ ‡å‡†åŒ¹é…

ã€ç‰©ç†æ€ã€‘
Eè½´(èƒ½çº§): {E:.3f} - {e_state}
Oè½´(ç§©åº): {O:.3f} - {o_state}
Mè½´(è´¢å¯Œ): {M:.3f} - {m_state}
Sè½´(åº”åŠ›): {S:.3f} - {s_state}
Rè½´(å…³è”): {R:.3f} - {r_state}
é©¬æ°è·ç¦»: {m_dist:.4f} | ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.4f}

ã€å¤å…¸å¯¹ç…§ã€‘
{axiom_ref}

ã€æ¡ˆä¾‹å‚è€ƒã€‘
æ­¤ç‰¹å¾ç»„åˆåœ¨ 518k æ ·æœ¬åº“ä¸­å±äºæ ‡å‡†æµå½¢èŒƒå›´ï¼Œè¡¨ç°å…¸å‹ã€‚

ç½®ä¿¡åº¦: {cos_sim:.2f}
"""
    
    def _generate_singularity_report(
        self, tensor: List[float], pattern_id: str,
        nearest: Dict, all_matches: List
    ) -> str:
        """ç”Ÿæˆå¥‡ç‚¹åŒ¹é…æŠ¥å‘Š (QGA-VV ä¸‰æ®µå¼)"""
        E, O, M, S, R = tensor
        case_id = nearest.get("case_id", "UNKNOWN")
        meta = nearest.get("metadata", {})
        distance = nearest.get("distance", 0)
        sub_pattern = meta.get("sub_pattern", "N/A")
        y_true = meta.get("y_true", 0.5)
        zones = meta.get("zones", "")
        
        # ç‰©ç†æ€æè¿°
        e_state = "å……æ²›" if E > 0.6 else "é€‚ä¸­" if E > 0.3 else "åå¼±"
        s_state = "æ¿€å‹" if S > 0.6 else "å¯æ§" if S > 0.3 else "å¹³ç¨³"
        
        # æ£€ç´¢è¯­ä¹‰å…¬ç†
        axiom_ref = ""
        try:
            vault = self._get_vault()
            axiom_result = vault.query_semantics(f"{pattern_id} å¥‡ç‚¹ ç‰¹æ®Šæƒ…å†µ", n_results=1)
            if axiom_result.get("ids"):
                axiom_ref = f"å±äº {axiom_result['ids'][0]} æè¿°çš„å¥‡ç‚¹å˜ä½“"
        except:
            axiom_ref = f"å±äº {pattern_id} çš„ç‰¹æ®Šå˜ä½“"
        
        # è½¨è¿¹æè¿°
        trajectory = "é«˜æˆå°±è½¨è¿¹" if y_true > 0.7 else "ä¸­ç­‰è½¨è¿¹" if y_true > 0.4 else "æŒ‘æˆ˜å‹è½¨è¿¹"
        
        return f"""ã€ååˆåº¦å®¡è®¡æŠ¥å‘Šã€‘
æ ¼å±€: {pattern_id}
åˆ¤å®š: ğŸ”® å¥‡ç‚¹åŒ¹é…

ã€ç‰©ç†æ€ã€‘
Eè½´(èƒ½çº§): {E:.3f} - {e_state}
Oè½´(ç§©åº): {O:.3f}
Mè½´(è´¢å¯Œ): {M:.3f}
Sè½´(åº”åŠ›): {S:.3f} - {s_state}
Rè½´(å…³è”): {R:.3f}
ä¸æ ‡å‡†æµå½¢åç¦»ï¼Œä½†ä¸å¥‡ç‚¹æ ·æœ¬é«˜åº¦ååˆ

ã€å¥‡ç‚¹æº¯æºã€‘
æœ€è¿‘é‚»: {case_id}
å­æ ¼å±€: {sub_pattern}
ç›¸ä¼¼è·ç¦»: {distance:.6f}
ç‰¹å¾åˆ†åŒº: {zones}

ã€å¤å…¸å¯¹ç…§ã€‘
{axiom_ref}

ã€æ¡ˆä¾‹å‚è€ƒã€‘
æ­¤ç‰¹å¾ç»„åˆåœ¨ 518k æ ·æœ¬åº“ä¸­è¡¨ç°ä¸º{trajectory}ï¼Œ
y_true æŒ‡æ ‡: {y_true:.2f}

ç»“è®º: è™½ä¸ç¬¦åˆæ ‡å‡† {pattern_id} æµå½¢ï¼Œä½†ä¸å¥‡ç‚¹æ¡ˆä¾‹ {case_id} é«˜åº¦ç›¸ä¼¼ã€‚

ç½®ä¿¡åº¦: {max(0.85, 1.0 - distance * 5):.2f}
"""
    
    def _generate_marginal_report(
        self, tensor: List[float], pattern_id: str,
        m_dist: float, traceback: Optional[Dict], axioms: List
    ) -> str:
        """ç”Ÿæˆè¾¹ç¼˜åŒ¹é…æŠ¥å‘Š"""
        E, O, M, S, R = tensor
        return f"""ã€å»åˆåº¦å®¡è®¡æŠ¥å‘Šã€‘
æ ¼å±€: {pattern_id}
åˆ¤å®š: âš ï¸ è¾¹ç¼˜åŒ¹é…

ç‰©ç†åˆ†æ:
- 5D åæ ‡: E={E:.3f}, O={O:.3f}, M={M:.3f}, S={S:.3f}, R={R:.3f}
- é©¬æ°è·ç¦»: {m_dist:.4f} (åç¦»æ ‡å‡†)

è¯­ä¹‰å‚è€ƒ:
- åŒ¹é…å…¬ç†: {len(axioms)} æ¡
- è§„èŒƒä¾æ®: {', '.join(axioms[:2]) if axioms else 'N/A'}

ç»“è®º: è¯¥å…«å­—å¤„äº {pattern_id} çš„è¾¹ç¼˜çŠ¶æ€ï¼Œå»ºè®®ç»“åˆæµå¹´å¤§è¿è¿›ä¸€æ­¥è§‚å¯Ÿã€‚
"""
    
    def _generate_rejection_report(
        self, tensor: List[float], pattern_id: str, m_dist: float
    ) -> str:
        """ç”Ÿæˆæ‹’ç»åŒ¹é…æŠ¥å‘Š"""
        E, O, M, S, R = tensor
        return f"""ã€å»åˆåº¦å®¡è®¡æŠ¥å‘Šã€‘
æ ¼å±€: {pattern_id}
åˆ¤å®š: âŒ ä¸åŒ¹é…

ç‰©ç†åˆ†æ:
- 5D åæ ‡: E={E:.3f}, O={O:.3f}, M={M:.3f}, S={S:.3f}, R={R:.3f}
- é©¬æ°è·ç¦»: {m_dist:.4f} (ä¸¥é‡åç¦»)

ç»“è®º: è¯¥å…«å­—ä¸ç¬¦åˆ {pattern_id} çš„ç‰©ç†å®šä¹‰ï¼Œå»ºè®®æ£€ç´¢å…¶ä»–æ ¼å±€ã€‚
"""


# å…¨å±€å•ä¾‹
_compliance_router: Optional[ComplianceRouter] = None


def get_compliance_router() -> ComplianceRouter:
    """è·å– ComplianceRouter å•ä¾‹"""
    global _compliance_router
    if _compliance_router is None:
        _compliance_router = ComplianceRouter()
    return _compliance_router

