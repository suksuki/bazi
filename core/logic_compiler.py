"""
LKV-to-FDS é€»è¾‘ç¼–è¯‘å™¨ (Logic Compiler)
=====================================
å°† LKV ä¸­çš„å¤å…¸é€»è¾‘åè®®ç¼–è¯‘ä¸º FDS å¯æ‰§è¡Œçš„æµ·é€‰ä»£ç 

æ¶æ„å®šä½ï¼š
- LKV: é€»è¾‘æŒ‡æŒ¥å®˜ï¼ˆæä¾›è§„åˆ™ï¼‰
- FDS: æ‰§è¡Œå·¥å…µï¼ˆå…¨é‡æ‰«æï¼‰

Version: 1.0
Compliance: FDS-LKV-LOGIC V1.0
"""

import logging
from typing import Dict, List, Any, Callable, Optional

logger = logging.getLogger(__name__)


# å¯¼å…¥åè®®
from core.protocol_checker import LOGIC_PROTOCOLS, YANG_REN_MAP


class LogicCompiler:
    """
    LKV-to-FDS é€»è¾‘ç¼–è¯‘å™¨
    
    å°†çŸ¥è¯†åº“ä¸­çš„ JSON åè®®è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„ Python è¿‡æ»¤å‡½æ•°
    """
    
    def __init__(self):
        self.protocols = LOGIC_PROTOCOLS
        self._compiled_filters: Dict[str, Callable] = {}
    
    def compile(self, pattern_id: str) -> Callable:
        """
        ç¼–è¯‘æŒ‡å®šæ ¼å±€çš„è¿‡æ»¤å‡½æ•°
        
        Args:
            pattern_id: æ ¼å±€ ID
            
        Returns:
            å¯æ‰§è¡Œçš„è¿‡æ»¤å‡½æ•° (bazi: Dict) -> bool
        """
        if pattern_id in self._compiled_filters:
            return self._compiled_filters[pattern_id]
        
        if pattern_id not in self.protocols:
            raise ValueError(f"æœªçŸ¥æ ¼å±€åè®®: {pattern_id}")
        
        protocol = self.protocols[pattern_id]
        
        # åŠ¨æ€ç”Ÿæˆè¿‡æ»¤å‡½æ•°
        def compiled_filter(bazi: Dict) -> bool:
            return self._execute_protocol(bazi, protocol)
        
        # æ·»åŠ å…ƒæ•°æ®
        compiled_filter.__name__ = f"filter_{pattern_id}"
        compiled_filter.__doc__ = f"ç¼–è¯‘è‡ª LKV åè®®: {protocol['name']}"
        
        self._compiled_filters[pattern_id] = compiled_filter
        logger.info(f"âœ… ç¼–è¯‘å®Œæˆ: {pattern_id} ({protocol['name']})")
        
        return compiled_filter
    
    def compile_all(self) -> Dict[str, Callable]:
        """ç¼–è¯‘æ‰€æœ‰æ ¼å±€çš„è¿‡æ»¤å‡½æ•°"""
        for pattern_id in self.protocols:
            self.compile(pattern_id)
        return self._compiled_filters
    
    def _execute_protocol(self, bazi: Dict, protocol: Dict) -> bool:
        """æ‰§è¡Œåè®®æ£€æŸ¥"""
        # 1. å¼ºåˆ¶æ¡ä»¶å¿…é¡»å…¨éƒ¨æ»¡è¶³
        for rule in protocol.get("mandatory", []):
            if not self._eval_rule(bazi, rule):
                return False
        
        # 2. å¯é€‰æ¡ä»¶è‡³å°‘æ»¡è¶³ä¸€ä¸ªï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        optional = protocol.get("optional_or", [])
        if optional:
            if not any(self._eval_rule(bazi, r) for r in optional):
                return False
        
        # 3. ç¦å¿Œæ¡ä»¶ä¸èƒ½è§¦å‘
        for rule in protocol.get("forbidden", []):
            if self._eval_forbidden(bazi, rule):
                return False
        
        return True
    
    def _eval_rule(self, bazi: Dict, rule: str) -> bool:
        """è¯„ä¼°å•æ¡è§„åˆ™"""
        stems = bazi.get("stems", [])
        month_main = bazi.get("month_main", "")
        day_master = bazi.get("day_master", "")
        month_branch = bazi.get("month_branch", "")
        
        # è§„åˆ™è§£æ
        if "stems.contains" in rule:
            shen = rule.split("'")[1] if "'" in rule else ""
            return shen in stems
        elif "month_main ==" in rule:
            expected = rule.split("'")[1] if "'" in rule else ""
            return month_main == expected
        elif "is_yang_stem" in rule:
            return day_master in ['ç”²', 'ä¸™', 'æˆŠ', 'åºš', 'å£¬']
        elif "is_sheep_blade" in rule:
            expected = YANG_REN_MAP.get(day_master)
            return month_branch == expected
        
        return False
    
    def _eval_forbidden(self, bazi: Dict, rule: str) -> bool:
        """è¯„ä¼°ç¦å¿Œè§„åˆ™"""
        stems = bazi.get("stems", [])
        
        if "æ­ç¥å¤ºé£Ÿ" in rule or "pian_yin without pian_cai" in rule:
            return "pian_yin" in stems and "pian_cai" not in stems
        elif "ä¼¤å®˜è§å®˜" in rule or "zheng_guan without zheng_yin" in rule:
            return "zheng_guan" in stems and "zheng_yin" not in stems
        elif "è´¢å¤šç ´å°" in rule or "wealth_count > 2" in rule:
            wealth_count = stems.count("zheng_cai") + stems.count("pian_cai")
            return wealth_count > 2
        elif "æ¯”åŠ«äº‰è´¢" in rule or "rob_count > 2" in rule:
            rob_count = stems.count("bi_jian") + stems.count("jie_cai")
            if "without protection" in rule or "æ— åˆ¶" in rule:
                has_protection = "zheng_guan" in stems or "qi_sha" in stems
                return rob_count > 2 and not has_protection
            return rob_count > 2
        
        return False
    
    def get_protocol_sql(self, pattern_id: str) -> str:
        """
        ç”Ÿæˆä¼ª SQL æŸ¥è¯¢ï¼ˆç”¨äºè°ƒè¯•å’Œæ–‡æ¡£ï¼‰
        
        Args:
            pattern_id: æ ¼å±€ ID
            
        Returns:
            ä¼ª SQL å­—ç¬¦ä¸²
        """
        if pattern_id not in self.protocols:
            return f"-- æœªçŸ¥æ ¼å±€: {pattern_id}"
        
        protocol = self.protocols[pattern_id]
        
        conditions = []
        for rule in protocol.get("mandatory", []):
            conditions.append(f"({rule})")
        
        optional = protocol.get("optional_or", [])
        if optional:
            or_clause = " OR ".join(f"({r})" for r in optional)
            conditions.append(f"({or_clause})")
        
        for rule in protocol.get("forbidden", []):
            conditions.append(f"NOT ({rule})")
        
        where_clause = " AND ".join(conditions)
        
        return f"""
-- LKV-Compiled SQL for {pattern_id} ({protocol['name']})
-- Semantic Reference: {protocol.get('semantic_ref', 'N/A')}

SELECT uid, tensor 
FROM holographic_universe_518k
WHERE {where_clause}
"""


class KnowledgeDrivenCensus:
    """
    çŸ¥è¯†é©±åŠ¨å‹æµ·é€‰å¼•æ“
    
    å®ç° LKV é©±åŠ¨ + FDS æ‰§è¡Œçš„ååŒæ¶æ„
    """
    
    def __init__(self):
        self.compiler = LogicCompiler()
        self._census_engine = None
    
    def _get_census_engine(self):
        """å»¶è¿ŸåŠ è½½ CensusEngine"""
        if self._census_engine is None:
            from core.census_engine import ClassicalCensusEngine
            self._census_engine = ClassicalCensusEngine()
        return self._census_engine
    
    def request_census(
        self, 
        pattern_id: str,
        limit: int = None,
        include_tensor: bool = True
    ) -> Dict[str, Any]:
        """
        LKV æäº¤æµ·é€‰ç”³è¯·
        
        æµç¨‹:
        1. LKV ç¼–è¯‘åè®® -> ç”Ÿæˆè¿‡æ»¤å‡½æ•°
        2. FDS æ‰§è¡Œå…¨é‡æ‰«æ -> è¿”å›æ ·æœ¬é›†
        3. è¿”å›ç»“æœ + ç»Ÿè®¡
        
        Args:
            pattern_id: æ ¼å±€ ID
            limit: æ‰«æé™åˆ¶
            include_tensor: æ˜¯å¦åŒ…å«å¼ é‡
            
        Returns:
            æµ·é€‰ç»“æœ
        """
        logger.info(f"ğŸ“œ LKV æ”¶åˆ°æµ·é€‰ç”³è¯·: {pattern_id}")
        
        # 1. ç¼–è¯‘åè®®
        filter_func = self.compiler.compile(pattern_id)
        logger.info(f"âš™ï¸ åè®®ç¼–è¯‘å®Œæˆ")
        
        # 2. è°ƒç”¨ FDS æ‰§è¡Œ
        engine = self._get_census_engine()
        logger.info(f"ğŸ” FDS å¼€å§‹å…¨é‡æ‰«æ...")
        
        result = engine.census(pattern_id, limit=limit, include_tensor=include_tensor)
        
        # 3. æ·»åŠ  LKV å…ƒæ•°æ®
        protocol = self.compiler.protocols.get(pattern_id, {})
        result["lkv_metadata"] = {
            "pattern_name": protocol.get("name", ""),
            "category": protocol.get("category", ""),
            "semantic_ref": protocol.get("semantic_ref", ""),
            "compiled_sql": self.compiler.get_protocol_sql(pattern_id)
        }
        
        logger.info(f"âœ… æµ·é€‰å®Œæˆ: {result['matched_count']} æ ·æœ¬")
        
        return result
    
    def audit_samples(
        self, 
        samples: List[Dict], 
        pattern_id: str,
        sample_size: int = 100
    ) -> Dict[str, Any]:
        """
        LKV æŠ½æ£€æ ·æœ¬åˆè§„æ€§
        
        Args:
            samples: FDS è¿”å›çš„æ ·æœ¬
            pattern_id: æ ¼å±€ ID
            sample_size: æŠ½æ£€æ•°é‡
            
        Returns:
            å®¡è®¡ç»“æœ
        """
        from core.protocol_checker import get_protocol_checker
        checker = get_protocol_checker()
        
        # æŠ½æ ·
        audit_samples = samples[:sample_size]
        
        passed = 0
        failed = 0
        
        for sample in audit_samples:
            # æ¨¡æ‹Ÿå…«å­—ç»“æ„ï¼ˆå®é™…éœ€è¦ä»æ ·æœ¬æå–ï¼‰
            bazi = self._sample_to_bazi(sample)
            result = checker.check_bazi(bazi, pattern_id)
            if result["passed"]:
                passed += 1
            else:
                failed += 1
        
        compliance_rate = passed / len(audit_samples) if audit_samples else 0
        
        return {
            "pattern_id": pattern_id,
            "audited_count": len(audit_samples),
            "passed": passed,
            "failed": failed,
            "compliance_rate": compliance_rate,
            "verdict": "åˆè§„" if compliance_rate > 0.95 else "éœ€å¤æŸ¥"
        }
    
    def _sample_to_bazi(self, sample: Dict) -> Dict:
        """å°†æ ·æœ¬è½¬æ¢ä¸ºå…«å­—ç»“æ„ï¼ˆç®€åŒ–æ¼”ç¤ºï¼‰"""
        uid = sample.get("uid", 0)
        tensor = sample.get("tensor", {})
        
        day_masters = ['ç”²', 'ä¹™', 'ä¸™', 'ä¸', 'æˆŠ', 'å·±', 'åºš', 'è¾›', 'å£¬', 'ç™¸']
        month_branches = ['å­', 'ä¸‘', 'å¯…', 'å¯', 'è¾°', 'å·³', 'åˆ', 'æœª', 'ç”³', 'é…‰', 'æˆŒ', 'äº¥']
        
        return {
            "uid": uid,
            "day_master": day_masters[uid % 10],
            "month_branch": month_branches[uid % 12],
            "month_main": "zheng_guan" if tensor.get("O", 0) > 0.5 else "pian_cai",
            "stems": ["qi_sha"] if tensor.get("O", 0) > 0.4 else ["zheng_cai"]
        }


# å…¨å±€å•ä¾‹
_knowledge_census: Optional[KnowledgeDrivenCensus] = None


def get_knowledge_census() -> KnowledgeDrivenCensus:
    """è·å– KnowledgeDrivenCensus å•ä¾‹"""
    global _knowledge_census
    if _knowledge_census is None:
        _knowledge_census = KnowledgeDrivenCensus()
    return _knowledge_census
