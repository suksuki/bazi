"""
[QGA V25.0] ç»Ÿè®¡å®¡è®¡å·¥å…·æ¨¡å— (Statistical Audit Utilities)
RSS-V1.4è§„èŒƒï¼šé€šç”¨ç»Ÿè®¡æ–¹æ³•ï¼Œä¾›æ ¼å±€å®¡è®¡å¤ç”¨

åŠŸèƒ½ï¼š
- ç¦»ç¾¤å€¼æ£€æµ‹ï¼ˆZ-Scoreã€IQRï¼‰
- æ¢¯åº¦æ¶ˆå¤±åˆ¤å®š
- åˆ†å¸ƒç»Ÿè®¡ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ã€ååº¦ï¼‰
- å¥‡ç‚¹å­˜åœ¨æ€§éªŒè¯ï¼ˆç»Ÿè®¡å±‚é¢ï¼‰

ä½œè€…: Antigravity Team
ç‰ˆæœ¬: V1.4
æ—¥æœŸ: 2025-12-28
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
import numpy as np
from scipy import stats

logger = logging.getLogger(__name__)


class StatisticalAuditor:
    """
    ç»Ÿè®¡å®¡è®¡å™¨ï¼ˆRSS-V1.4è§„èŒƒï¼‰
    
    æä¾›é€šç”¨çš„ç»Ÿè®¡æ–¹æ³•ï¼Œç”¨äºæ ¼å±€å®¡è®¡ä¸­çš„ï¼š
    - ç¦»ç¾¤å€¼æ£€æµ‹ï¼ˆåŠ¨æ€å¥‡ç‚¹åˆ¤å®šï¼‰
    - æ¢¯åº¦æ¶ˆå¤±åˆ¤å®šï¼ˆé€»è¾‘å¹³æ»‘æ£€æµ‹ï¼‰
    - åˆ†å¸ƒç»Ÿè®¡ï¼ˆå…¨é‡æ ·æœ¬åˆ†æï¼‰
    """
    
    def __init__(self, z_score_threshold: float = 3.0, gradient_threshold: float = 0.05):
        """
        åˆå§‹åŒ–ç»Ÿè®¡å®¡è®¡å™¨
        
        Args:
            z_score_threshold: Z-Scoreé˜ˆå€¼ï¼ˆé»˜è®¤3.0ï¼Œå³3-Sigmaè§„åˆ™ï¼‰
            gradient_threshold: æ¢¯åº¦æ¶ˆå¤±åˆ¤å®šé˜ˆå€¼ï¼ˆé»˜è®¤0.05ï¼Œå³5%å·®å¼‚ï¼‰
        """
        self.z_score_threshold = z_score_threshold
        self.gradient_threshold = gradient_threshold
        logger.info(f"âœ… ç»Ÿè®¡å®¡è®¡å™¨åˆå§‹åŒ–å®Œæˆï¼ˆZ-Scoreé˜ˆå€¼={z_score_threshold}, æ¢¯åº¦é˜ˆå€¼={gradient_threshold}ï¼‰")
    
    def detect_outliers(self, 
                       values: List[float],
                       method: str = "combined") -> Dict[str, Any]:
        """
        ç¦»ç¾¤å€¼æ£€æµ‹ï¼ˆRSS-V1.4è§„èŒƒï¼šåŠ¨æ€ç¦»ç¾¤å€¼æ£€æµ‹ï¼‰
        
        ä½¿ç”¨Z-Scoreï¼ˆ3-Sigmaè§„åˆ™ï¼‰å’ŒIQRæ–¹æ³•æ£€æµ‹ç»Ÿè®¡å­¦æ„ä¹‰ä¸Šçš„ç¦»ç¾¤å€¼ã€‚
        
        Args:
            values: æ•°å€¼åˆ—è¡¨ï¼ˆå¦‚ç¨³å®šæ€§å€¼ï¼‰
            method: æ£€æµ‹æ–¹æ³•ï¼ˆ"z_score", "iqr", "combined"ï¼‰
            
        Returns:
            åŒ…å«ç¦»ç¾¤å€¼ç´¢å¼•å’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        if not values or len(values) < 2:
            return {
                "outlier_indices": [],
                "normal_indices": list(range(len(values))),
                "statistics": {},
                "has_outliers": False
            }
        
        values_array = np.array(values)
        
        # è®¡ç®—ç»Ÿè®¡é‡
        mean_val = np.mean(values_array)
        std_val = np.std(values_array)
        median_val = np.median(values_array)
        min_val = np.min(values_array)
        max_val = np.max(values_array)
        
        # è®¡ç®—ååº¦ï¼ˆSkewnessï¼‰ï¼šç”¨äºåˆ¤æ–­æ˜¯å¦å­˜åœ¨é•¿å°¾
        skewness = stats.skew(values_array) if len(values_array) > 2 else 0.0
        
        # æ–¹æ³•1ï¼šZ-Scoreæ£€æµ‹ï¼ˆ3-Sigmaè§„åˆ™ï¼‰
        z_scores = (values_array - mean_val) / (std_val + 1e-6)
        z_outlier_indices = [i for i, z in enumerate(z_scores) if z < -self.z_score_threshold]
        
        # æ–¹æ³•2ï¼šIQRæ£€æµ‹ï¼ˆä½œä¸ºè¡¥å……ï¼‰
        q1 = np.percentile(values_array, 25)
        q3 = np.percentile(values_array, 75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        iqr_outlier_indices = [i for i, v in enumerate(values_array) 
                              if v < lower_bound or v > upper_bound]
        
        # æ ¹æ®æ–¹æ³•é€‰æ‹©ç»“æœ
        if method == "z_score":
            outlier_indices = z_outlier_indices
        elif method == "iqr":
            outlier_indices = iqr_outlier_indices
        else:  # combined
            outlier_indices = list(set(z_outlier_indices + iqr_outlier_indices))
        
        normal_indices = [i for i in range(len(values)) if i not in outlier_indices]
        
        logger.info(f"ğŸ“Š ç¦»ç¾¤å€¼æ£€æµ‹: æ€»æ ·æœ¬={len(values)}, ç¦»ç¾¤æ ·æœ¬={len(outlier_indices)}, "
                   f"å‡å€¼={mean_val:.4f}, æ ‡å‡†å·®={std_val:.4f}, ååº¦={skewness:.4f}, "
                   f"Z-Scoreç¦»ç¾¤={len(z_outlier_indices)}, IQRç¦»ç¾¤={len(iqr_outlier_indices)}")
        
        return {
            "outlier_indices": outlier_indices,
            "normal_indices": normal_indices,
            "statistics": {
                "mean": float(mean_val),
                "std": float(std_val),
                "median": float(median_val),
                "min": float(min_val),
                "max": float(max_val),
                "skewness": float(skewness),
                "q1": float(q1),
                "q3": float(q3),
                "iqr": float(iqr),
                "lower_bound": float(lower_bound),
                "upper_bound": float(upper_bound)
            },
            "z_scores": [float(z) for z in z_scores],
            "detection_methods": {
                "z_score_outliers": len(z_outlier_indices),
                "iqr_outliers": len(iqr_outlier_indices),
                "combined_outliers": len(outlier_indices),
                "method_used": method
            },
            "has_outliers": len(outlier_indices) > 0
        }
    
    def check_gradient_vanishing(self,
                                 values: List[float],
                                 outlier_indices: Optional[List[int]] = None) -> Dict[str, Any]:
        """
        æ¢¯åº¦æ¶ˆå¤±åˆ¤å®šï¼ˆRSS-V1.4è§„èŒƒï¼šé€»è¾‘å¹³æ»‘æ£€æµ‹ï¼‰
        
        å¦‚æœæœ€å·®æ ·æœ¬å’Œå¹³å‡æ ·æœ¬å·®å¼‚æå°ï¼Œåˆ¤å®šä¸º"é€»è¾‘å¹³æ»‘"ï¼Œæ‹’ç»å¥‡ç‚¹æ³¨å†Œã€‚
        
        Args:
            values: æ•°å€¼åˆ—è¡¨ï¼ˆå¦‚ç¨³å®šæ€§å€¼ï¼‰
            outlier_indices: ç¦»ç¾¤å€¼ç´¢å¼•åˆ—è¡¨ï¼ˆå¦‚æœå·²æ£€æµ‹ï¼‰
            
        Returns:
            åŒ…å«æ¢¯åº¦ä¿¡æ¯å’Œåˆ¤å®šç»“æœçš„å­—å…¸
        """
        if not values:
            return {
                "has_gradient": False,
                "gradient": 0.0,
                "gradient_ratio": 0.0,
                "verdict": "no_data"
            }
        
        values_array = np.array(values)
        mean_val = np.mean(values_array)
        
        if outlier_indices:
            # å¦‚æœæœ‰ç¦»ç¾¤å€¼ï¼Œä½¿ç”¨ç¦»ç¾¤å€¼ä¸­çš„æœ€å°å€¼
            outlier_values = [values[i] for i in outlier_indices]
            worst_val = min(outlier_values)
        else:
            # å¦åˆ™ä½¿ç”¨å…¨å±€æœ€å°å€¼
            worst_val = np.min(values_array)
        
        gradient = mean_val - worst_val
        gradient_ratio = gradient / (mean_val + 1e-6)  # ç›¸å¯¹å·®å¼‚ç™¾åˆ†æ¯”
        
        # RSS-V1.4è§„èŒƒï¼šå¦‚æœå·®å¼‚å°äº20%ï¼Œåˆ¤å®šä¸ºé€»è¾‘å¹³æ»‘
        has_gradient = gradient > self.gradient_threshold and gradient_ratio > 0.20
        
        verdict = "has_gradient" if has_gradient else "gradient_vanished"
        
        logger.info(f"ğŸ” æ¢¯åº¦æ¶ˆå¤±åˆ¤å®š: å‡å€¼={mean_val:.4f}, æœ€å·®å€¼={worst_val:.4f}, "
                   f"æ¢¯åº¦={gradient:.4f}, ç›¸å¯¹å·®å¼‚={gradient_ratio*100:.2f}%, "
                   f"åˆ¤å®š={verdict}")
        
        return {
            "has_gradient": has_gradient,
            "gradient": float(gradient),
            "gradient_ratio": float(gradient_ratio),
            "mean": float(mean_val),
            "worst": float(worst_val),
            "verdict": verdict
        }
    
    def calculate_distribution_stats(self, values: List[float]) -> Dict[str, Any]:
        """
        è®¡ç®—åˆ†å¸ƒç»Ÿè®¡é‡ï¼ˆRSS-V1.4è§„èŒƒï¼šå…¨é‡åˆ†å¸ƒå®¡è®¡ï¼‰
        
        Args:
            values: æ•°å€¼åˆ—è¡¨
            
        Returns:
            åŒ…å«å®Œæ•´ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        if not values:
            return {}
        
        values_array = np.array(values)
        
        stats_dict = {
            "count": len(values),
            "mean": float(np.mean(values_array)),
            "std": float(np.std(values_array)),
            "median": float(np.median(values_array)),
            "min": float(np.min(values_array)),
            "max": float(np.max(values_array)),
            "q1": float(np.percentile(values_array, 25)),
            "q3": float(np.percentile(values_array, 75)),
            "iqr": float(np.percentile(values_array, 75) - np.percentile(values_array, 25)),
        }
        
        # è®¡ç®—ååº¦ï¼ˆSkewnessï¼‰
        if len(values_array) > 2:
            stats_dict["skewness"] = float(stats.skew(values_array))
            stats_dict["kurtosis"] = float(stats.kurtosis(values_array))
        else:
            stats_dict["skewness"] = 0.0
            stats_dict["kurtosis"] = 0.0
        
        # è®¡ç®—åŠ¨æ€ç¦»ç¾¤çº¢çº¿ï¼ˆRSS-V1.4è§„èŒƒï¼‰
        mean_val = stats_dict["mean"]
        std_val = stats_dict["std"]
        dynamic_threshold = min(0.15, mean_val - 3 * std_val)
        stats_dict["dynamic_singularity_threshold"] = float(dynamic_threshold)
        
        return stats_dict
    
    def verify_singularity_existence(self,
                                    values: List[float],
                                    outlier_indices: Optional[List[int]] = None) -> Dict[str, Any]:
        """
        å¥‡ç‚¹å­˜åœ¨æ€§éªŒè¯ï¼ˆRSS-V1.4è§„èŒƒï¼šç»Ÿè®¡å±‚é¢éªŒè¯ï¼‰
        
        ç»“åˆç¦»ç¾¤å€¼æ£€æµ‹å’Œæ¢¯åº¦æ¶ˆå¤±åˆ¤å®šï¼ŒéªŒè¯æ˜¯å¦å­˜åœ¨çœŸæ­£çš„å¥‡ç‚¹ã€‚
        
        Args:
            values: æ•°å€¼åˆ—è¡¨
            outlier_indices: ç¦»ç¾¤å€¼ç´¢å¼•åˆ—è¡¨ï¼ˆå¦‚æœå·²æ£€æµ‹ï¼‰
            
        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        # 1. ç¦»ç¾¤å€¼æ£€æµ‹
        outlier_result = self.detect_outliers(values, method="combined")
        
        # 2. æ¢¯åº¦æ¶ˆå¤±åˆ¤å®š
        gradient_result = self.check_gradient_vanishing(
            values, 
            outlier_indices=outlier_result["outlier_indices"]
        )
        
        # 3. ç»¼åˆåˆ¤å®š
        has_outliers = outlier_result["has_outliers"]
        has_gradient = gradient_result["has_gradient"]
        
        # RSS-V1.4è§„èŒƒï¼šåªæœ‰åŒæ—¶æ»¡è¶³"å­˜åœ¨ç¦»ç¾¤å€¼"å’Œ"å­˜åœ¨æ¢¯åº¦"æ—¶ï¼Œæ‰åˆ¤å®šä¸ºå­˜åœ¨å¥‡ç‚¹
        singularity_exists = has_outliers and has_gradient
        
        verdict = "singularity_exists" if singularity_exists else "no_singularity"
        
        if not singularity_exists:
            if not has_outliers:
                reason = "no_statistical_outliers"
            elif not has_gradient:
                reason = "gradient_vanished"
            else:
                reason = "unknown"
        else:
            reason = "verified"
        
        logger.info(f"âœ… å¥‡ç‚¹å­˜åœ¨æ€§éªŒè¯: ç¦»ç¾¤å€¼={has_outliers}, æ¢¯åº¦={has_gradient}, "
                   f"ç»¼åˆåˆ¤å®š={verdict}, åŸå› ={reason}")
        
        return {
            "singularity_exists": singularity_exists,
            "verdict": verdict,
            "reason": reason,
            "outlier_detection": outlier_result,
            "gradient_check": gradient_result,
            "statistics": self.calculate_distribution_stats(values)
        }


# å…¨å±€å•ä¾‹å®ä¾‹
_global_auditor = None

def get_statistical_auditor(z_score_threshold: float = 3.0, 
                           gradient_threshold: float = 0.05) -> StatisticalAuditor:
    """
    è·å–å…¨å±€ç»Ÿè®¡å®¡è®¡å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    Args:
        z_score_threshold: Z-Scoreé˜ˆå€¼
        gradient_threshold: æ¢¯åº¦é˜ˆå€¼
        
    Returns:
        StatisticalAuditorå®ä¾‹
    """
    global _global_auditor
    if _global_auditor is None:
        _global_auditor = StatisticalAuditor(z_score_threshold, gradient_threshold)
    return _global_auditor

