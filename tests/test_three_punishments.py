#!/usr/bin/env python3
"""
Sprint 5.3: Three Punishments Test
Test the ğŸ’€ Skull Protocol - Earth Punishment Detection
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.engine_v88 import EngineV88 as QuantumEngine  # V8.8 Modular
from core.bazi_profile import VirtualBaziProfile

def test_three_punishments_detection():
    """
    Test Case: å¤©ç”Ÿå¸¦åˆ‘ Chart encountering ä¸‰åˆ‘å®Œæ•´
    
    å‘½å±€: ç™¸ä¸‘ ä¹™æœª ç”²å­ ä¸™å¯…
    - å¹´æ”¯: ä¸‘
    - æœˆæ”¯: æœª
    æµå¹´: 2030 åºšæˆŒ
    - å¹´æ”¯: æˆŒ
    
    å®Œæ•´ä¸‰åˆ‘: {ä¸‘, æœª, æˆŒ} âœ…
    é¢„æœŸ: ğŸ’€ Structural Collapse
    """
    print("\n" + "="*80)
    print("ğŸ’€ Sprint 5.3: Three Punishments Detection Test")
    print("="*80)
    
    engine = QuantumEngine()
    
    # The Doomed Chart - å¸¦åˆ‘å‘½é€ 
    punishment_chart_pillars = {
        'year': 'ç™¸ä¸‘',  # ä¸‘ âœ“
        'month': 'ä¹™æœª',  # æœª âœ“
        'day': 'ç”²å­',
        'hour': 'ä¸™å¯…'
    }
    # Create Virtual Profile
    profile = VirtualBaziProfile(
        pillars=punishment_chart_pillars, 
        static_luck="åºšç”³", # Luck doesn't matter for this test logic
        day_master="ç”²",
        gender=1
    )
    
    # favorable/unfavorable are handled by engine internally in V6.0 or defaults used
    # In V6.0 calculate_year_context, it doesn't accept external favorable/unfavorable.
    # We rely on the engine's internal logic or defaults.
    
    # Control Year: 2024 (ç”²è¾°) - No punishment
    print("\nğŸ“… Control Year: 2024 ç”²è¾° (No Punishment)")
    ctx_control = engine.calculate_year_context(profile, 2024)
    
    print(f"  Icon: {ctx_control.icon}")
    print(f"  Score: {ctx_control.score}")
    print(f"  Energy: {ctx_control.energy_level}")
    print(f"  Tags: {ctx_control.tags[:3]}")
    
    # Test Year: 2030 (åºšæˆŒ) - PUNISHMENT TRIGGERED ğŸ’€
    print("\nğŸ’€ Test Year: 2030 åºšæˆŒ (Punishment Triggered!)")
    ctx_punishment = engine.calculate_year_context(profile, 2030)
    
    print(f"  Icon: {ctx_punishment.icon}")
    print(f"  Score: {ctx_punishment.score}")
    print(f"  Energy: {ctx_punishment.energy_level}")
    print(f"  Risk Level: {ctx_punishment.risk_level}")
    print(f"  Tags: {ctx_punishment.tags[:5]}")
    print(f"\n  Narrative Prompt:")
    print(f"    {ctx_punishment.narrative_prompt[:150]}...")
    
    # Assertions
    print("\n" + "-"*80)
    print("Validating Results...")
    
    # Control should NOT have skull
    assert ctx_control.icon != "ğŸ’€", "Control year should not trigger punishment"
    print("âœ… Control year: No skull icon")
    
    # Test year SHOULD have skull
    assert ctx_punishment.icon == "ğŸ’€", f"Expected ğŸ’€, got {ctx_punishment.icon}"
    print("âœ… Test year: Skull icon detected!")
    
    # Score should be heavily penalized (absolute value check)
    # Punishment adds -40 penalty, so score should be very negative
    assert ctx_punishment.score < -30, f"Punishment score too high: {ctx_punishment.score}"
    print(f"âœ… Score penalty: {ctx_control.score:.1f} â†’ {ctx_punishment.score:.1f} (heavily penalized)")

    
    # Risk level should be danger
    assert ctx_punishment.risk_level == "danger", f"Expected 'danger', got {ctx_punishment.risk_level}"
    print("âœ… Risk level: danger")
    
    # Tags should include punishment markers
    assert any("ä¸‰åˆ‘" in tag for tag in ctx_punishment.tags), "Missing ä¸‰åˆ‘ tag"
    assert any("å´©å¡Œ" in tag for tag in ctx_punishment.tags), "Missing å´©å¡Œ tag"
    print(f"âœ… Tags correct: {ctx_punishment.tags[:3]}")
    
    # Energy level should indicate structural collapse
    assert "Collapse" in ctx_punishment.energy_level or "å¤§å‡¶" in ctx_punishment.energy_level or "High Risk" in ctx_punishment.energy_level
    print(f"âœ… Energy level: {ctx_punishment.energy_level}")
    
    # Narrative should have extreme warning
    # Note: Narrative prompt building depends on LLM prompt construction logic.
    # In V6.0 code check: ctx.narrative_prompt ...
    # We check if it contains keywords.
    # If narrative_events has 'punishment_collapse', likely prompt has it.
    
    print("\n" + "="*80)
    print("ğŸ‰ Three Punishments Test PASSED!")
    print("The Skull Protocol is ACTIVE! ğŸ’€")
    print("="*80)


def test_no_punishment_with_two_branches():
    """
    Test: Only 2 of 3 branches present - Should NOT trigger
    """
    print("\n" + "="*80)
    print("ğŸ§ª Test: Partial Punishment (Should NOT Trigger)")
    print("="*80)
    
    engine = QuantumEngine()
    
    # Only has ä¸‘ and æœª, missing æˆŒ
    partial_chart_pillars = {
        'year': 'ç™¸ä¸‘',  # ä¸‘ âœ“
        'month': 'ä¹™æœª',  # æœª âœ“
        'day': 'ç”²å­',
        'hour': 'ä¸™å¯…'
    }
    
    profile = VirtualBaziProfile(
        pillars=partial_chart_pillars, 
        static_luck="åºšç”³",
        day_master="ç”²",
        gender=1
    )
    
    # Year: 2024 ç”²è¾° (è¾°, not æˆŒ)
    ctx = engine.calculate_year_context(profile, 2024)
    
    print(f"  Icon: {ctx.icon}")
    print(f"  Risk: {ctx.risk_level}")
    
    # Should NOT trigger punishment
    assert ctx.icon != "ğŸ’€", "Should not trigger with only 2/3 branches"
    assert ctx.risk_level != "danger", "Risk should not be 'danger'"
    
    print("âœ… Partial punishment correctly NOT triggered")
    print("="*80)


if __name__ == "__main__":
    try:
        test_three_punishments_detection()
        test_no_punishment_with_two_branches()
        
        print("\nğŸ† ALL TESTS PASSED!")
        print("Sprint 5.3: The Skull Protocol is ready for deployment! ğŸ’€âœ¨")
        
    except AssertionError as e:
        print(f"\nâŒ TEST FAILED: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ ERROR: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
