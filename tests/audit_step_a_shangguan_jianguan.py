"""
[QGA V25.0 æ ¼å±€å®¡è®¡] Step A: åŸå±€æµ·é€‰
ä»»åŠ¡: [01-ä¼¤å®˜è§å®˜] é™æ€æ™¶æ ¼ç­›é€‰

ä»51.84ä¸‡æ ·æœ¬ä¸­ç­›é€‰å‡ºç¬¦åˆ"ä¼¤å®˜è§å®˜"æ¡ä»¶çš„æ ·æœ¬ï¼š
- 1ä¸ªå¸¦è´¢æ˜Ÿä¸­ç»§çš„ï¼ˆé¢„è®¾ç¨³æ€ï¼‰
- 2ä¸ªæ— è§£æ•‘ä¸”ç›¸ä½å¼ºå¹²æ¶‰çš„ï¼ˆé¢„è®¾å´©æ€/å¥‡ç‚¹ï¼‰
"""

import sys
from pathlib import Path
import json
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.trinity.core.engines.pattern_scout import PatternScout
from core.subjects.neural_router.feature_vectorizer import FeatureVectorizer
from core.trinity.core.nexus.definitions import BaziParticleNexus
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class StepASelection:
    """Step A: åŸå±€æµ·é€‰å™¨ï¼ˆä»51.84ä¸‡æ ·æœ¬ä¸­ç­›é€‰ï¼‰"""
    
    def __init__(self):
        self.scout = PatternScout()
        self.vectorizer = FeatureVectorizer()
        logger.info("âœ… Step A åŸå±€æµ·é€‰å™¨åˆå§‹åŒ–å®Œæˆï¼ˆ51.84ä¸‡æ ·æœ¬æ¨¡å¼ï¼‰")
    
    def extract_shi_shen(self, chart: List[Tuple[str, str]], day_master: str) -> Dict[str, float]:
        """æå–åç¥åˆ†å¸ƒ"""
        shi_shen_counts = {
            'æ¯”è‚©': 0.0, 'åŠ«è´¢': 0.0, 'é£Ÿç¥': 0.0, 'ä¼¤å®˜': 0.0,
            'æ­£è´¢': 0.0, 'åè´¢': 0.0, 'æ­£å®˜': 0.0, 'ä¸ƒæ€': 0.0,
            'æ­£å°': 0.0, 'åå°': 0.0
        }
        
        for gan, zhi in chart:
            # å¤©å¹²åç¥
            gan_shi_shen = BaziParticleNexus.get_shi_shen(gan, day_master)
            if gan_shi_shen in shi_shen_counts:
                shi_shen_counts[gan_shi_shen] += 1.0
        
        return shi_shen_counts
    
    def calculate_stress_tensor(self, chart: List[Tuple[str, str]]) -> float:
        """è®¡ç®—åº”åŠ›å¼ é‡"""
        stress = 0.0
        
        # åœ°æ”¯å†²å…‹
        branch_clashes = {
            'å­': 'åˆ', 'ä¸‘': 'æœª', 'å¯…': 'ç”³', 'å¯': 'é…‰',
            'è¾°': 'æˆŒ', 'å·³': 'äº¥'
        }
        branches = [p[1] for p in chart]
        for i in range(len(branches)):
            for j in range(i + 1, len(branches)):
                if branch_clashes.get(branches[i]) == branches[j] or \
                   branch_clashes.get(branches[j]) == branches[i]:
                    stress += 0.2
        
        # å¤©å¹²ç›¸å…‹
        stem_clashes = {
            'ç”²': 'åºš', 'ä¹™': 'è¾›', 'ä¸™': 'å£¬', 'ä¸': 'ç™¸', 'æˆŠ': 'ç”²',
            'å·±': 'ä¹™', 'åºš': 'ä¸™', 'è¾›': 'ä¸', 'å£¬': 'æˆŠ', 'ç™¸': 'å·±'
        }
        stems = [p[0] for p in chart]
        for i in range(len(stems)):
            for j in range(i + 1, len(stems)):
                if stem_clashes.get(stems[i]) == stems[j] or \
                   stem_clashes.get(stems[j]) == stems[i]:
                    stress += 0.1
        
        return min(1.0, stress)
    
    def analyze_chart(self, chart: List[Tuple[str, str]], day_master: str) -> Optional[Dict[str, Any]]:
        """åˆ†æå…«å­—æ˜¯å¦ç¬¦åˆ"ä¼¤å®˜è§å®˜"æ¡ä»¶"""
        # æå–åç¥åˆ†å¸ƒ
        shi_shen_counts = self.extract_shi_shen(chart, day_master)
        
        # è®¡ç®—ä¼¤å®˜å’Œæ­£å®˜å‘é‡
        shang_guan_count = shi_shen_counts.get('ä¼¤å®˜', 0)
        zheng_guan_count = shi_shen_counts.get('æ­£å®˜', 0)
        
        # å½’ä¸€åŒ–ï¼ˆè°ƒæ•´ï¼šä¼¤å®˜å’Œæ­£å®˜å„1ä¸ªå°±æ»¡è¶³æ¡ä»¶ï¼‰
        s_vector = min(1.0, shang_guan_count / 2.0)  # æœ‰1ä¸ªä¼¤å®˜å°±0.5
        g_vector = min(1.0, zheng_guan_count / 2.0)  # æœ‰1ä¸ªæ­£å®˜å°±0.5
        
        # è®¡ç®—åº”åŠ›å¼ é‡
        stress_tensor = self.calculate_stress_tensor(chart)
        
        # æ£€æŸ¥è´¢æ˜Ÿï¼ˆåœŸ/é‡‘ï¼‰ä½œä¸ºä¸­ç»§
        cai_count = shi_shen_counts.get('æ­£è´¢', 0) + shi_shen_counts.get('åè´¢', 0)
        cai_vector = min(1.0, cai_count / 2.0)
        
        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆåŸºæœ¬æ¡ä»¶ï¼ˆé™ä½é˜ˆå€¼ï¼Œå› ä¸ºå½’ä¸€åŒ–æ–¹å¼å·²è°ƒæ•´ï¼‰
        if s_vector > 0.3 and g_vector > 0.3 and stress_tensor > 0.2:
            # è®¡ç®—ç›¸ä½è§’ï¼ˆåŸºäºé‡‘ç«åœºå¼ºï¼‰
            elemental_fields = self.vectorizer.extract_elemental_fields(
                chart=chart,
                day_master=day_master,
                luck_pillar=None,
                year_pillar=None
            )
            
            metal_field = elemental_fields.get('metal', 0.0)
            fire_field = elemental_fields.get('fire', 0.0)
            phase_angle = abs(metal_field - fire_field)
            
            return {
                'chart': chart,
                'day_master': day_master,
                's_vector': s_vector,
                'g_vector': g_vector,
                'stress_tensor': stress_tensor,
                'cai_vector': cai_vector,
                'phase_angle': phase_angle,
                'metal_field': metal_field,
                'fire_field': fire_field,
                'shi_shen_counts': shi_shen_counts,
                'has_rescue': cai_vector > 0.3,  # è´¢æ˜Ÿä¸­ç»§
                'is_strong_interference': phase_angle > 0.3 and cai_vector < 0.2  # å¼ºå¹²æ¶‰ä¸”æ— è§£æ•‘
            }
        
        return None
    
    def select_samples(self, sample_size: int = 518400, target_count: int = 3) -> List[Dict[str, Any]]:
        """
        ä»51.84ä¸‡æ ·æœ¬ä¸­ç­›é€‰ç¬¦åˆæ¡ä»¶çš„æ ·æœ¬
        
        Args:
            sample_size: æ‰«ææ ·æœ¬æ•°ï¼ˆé»˜è®¤51.84ä¸‡ï¼‰
            target_count: ç›®æ ‡æ ·æœ¬æ•°ï¼ˆ1ä¸ªç¨³æ€ + 2ä¸ªå´©æ€ï¼‰
            
        Returns:
            ç­›é€‰ç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸš€ å¼€å§‹Step AåŸå±€æµ·é€‰ï¼ˆæ‰«æ{sample_size:,}ä¸ªæ ·æœ¬ï¼‰...")
        
        # ä½¿ç”¨PatternScoutæ‰«æ"ä¼¤å®˜è§å®˜"æ ¼å±€
        found_samples = []
        steady_state_samples = []
        collapse_state_samples = []
        
        def progress_callback(curr, total, stats):
            if curr % 10000 == 0 or curr == total:
                logger.info(f"ğŸ“Š æ‰«æè¿›åº¦: {curr:,}/{total:,} ({curr/total*100:.1f}%) | å·²æ‰¾åˆ°: {len(found_samples)}ä¸ªå€™é€‰")
        
        # æ‰«ææ ·æœ¬
        scout_results = self.scout.scout_pattern(
            pattern_id="SHANG_GUAN_JIAN_GUAN",
            sample_size=sample_size,
            progress_callback=progress_callback
        )
        
        logger.info(f"âœ… PatternScoutæ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(scout_results)} ä¸ªåŒ¹é…æ ·æœ¬")
        
        # è°ƒè¯•ï¼šæŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ ¼å¼
        if scout_results:
            logger.info(f"ğŸ” è°ƒè¯•ï¼šç¬¬ä¸€ä¸ªæ ·æœ¬çš„keys: {list(scout_results[0].keys())}")
            logger.info(f"ğŸ” è°ƒè¯•ï¼šç¬¬ä¸€ä¸ªæ ·æœ¬çš„chartç±»å‹: {type(scout_results[0].get('chart'))}")
            logger.info(f"ğŸ” è°ƒè¯•ï¼šç¬¬ä¸€ä¸ªæ ·æœ¬çš„chartå†…å®¹: {scout_results[0].get('chart')}")
        
        # åˆ†ææ¯ä¸ªåŒ¹é…æ ·æœ¬
        for idx, result in enumerate(scout_results):
            # å°è¯•å¤šç§æ ¼å¼
            chart_data = result.get('chart', [])
            if not chart_data:
                # å°è¯•ç›´æ¥ä»resultè·å–
                if 'year' in result and 'month' in result:
                    chart_data = [
                        (result.get('year', ['', ''])[0], result.get('year', ['', ''])[1]),
                        (result.get('month', ['', ''])[0], result.get('month', ['', ''])[1]),
                        (result.get('day', ['', ''])[0], result.get('day', ['', ''])[1]),
                        (result.get('hour', ['', ''])[0], result.get('hour', ['', ''])[1])
                    ]
                else:
                    continue
            
            if not chart_data or len(chart_data) < 4:
                continue
            
            # å¤„ç†chart_dataæ ¼å¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å…ƒç»„ï¼‰
            if isinstance(chart_data[0], str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œéœ€è¦è§£æ
                chart = [
                    (chart_data[0][0], chart_data[0][1]) if len(chart_data[0]) >= 2 else ('', ''),
                    (chart_data[1][0], chart_data[1][1]) if len(chart_data[1]) >= 2 else ('', ''),
                    (chart_data[2][0], chart_data[2][1]) if len(chart_data[2]) >= 2 else ('', ''),
                    (chart_data[3][0], chart_data[3][1]) if len(chart_data[3]) >= 2 else ('', '')
                ]
            else:
                # å¦‚æœæ˜¯å…ƒç»„æ ¼å¼
                chart = [
                    (chart_data[0][0], chart_data[0][1]) if len(chart_data[0]) >= 2 else ('', ''),
                    (chart_data[1][0], chart_data[1][1]) if len(chart_data[1]) >= 2 else ('', ''),
                    (chart_data[2][0], chart_data[2][1]) if len(chart_data[2]) >= 2 else ('', ''),
                    (chart_data[3][0], chart_data[3][1]) if len(chart_data[3]) >= 2 else ('', '')
                ]
            
            # æå–æ—¥ä¸»
            day_master = result.get('day_master') or (chart[2][0] if chart[2][0] else '')
            if not day_master:
                continue
            
            # åˆ†ææ ·æœ¬
            analysis = self.analyze_chart(chart, day_master)
            if analysis:
                analysis['scout_result'] = result  # ä¿ç•™åŸå§‹ç»“æœ
                found_samples.append(analysis)
                
                # åˆ†ç±»
                if analysis.get('has_rescue'):
                    steady_state_samples.append(analysis)
                elif analysis.get('is_strong_interference'):
                    collapse_state_samples.append(analysis)
            else:
                # è°ƒè¯•ï¼šæ‰“å°å‰å‡ ä¸ªæœªé€šè¿‡çš„æ ·æœ¬
                if idx < 3:
                    shi_shen = self.extract_shi_shen(chart, day_master)
                    s_vec = min(1.0, shi_shen.get('ä¼¤å®˜', 0) / 4.0)
                    g_vec = min(1.0, shi_shen.get('æ­£å®˜', 0) / 4.0)
                    stress = self.calculate_stress_tensor(chart)
                    logger.info(f"ğŸ” æ ·æœ¬{idx}æœªé€šè¿‡åˆ†æ: s_vector={s_vec:.3f}, g_vector={g_vec:.3f}, stress={stress:.3f}")
        
        logger.info(f"âœ… åˆ†æå®Œæˆ: æ€»è®¡{len(found_samples)}ä¸ªå€™é€‰ï¼Œç¨³æ€{len(steady_state_samples)}ä¸ªï¼Œå´©æ€{len(collapse_state_samples)}ä¸ª")
        
        # é€‰æ‹©æœ€ä½³æ ·æœ¬
        selected = []
        
        # é€‰æ‹©1ä¸ªç¨³æ€æ ·æœ¬ï¼ˆä¼˜å…ˆé€‰æ‹©è´¢æ˜Ÿæœ€å¼ºçš„ï¼‰
        if steady_state_samples:
            steady_state_samples.sort(key=lambda x: -x.get('cai_vector', 0))
            selected.append(steady_state_samples[0])
            logger.info(f"âœ… é€‰æ‹©ç¨³æ€æ ·æœ¬: è´¢æ˜Ÿå‘é‡={steady_state_samples[0]['cai_vector']:.3f}")
        else:
            # å¦‚æœæ²¡æœ‰ç¨³æ€æ ·æœ¬ï¼Œé€‰æ‹©è´¢æ˜Ÿæœ€å¼ºçš„å€™é€‰æ ·æœ¬
            candidates_with_cai = [s for s in found_samples if s.get('cai_vector', 0) > 0.1]
            if candidates_with_cai:
                candidates_with_cai.sort(key=lambda x: -x.get('cai_vector', 0))
                selected.append(candidates_with_cai[0])
                logger.info(f"âœ… é€‰æ‹©å‡†ç¨³æ€æ ·æœ¬: è´¢æ˜Ÿå‘é‡={candidates_with_cai[0]['cai_vector']:.3f}")
        
        # é€‰æ‹©2ä¸ªå´©æ€æ ·æœ¬ï¼ˆä¼˜å…ˆé€‰æ‹©ç›¸ä½è§’æœ€å¤§ã€åº”åŠ›æœ€å¤§çš„ï¼‰
        if collapse_state_samples:
            collapse_state_samples.sort(key=lambda x: -(x.get('phase_angle', 0) + x.get('stress_tensor', 0)))
            selected.extend(collapse_state_samples[:2])
            for i, sample in enumerate(collapse_state_samples[:2], 1):
                logger.info(f"âœ… é€‰æ‹©å´©æ€æ ·æœ¬{i}: ç›¸ä½è§’={sample['phase_angle']:.3f}, åº”åŠ›={sample['stress_tensor']:.3f}")
        else:
            # å¦‚æœæ²¡æœ‰å´©æ€æ ·æœ¬ï¼Œé€‰æ‹©åº”åŠ›æœ€å¤§ã€ç›¸ä½è§’æœ€å¤§çš„å€™é€‰æ ·æœ¬
            remaining = [s for s in found_samples if s not in selected]
            if remaining:
                remaining.sort(key=lambda x: -(x.get('stress_tensor', 0) + x.get('phase_angle', 0)))
                selected.extend(remaining[:min(2, len(remaining))])
                for i, sample in enumerate(remaining[:min(2, len(remaining))], 1):
                    logger.info(f"âœ… é€‰æ‹©å‡†å´©æ€æ ·æœ¬{i}: ç›¸ä½è§’={sample['phase_angle']:.3f}, åº”åŠ›={sample['stress_tensor']:.3f}")
        
        return selected[:target_count]


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ” [01-ä¼¤å®˜è§å®˜] Step A: åŸå±€æµ·é€‰ï¼ˆ51.84ä¸‡æ ·æœ¬ï¼‰")
    print("=" * 80)
    print("")
    print("ğŸ“‹ æµ·é€‰æ ‡å‡†:")
    print("  - S_Vector (ä¼¤å®˜) > 0.3")
    print("  - G_Vector (æ­£å®˜) > 0.3")
    print("  - stress_tensor > 0.2")
    print("  - ç›¸ä½è§’æ¥è¿‘ 180Â°ï¼ˆé‡‘ç«å¯¹å†²ï¼‰")
    print("")
    print("ğŸ¯ æ ·æœ¬è¦æ±‚:")
    print("  - 1ä¸ªå¸¦è´¢æ˜Ÿä¸­ç»§çš„ï¼ˆé¢„è®¾ç¨³æ€ï¼‰")
    print("  - 2ä¸ªæ— è§£æ•‘ä¸”ç›¸ä½å¼ºå¹²æ¶‰çš„ï¼ˆé¢„è®¾å´©æ€/å¥‡ç‚¹ï¼‰")
    print("")
    print("âš ï¸  æ³¨æ„ï¼šæ‰«æ51.84ä¸‡æ ·æœ¬å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
    print("")
    
    selector = StepASelection()
    
    # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œå¯ä»¥å…ˆæ‰«æè¾ƒå°çš„æ ·æœ¬æ•°
    # å®Œæ•´æ‰«æè¯·ä½¿ç”¨ sample_size=518400
    selected_samples = selector.select_samples(sample_size=10000, target_count=3)  # å…ˆç”¨1ä¸‡æ ·æœ¬æµ‹è¯•
    
    if not selected_samples:
        print("âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ ·æœ¬")
        print("   å»ºè®®ï¼šå¢åŠ æ‰«ææ ·æœ¬æ•°æˆ–é™ä½ç­›é€‰é˜ˆå€¼")
        return
    
    print("\n" + "=" * 80)
    print("âœ… æµ·é€‰å®Œæˆï¼")
    print("=" * 80)
    print("")
    
    for i, sample in enumerate(selected_samples, 1):
        chart = sample['chart']
        bazi_str = f"{chart[0][0]}{chart[0][1]} {chart[1][0]}{chart[1][1]} {chart[2][0]}{chart[2][1]} {chart[3][0]}{chart[3][1]}"
        
        print(f"ã€æ ·æœ¬ {i}ã€‘")
        print(f"  å…«å­—: {bazi_str}")
        print(f"  æ—¥ä¸»: {sample['day_master']}")
        print(f"  ä¼¤å®˜å‘é‡ (S_Vector): {sample['s_vector']:.3f}")
        print(f"  æ­£å®˜å‘é‡ (G_Vector): {sample['g_vector']:.3f}")
        print(f"  åº”åŠ›å¼ é‡: {sample['stress_tensor']:.3f}")
        print(f"  è´¢æ˜Ÿå‘é‡: {sample['cai_vector']:.3f}")
        print(f"  ç›¸ä½è§’: {sample['phase_angle']:.3f}")
        print(f"  é‡‘åœºå¼º: {sample['metal_field']:.3f}")
        print(f"  ç«åœºå¼º: {sample['fire_field']:.3f}")
        print(f"  çŠ¶æ€: {'ç¨³æ€ï¼ˆæœ‰è´¢æ˜Ÿä¸­ç»§ï¼‰' if sample.get('has_rescue') else 'å´©æ€ï¼ˆæ— è§£æ•‘ï¼‰'}")
        print("")
    
    # ä¿å­˜ç»“æœ
    output_file = Path('logs/step_a_shangguan_jianguan_selection.json')
    output_file.parent.mkdir(exist_ok=True)
    
    result_data = {
        'task': '[01-ä¼¤å®˜è§å®˜] Step A: åŸå±€æµ·é€‰ï¼ˆ51.84ä¸‡æ ·æœ¬ï¼‰',
        'timestamp': datetime.now().isoformat(),
        'total_samples': len(selected_samples),
        'samples': [
            {
                'bazi': f"{s['chart'][0][0]}{s['chart'][0][1]} {s['chart'][1][0]}{s['chart'][1][1]} {s['chart'][2][0]}{s['chart'][2][1]} {s['chart'][3][0]}{s['chart'][3][1]}",
                'day_master': s['day_master'],
                's_vector': s['s_vector'],
                'g_vector': s['g_vector'],
                'stress_tensor': s['stress_tensor'],
                'cai_vector': s['cai_vector'],
                'phase_angle': s['phase_angle'],
                'metal_field': s['metal_field'],
                'fire_field': s['fire_field'],
                'has_rescue': s.get('has_rescue', False),
                'is_strong_interference': s.get('is_strong_interference', False)
            }
            for s in selected_samples
        ]
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç»“æœå·²ä¿å­˜: {output_file}")
    print("")
    print("=" * 80)
    print("ğŸ¯ ä¸‹ä¸€æ­¥: Step B - åŠ¨æ€ä»¿çœŸ")
    print("=" * 80)
    print("")
    print("ğŸ’¡ æç¤ºï¼šå¦‚éœ€å®Œæ•´æ‰«æ51.84ä¸‡æ ·æœ¬ï¼Œè¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ sample_size=518400")


if __name__ == "__main__":
    main()
