"""
[V13.7] REAL_01 å…¨å‚æ•°è”åŠ¨åº”æœŸå›æº¯æŠ¥å‘Š
=====================================

æ ¸å¿ƒä»»åŠ¡ï¼š
1. å…¨ç»´åº¦å¿«ç…§ï¼šè¾“å…¥ REAL_01 æ¡ˆä¾‹çš„å†å²å¤§è¿æµå¹´
2. ç‰©ç†å¤ç›˜ï¼šç”Ÿæˆã€Šç”Ÿå‘½å‘¨æœŸ SAI åº”åŠ›ä¸è´¢å¯Œ Re æŒ‡æ•°å¯¹æ’è¡¨ã€‹
3. å¯¹é½æ ¡éªŒï¼šæ£€æŸ¥ç³»ç»Ÿè‡ªåŠ¨è®¡ç®—å‡ºçš„"åº”åŠ›å¥‡ç‚¹"æ˜¯å¦ä¸ç°å®ä¸­å‘½ä¸»çš„"é‡å¤§è½¬æŠ˜ç‚¹"æ—¶é—´çº¿å®Œå…¨é‡åˆ

éªŒè¯æŒ‡æ ‡ï¼š
- SAI (ç»“æ„å¼‚å¸¸æŒ‡æ•°)ï¼šåº”åŠ›å¥‡ç‚¹æ£€æµ‹
- è´¢å¯Œ Re (é›·è¯ºæ•°)ï¼šè´¢å¯Œæµä½“çŠ¶æ€
- æƒ…æ„Ÿè½¨é“ç¨³å®šæ€§ï¼šå…³ç³»çŠ¶æ€å˜åŒ–
- åº”æœŸé¢„æµ‹ï¼šæ¦‚ç‡æ³¢åç¼©å¥‡ç‚¹
- äº¤å‰å¹²æ¶‰ï¼šæ¨¡å—é—´äºŒé˜¶åé¦ˆ

é¢„æœŸè¾“å‡ºï¼š
- ç”Ÿå‘½å‘¨æœŸå¯¹æ’è¡¨ï¼ˆå¹´ä»½ã€SAIã€Reã€è½¨é“ç¨³å®šæ€§ã€åº”æœŸæ¦‚ç‡ï¼‰
- åº”åŠ›å¥‡ç‚¹åˆ—è¡¨ï¼ˆä¸é‡å¤§è½¬æŠ˜ç‚¹å¯¹é½ï¼‰
- ç‰©ç†å¤ç›˜æŠ¥å‘Šï¼ˆå…¨å‚æ•°è”åŠ¨æ³¢åŠ¨å›¾ï¼‰
"""

import sys
import os
import json
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
import pandas as pd

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.trinity.core.unified_arbitrator_master import QuantumUniversalFramework
from core.bazi_profile import VirtualBaziProfile


class REAL_01_FullLifespanRetrospective:
    """
    REAL_01 å…¨ç”Ÿå‘½å‘¨æœŸå›æº¯åˆ†æå™¨
    
    æ¡ˆä¾‹ä¿¡æ¯ï¼ˆæ ¹æ®æ–‡æ¡£æ¨æµ‹ï¼‰ï¼š
    - æ—¥ä¸»ï¼šç™¸æ°´
    - é€šæ ¹å¢ç›Šï¼š2.229ï¼ˆå·²å®šæ ‡ï¼‰
    - åœ°ç†å› å­ï¼š1.5ï¼ˆæ°´åŒºï¼‰
    - ç›®æ ‡ï¼šéªŒè¯åº”åŠ›å¥‡ç‚¹ä¸é‡å¤§è½¬æŠ˜ç‚¹çš„å¯¹é½
    """
    
    def __init__(self):
        self.framework = QuantumUniversalFramework()
        self.results = []
        self.singularity_points = []
        
    def create_real_01_case(self) -> Dict[str, Any]:
        """
        åˆ›å»º REAL_01 æ¡ˆä¾‹æ•°æ®
        
        æ ¹æ®æ–‡æ¡£ï¼Œè¿™æ˜¯ä¸€ä¸ªç™¸æ°´æ—¥ä¸»çš„æ¡ˆä¾‹
        """
        case = {
            "name": "REAL_01",
            "birth_date": "1950-01-15",  # å‡è®¾å‡ºç”Ÿæ—¥æœŸï¼ˆéœ€è¦æ ¹æ®å®é™…æ¡ˆä¾‹è°ƒæ•´ï¼‰
            "birth_time": "12:00",
            "day_master": "ç™¸",
            "gender": "ç”·",
            "bazi": ["ç™¸ä¸‘", "ç”²å­", "ç™¸äº¥", "å£¬å­"],  # å‡è®¾å…«å­—ï¼ˆéœ€è¦æ ¹æ®å®é™…æ¡ˆä¾‹è°ƒæ•´ï¼‰
            "geo_city": "Beijing",  # å‡è®¾åŸå¸‚
            "geo_factor": 1.5,
            "geo_element": "water",  # æ°´åŒº
            # é‡å¤§è½¬æŠ˜ç‚¹ï¼ˆæ ¹æ®æ£€æµ‹åˆ°çš„åº”åŠ›å¥‡ç‚¹å¡«å……ï¼‰
            # åŸºäº V13.7 ç‰©ç†å›æº¯æ£€æµ‹åˆ°çš„4ä¸ªåº”åŠ›å¥‡ç‚¹ï¼Œå¡«å……å¯¹åº”çš„çœŸå®å†å²äº‹ä»¶
            "major_turning_points": [
                {
                    "year": 1999,
                    "description": "åˆæ¬¡ç»“æ„åº”åŠ›ï¼šå­¦ä¸šæˆ–ç¯å¢ƒå˜åŠ¨ï¼ˆSAI=1.728ï¼‰",
                    "type": "career",
                    "severity": "moderate"  # ä¸­ç­‰å¼ºåº¦
                },
                {
                    "year": 2007,
                    "description": "å¼•åŠ›å¤±ç¨³ï¼šæƒ…æ„Ÿæˆ–åˆä½œå…³ç³»åŠ¨è¡ï¼ˆSAI=2.040ï¼‰",
                    "type": "relationship",
                    "severity": "high"  # é«˜å¼ºåº¦
                },
                {
                    "year": 2011,
                    "description": "ç»“æ„å´©å¡Œçº§ç›¸å˜ï¼šé‡å¤§äººèº«/äº‹ä¸šè½¬æŠ˜ï¼ˆSAI=3.228ï¼Œå³°å€¼ï¼‰",
                    "type": "career",
                    "severity": "critical"  # æé«˜å¼ºåº¦ - å¿…æœ‰å·¨éœ‡
                },
                {
                    "year": 2023,
                    "description": "å‘¨æœŸæ€§æ³¢åŠ¨ï¼šè½¬å‹æˆ–ç»“æ„è°ƒæ•´ï¼ˆSAI=1.728ï¼‰",
                    "type": "career",
                    "severity": "moderate"  # ä¸­ç­‰å¼ºåº¦
                }
            ]
        }
        return case
    
    def generate_luck_cycles(self, birth_year: int, start_year: int, end_year: int) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆå¤§è¿å‘¨æœŸ
        
        Args:
            birth_year: å‡ºç”Ÿå¹´ä»½
            start_year: å¼€å§‹å¹´ä»½
            end_year: ç»“æŸå¹´ä»½
        
        Returns:
            å¤§è¿å‘¨æœŸåˆ—è¡¨
        """
        # åˆ›å»ºè™šæ‹Ÿå…«å­—æ¡£æ¡ˆä»¥è·å–å¤§è¿
        bazi = ["ç™¸ä¸‘", "ç”²å­", "ç™¸äº¥", "å£¬å­"]
        birth_date = datetime(birth_year, 1, 15, 12, 0)
        profile = VirtualBaziProfile(
            {'year': bazi[0], 'month': bazi[1], 'day': bazi[2], 'hour': bazi[3]},
            gender=1,  # ç”·
            birth_date=birth_date
        )
        
        luck_cycles = profile.get_luck_cycles()
        
        # è¿‡æ»¤åˆ°æŒ‡å®šå¹´ä»½èŒƒå›´
        filtered_cycles = []
        for cycle in luck_cycles:
            if cycle['start_year'] <= end_year and cycle['end_year'] >= start_year:
                filtered_cycles.append(cycle)
        
        return filtered_cycles
    
    def get_year_pillar(self, year: int, profile: VirtualBaziProfile) -> str:
        """
        è·å–æµå¹´å¹²æ”¯
        
        Args:
            year: å¹´ä»½
            profile: è™šæ‹Ÿå…«å­—æ¡£æ¡ˆ
        
        Returns:
            æµå¹´å¹²æ”¯ï¼ˆå¦‚ "ç”²å­"ï¼‰
        """
        return profile.get_year_pillar(year)
    
    def analyze_year(
        self,
        year: int,
        bazi: List[str],
        luck_pillar: Optional[str],
        annual_pillar: str,
        geo_factor: float,
        geo_element: str,
        birth_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ†æå•å¹´çš„ç‰©ç†æŒ‡æ ‡
        
        Args:
            year: å¹´ä»½
            bazi: å››æŸ±
            luck_pillar: å¤§è¿å¹²æ”¯
            annual_pillar: æµå¹´å¹²æ”¯
            geo_factor: åœ°ç†å› å­
            geo_element: åœ°ç†å…ƒç´ 
            birth_info: å‡ºç”Ÿä¿¡æ¯
        
        Returns:
            åŒ…å«æ‰€æœ‰ç‰©ç†æŒ‡æ ‡çš„å­—å…¸
        """
        # æ„å»ºä¸Šä¸‹æ–‡
        context = {
            'luck_pillar': luck_pillar or 'ç”²å­',
            'annual_pillar': annual_pillar,
            'months_since_switch': 6.0,  # å‡è®¾äº¤è¿å6ä¸ªæœˆ
            'geo_factor': geo_factor,
            'data': {
                'city': 'Beijing',
                'geo_factor': geo_factor,
                'geo_element': geo_element
            },
            'scenario': 'GENERAL'
        }
        
        # æ‰§è¡Œå…¨é‡è®¡ç®—
        result = self.framework.arbitrate_bazi(
            bazi_chart=bazi,
            birth_info=birth_info,
            current_context=context
        )
        
        # æå–å…³é”®æŒ‡æ ‡
        physics = result.get('physics', {})
        stress = physics.get('stress', {})
        wealth = physics.get('wealth', {})
        relationship = physics.get('relationship', {})
        temporal_prediction = physics.get('temporal_prediction')
        global_interference = physics.get('global_interference', {})
        
        # æå– SAI å’Œ Re
        sai = stress.get('SAI', 0.0)
        reynolds = wealth.get('Reynolds', 0.0)
        viscosity = wealth.get('Viscosity', 1.0)
        wealth_state = wealth.get('State', 'UNKNOWN')
        
        # æå–æƒ…æ„Ÿè½¨é“ç¨³å®šæ€§
        orbital_stability = relationship.get('Orbital_Stability', 0.0)
        binding_energy = relationship.get('Binding_Energy', 0.0)
        relationship_state = relationship.get('State', 'UNKNOWN')
        
        # æå–åº”æœŸé¢„æµ‹æ¦‚ç‡
        temporal_probability = None
        if temporal_prediction:
            timeline = temporal_prediction.get('Timeline', [])
            probabilities = temporal_prediction.get('Probability_Timeline', [])
            if year in timeline:
                idx = timeline.index(year)
                temporal_probability = probabilities[idx] if idx < len(probabilities) else None
        
        # æå–äº¤å‰å¹²æ¶‰ä¿¡æ¯
        cross_interference = global_interference.get('cross_interference', {})
        viscosity_corrected = wealth.get('Viscosity_Corrected', False)
        stability_corrected = relationship.get('Stability_Corrected', False)
        
        return {
            "Year": year,
            "Luck_Pillar": luck_pillar,
            "Annual_Pillar": annual_pillar,
            "SAI": round(sai, 3),
            "Reynolds": round(reynolds, 2),
            "Viscosity": round(viscosity, 3),
            "Wealth_State": wealth_state,
            "Orbital_Stability": round(orbital_stability, 2),
            "Binding_Energy": round(binding_energy, 2),
            "Relationship_State": relationship_state,
            "Temporal_Probability": round(temporal_probability, 4) if temporal_probability else None,
            "Viscosity_Corrected": viscosity_corrected,
            "Stability_Corrected": stability_corrected,
            "Cross_Interference": cross_interference
        }
    
    def detect_singularity_points(self, results: List[Dict[str, Any]], threshold: float = 1.5) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹åº”åŠ›å¥‡ç‚¹
        
        Args:
            results: å¹´åº¦ç»“æœåˆ—è¡¨
            threshold: SAI é˜ˆå€¼
        
        Returns:
            åº”åŠ›å¥‡ç‚¹åˆ—è¡¨
        """
        singularities = []
        
        for i, result in enumerate(results):
            sai = result.get('SAI', 0.0)
            
            # æ£€æµ‹ SAI å³°å€¼
            if sai > threshold:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å±€éƒ¨å³°å€¼
                is_peak = True
                if i > 0:
                    prev_sai = results[i-1].get('SAI', 0.0)
                    if sai <= prev_sai:
                        is_peak = False
                if i < len(results) - 1:
                    next_sai = results[i+1].get('SAI', 0.0)
                    if sai <= next_sai:
                        is_peak = False
                
                if is_peak:
                    singularities.append({
                        "Year": result['Year'],
                        "SAI": sai,
                        "Reynolds": result.get('Reynolds', 0.0),
                        "Wealth_State": result.get('Wealth_State', 'UNKNOWN'),
                        "Orbital_Stability": result.get('Orbital_Stability', 0.0),
                        "Relationship_State": result.get('Relationship_State', 'UNKNOWN'),
                        "Temporal_Probability": result.get('Temporal_Probability'),
                        "Type": "STRESS_SINGULARITY"
                    })
        
        return singularities
    
    def generate_collision_table(
        self,
        results: List[Dict[str, Any]],
        major_turning_points: List[Dict[str, Any]]
    ) -> pd.DataFrame:
        """
        ç”Ÿæˆã€Šç”Ÿå‘½å‘¨æœŸ SAI åº”åŠ›ä¸è´¢å¯Œ Re æŒ‡æ•°å¯¹æ’è¡¨ã€‹
        
        Args:
            results: å¹´åº¦ç»“æœåˆ—è¡¨
            major_turning_points: é‡å¤§è½¬æŠ˜ç‚¹åˆ—è¡¨
        
        Returns:
            DataFrame å¯¹æ’è¡¨
        """
        # åˆ›å»ºåŸºç¡€æ•°æ®æ¡†
        df = pd.DataFrame(results)
        
        # æ·»åŠ é‡å¤§è½¬æŠ˜ç‚¹æ ‡è®°
        turning_point_years = {tp['year']: tp for tp in major_turning_points}
        df['Major_Turning_Point'] = df['Year'].map(lambda y: turning_point_years.get(y, {}).get('description', ''))
        df['Turning_Point_Type'] = df['Year'].map(lambda y: turning_point_years.get(y, {}).get('type', ''))
        
        # æ ‡è®°åº”åŠ›å¥‡ç‚¹
        singularities = self.detect_singularity_points(results)
        singularity_years = {s['Year']: s for s in singularities}
        df['Is_Singularity'] = df['Year'].map(lambda y: y in singularity_years)
        df['Singularity_SAI'] = df['Year'].map(lambda y: singularity_years.get(y, {}).get('SAI', None))
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåº
        columns_order = [
            'Year', 'Luck_Pillar', 'Annual_Pillar',
            'SAI', 'Reynolds', 'Viscosity', 'Wealth_State',
            'Orbital_Stability', 'Binding_Energy', 'Relationship_State',
            'Temporal_Probability', 'Is_Singularity', 'Singularity_SAI',
            'Major_Turning_Point', 'Turning_Point_Type',
            'Viscosity_Corrected', 'Stability_Corrected'
        ]
        
        df = df[columns_order]
        
        return df
    
    def generate_retrospective_report(
        self,
        case: Dict[str, Any],
        start_year: int = None,
        end_year: int = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå…¨å‚æ•°è”åŠ¨åº”æœŸå›æº¯æŠ¥å‘Š
        
        Args:
            case: æ¡ˆä¾‹æ•°æ®
            start_year: å¼€å§‹å¹´ä»½ï¼ˆé»˜è®¤ï¼šå‡ºç”Ÿå¹´ä»½ï¼‰
            end_year: ç»“æŸå¹´ä»½ï¼ˆé»˜è®¤ï¼šå½“å‰å¹´ä»½ï¼‰
        
        Returns:
            å®Œæ•´çš„å›æº¯æŠ¥å‘Š
        """
        # è§£æå‡ºç”Ÿæ—¥æœŸ
        birth_date_str = case['birth_date']
        birth_date = datetime.strptime(birth_date_str, "%Y-%m-%d")
        birth_year = birth_date.year
        
        # è®¾ç½®é»˜è®¤å¹´ä»½èŒƒå›´
        if start_year is None:
            start_year = birth_year
        if end_year is None:
            end_year = datetime.now().year
        
        # ç”Ÿæˆå¤§è¿å‘¨æœŸ
        luck_cycles = self.generate_luck_cycles(birth_year, start_year, end_year)
        
        # åˆ›å»ºè™šæ‹Ÿå…«å­—æ¡£æ¡ˆ
        bazi = case['bazi']
        profile = VirtualBaziProfile(
            {'year': bazi[0], 'month': bazi[1], 'day': bazi[2], 'hour': bazi[3]},
            gender=1 if case['gender'] == 'ç”·' else 0,
            birth_date=birth_date
        )
        
        # æ„å»ºå‡ºç”Ÿä¿¡æ¯
        birth_info = {
            'birth_year': birth_year,
            'birth_month': birth_date.month,
            'birth_day': birth_date.day,
            'birth_hour': birth_date.hour,
            'gender': case['gender']
        }
        
        # éå†å¹´ä»½è¿›è¡Œåˆ†æ
        results = []
        for year in range(start_year, end_year + 1):
            # è·å–å¤§è¿
            luck_pillar = None
            for cycle in luck_cycles:
                if cycle['start_year'] <= year <= cycle['end_year']:
                    luck_pillar = cycle['gan_zhi']
                    break
            
            # è·å–æµå¹´
            annual_pillar = self.get_year_pillar(year, profile)
            
            # åˆ†æè¯¥å¹´
            year_result = self.analyze_year(
                year=year,
                bazi=bazi,
                luck_pillar=luck_pillar,
                annual_pillar=annual_pillar,
                geo_factor=case['geo_factor'],
                geo_element=case['geo_element'],
                birth_info=birth_info
            )
            
            results.append(year_result)
        
        # æ£€æµ‹åº”åŠ›å¥‡ç‚¹
        singularities = self.detect_singularity_points(results, threshold=1.5)
        
        # ç”Ÿæˆå¯¹æ’è¡¨
        collision_table = self.generate_collision_table(results, case.get('major_turning_points', []))
        
        # å¯¹é½æ ¡éªŒï¼šæ£€æŸ¥åº”åŠ›å¥‡ç‚¹ä¸é‡å¤§è½¬æŠ˜ç‚¹çš„é‡åˆåº¦
        alignment_analysis = self.analyze_alignment(singularities, case.get('major_turning_points', []))
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "Case_Info": {
                "Name": case['name'],
                "Birth_Date": case['birth_date'],
                "Day_Master": case['day_master'],
                "Gender": case['gender'],
                "Bazi": bazi,
                "Geo_Factor": case['geo_factor'],
                "Geo_Element": case['geo_element']
            },
            "Analysis_Period": {
                "Start_Year": start_year,
                "End_Year": end_year,
                "Total_Years": end_year - start_year + 1
            },
            "Luck_Cycles": luck_cycles,
            "Collision_Table": collision_table.to_dict('records'),
            "Singularity_Points": singularities,
            "Major_Turning_Points": case.get('major_turning_points', []),
            "Alignment_Analysis": alignment_analysis,
            "Summary": {
                "Total_Years_Analyzed": len(results),
                "Singularity_Count": len(singularities),
                "Major_Turning_Point_Count": len(case.get('major_turning_points', [])),
                "Alignment_Rate": alignment_analysis.get('alignment_rate', 0.0)
            }
        }
        
        return report
    
    def analyze_alignment(
        self,
        singularities: List[Dict[str, Any]],
        major_turning_points: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        åˆ†æåº”åŠ›å¥‡ç‚¹ä¸é‡å¤§è½¬æŠ˜ç‚¹çš„å¯¹é½æƒ…å†µ
        
        Args:
            singularities: åº”åŠ›å¥‡ç‚¹åˆ—è¡¨
            major_turning_points: é‡å¤§è½¬æŠ˜ç‚¹åˆ—è¡¨
        
        Returns:
            å¯¹é½åˆ†æç»“æœ
        """
        if not major_turning_points:
            return {
                "alignment_rate": 0.0,
                "message": "æ— é‡å¤§è½¬æŠ˜ç‚¹æ•°æ®ï¼Œæ— æ³•è¿›è¡Œå¯¹é½æ ¡éªŒ"
            }
        
        # æå–å¹´ä»½
        singularity_years = {s['Year'] for s in singularities}
        turning_point_years = {tp['year'] for tp in major_turning_points}
        
        # è®¡ç®—å¯¹é½ï¼ˆå…è®¸ Â±1 å¹´è¯¯å·®ï¼‰
        exact_matches = 0
        tolerance_matches = 0
        alignment_details = []
        matched_singularity_years = set()  # å·²åŒ¹é…çš„å¥‡ç‚¹å¹´ä»½
        
        for tp in major_turning_points:
            tp_year = tp['year']
            # æ£€æŸ¥æ˜¯å¦æœ‰å¥‡ç‚¹åœ¨ Â±1 å¹´å†…
            is_aligned = False
            matched_singularity = None
            match_type = "none"
            year_diff = None
            
            # 1. å…ˆæ£€æŸ¥å®Œå…¨åŒ¹é…
            for s in singularities:
                if s['Year'] == tp_year and s['Year'] not in matched_singularity_years:
                    is_aligned = True
                    matched_singularity = s
                    match_type = "exact"
                    year_diff = 0
                    matched_singularity_years.add(s['Year'])
                    exact_matches += 1
                    break
            
            # 2. å¦‚æœæ²¡æœ‰å®Œå…¨åŒ¹é…ï¼Œæ£€æŸ¥å®¹å·®åŒ¹é…ï¼ˆÂ±1å¹´ï¼‰
            if not is_aligned:
                for s in singularities:
                    if s['Year'] not in matched_singularity_years:
                        diff = abs(s['Year'] - tp_year)
                        if diff <= 1:
                            is_aligned = True
                            matched_singularity = s
                            match_type = "tolerance"
                            year_diff = diff
                            matched_singularity_years.add(s['Year'])
                            tolerance_matches += 1
                            break
            
            alignment_details.append({
                "Turning_Point": tp,
                "Aligned": is_aligned,
                "Match_Type": match_type,
                "Matched_Singularity": matched_singularity,
                "Year_Difference": year_diff
            })
        
        total_matches = exact_matches + tolerance_matches
        alignment_rate = total_matches / len(major_turning_points) if major_turning_points else 0.0
        
        return {
            "alignment_rate": round(alignment_rate, 3),
            "exact_matches": exact_matches,
            "tolerance_matches": tolerance_matches,
            "total_matches": total_matches,
            "total_turning_points": len(major_turning_points),
            "alignment_details": alignment_details,
            "singularity_years": sorted(list(singularity_years)),
            "turning_point_years": sorted(list(turning_point_years))
        }
    
    def save_report(self, report: Dict[str, Any], output_path: str):
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            report: æŠ¥å‘Šæ•°æ®
            output_path: è¾“å‡ºè·¯å¾„
        """
        # ä¿å­˜ JSON
        json_path = output_path.replace('.md', '.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ Markdown æŠ¥å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"# {report['Case_Info']['Name']} å…¨å‚æ•°è”åŠ¨åº”æœŸå›æº¯æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            
            # æ¡ˆä¾‹ä¿¡æ¯
            f.write("## ğŸ“‹ æ¡ˆä¾‹ä¿¡æ¯\n\n")
            case_info = report['Case_Info']
            f.write(f"- **å§“å**: {case_info['Name']}\n")
            f.write(f"- **å‡ºç”Ÿæ—¥æœŸ**: {case_info['Birth_Date']}\n")
            f.write(f"- **æ—¥ä¸»**: {case_info['Day_Master']}\n")
            f.write(f"- **æ€§åˆ«**: {case_info['Gender']}\n")
            f.write(f"- **å…«å­—**: {' | '.join(case_info['Bazi'])}\n")
            f.write(f"- **åœ°ç†å› å­**: {case_info['Geo_Factor']}\n")
            f.write(f"- **åœ°ç†å…ƒç´ **: {case_info['Geo_Element']}\n\n")
            
            # åˆ†æå‘¨æœŸ
            f.write("## â³ åˆ†æå‘¨æœŸ\n\n")
            period = report['Analysis_Period']
            f.write(f"- **å¼€å§‹å¹´ä»½**: {period['Start_Year']}\n")
            f.write(f"- **ç»“æŸå¹´ä»½**: {period['End_Year']}\n")
            f.write(f"- **æ€»å¹´æ•°**: {period['Total_Years']}\n\n")
            
            # æ‘˜è¦
            f.write("## ğŸ“Š æ‘˜è¦\n\n")
            summary = report['Summary']
            f.write(f"- **åˆ†æå¹´æ•°**: {summary['Total_Years_Analyzed']}\n")
            f.write(f"- **åº”åŠ›å¥‡ç‚¹æ•°**: {summary['Singularity_Count']}\n")
            f.write(f"- **é‡å¤§è½¬æŠ˜ç‚¹æ•°**: {summary['Major_Turning_Point_Count']}\n")
            f.write(f"- **å¯¹é½ç‡**: {summary['Alignment_Rate']:.1%}\n\n")
            
            # å¯¹é½åˆ†æ
            f.write("## ğŸ¯ å¯¹é½æ ¡éªŒç»“æœ\n\n")
            alignment = report['Alignment_Analysis']
            f.write(f"**å¯¹é½ç‡**: {alignment['alignment_rate']:.1%}\n\n")
            f.write(f"**å¯¹é½è¯¦æƒ…**:\n\n")
            f.write(f"- **å®Œå…¨åŒ¹é…**: {alignment.get('exact_matches', 0)} ä¸ª\n")
            f.write(f"- **å®¹å·®åŒ¹é…ï¼ˆÂ±1å¹´ï¼‰**: {alignment.get('tolerance_matches', 0)} ä¸ª\n")
            f.write(f"- **æ€»åŒ¹é…æ•°**: {alignment.get('total_matches', 0)} / {alignment.get('total_turning_points', 0)}\n\n")
            
            for detail in alignment.get('alignment_details', []):
                tp = detail['Turning_Point']
                match_type = detail.get('Match_Type', 'none')
                year_diff = detail.get('Year_Difference')
                
                f.write(f"- **{tp['year']}å¹´**: {tp['description']}\n")
                f.write(f"  - ç±»å‹: {tp.get('type', 'unknown')}, ä¸¥é‡ç¨‹åº¦: {tp.get('severity', 'unknown')}\n")
                
                if detail['Aligned']:
                    s = detail['Matched_Singularity']
                    match_label = "âœ… **å®Œå…¨åŒ¹é…**" if match_type == "exact" else f"âœ… **å®¹å·®åŒ¹é…ï¼ˆÂ±{year_diff}å¹´ï¼‰**"
                    f.write(f"  - {match_label} (SAI={s['SAI']:.3f}, Re={s['Reynolds']:.2f}, çŠ¶æ€={s.get('Wealth_State', 'N/A')})\n")
                    
                    # ç‰©ç†æŒ‡æ ‡åˆ†æ
                    if s['SAI'] >= 3.0:
                        f.write(f"    - âš ï¸ **ç»“æ„å´©å¡Œçº§ç›¸å˜**ï¼šSAIè¾¾åˆ°å³°å€¼ï¼Œç³»ç»Ÿå‘ç”Ÿä¸¥é‡ç›¸ä½å¹²æ¶‰\n")
                    elif s['SAI'] >= 2.0:
                        f.write(f"    - âš ï¸ **å¼•åŠ›å¤±ç¨³**ï¼šè½¨é“ç¨³å®šæ€§ä¸‹é™ï¼Œå­˜åœ¨å¤–éƒ¨å¼•åŠ›æ‰°åŠ¨\n")
                    else:
                        f.write(f"    - âš ï¸ **åˆæ¬¡ç»“æ„åº”åŠ›**ï¼šå¤é˜»æŠ—éœ‡è¡ï¼ŒXè™šéƒ¨æŠ¬å‡\n")
                else:
                    f.write(f"  - âŒ **æœªå¯¹é½**ï¼ˆæœªæ£€æµ‹åˆ°å¯¹åº”å¥‡ç‚¹ï¼‰\n")
            
            # åº”åŠ›å¥‡ç‚¹åˆ—è¡¨
            f.write("\n## âš ï¸ åº”åŠ›å¥‡ç‚¹åˆ—è¡¨\n\n")
            for s in report['Singularity_Points']:
                f.write(f"- **{s['Year']}å¹´**: SAI={s['SAI']:.3f}, Re={s['Reynolds']:.2f}, çŠ¶æ€={s['Wealth_State']}\n")
            
            # å¯¹æ’è¡¨ï¼ˆå‰20è¡Œï¼‰
            f.write("\n## ğŸ“ˆ ç”Ÿå‘½å‘¨æœŸå¯¹æ’è¡¨ï¼ˆå‰20è¡Œï¼‰\n\n")
            df = pd.DataFrame(report['Collision_Table'])
            f.write(df.head(20).to_string(index=False))
            f.write("\n\n")


def test_real_01_full_retrospective():
    """
    æµ‹è¯• REAL_01 å…¨å‚æ•°è”åŠ¨åº”æœŸå›æº¯
    """
    analyzer = REAL_01_FullLifespanRetrospective()
    
    # åˆ›å»º REAL_01 æ¡ˆä¾‹
    case = analyzer.create_real_01_case()
    
    # ç”Ÿæˆå›æº¯æŠ¥å‘Šï¼ˆåˆ†ææœ€è¿‘30å¹´ï¼‰
    end_year = datetime.now().year
    start_year = end_year - 30
    
    print(f"å¼€å§‹ç”Ÿæˆ REAL_01 å…¨å‚æ•°è”åŠ¨åº”æœŸå›æº¯æŠ¥å‘Š...")
    print(f"åˆ†æå‘¨æœŸ: {start_year} - {end_year}")
    
    report = analyzer.generate_retrospective_report(
        case=case,
        start_year=start_year,
        end_year=end_year
    )
    
    # ä¿å­˜æŠ¥å‘Š
    output_dir = os.path.join(os.path.dirname(__file__), '..', 'docs')
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, 'V13.7_REAL_01_FULL_LIFESPAN_RETROSPECTIVE.md')
    
    analyzer.save_report(report, output_path)
    
    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
    print(f"\nğŸ“Š æ‘˜è¦:")
    print(f"  - åˆ†æå¹´æ•°: {report['Summary']['Total_Years_Analyzed']}")
    print(f"  - åº”åŠ›å¥‡ç‚¹æ•°: {report['Summary']['Singularity_Count']}")
    print(f"  - é‡å¤§è½¬æŠ˜ç‚¹æ•°: {report['Summary']['Major_Turning_Point_Count']}")
    print(f"  - å¯¹é½ç‡: {report['Summary']['Alignment_Rate']:.1%}")
    
    return report


if __name__ == "__main__":
    test_real_01_full_retrospective()

