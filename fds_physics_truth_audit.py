#!/usr/bin/env python3
"""
FDS ç‰©ç†çœŸå®æ€§å®¡è®¡è„šæœ¬ (Physics Truth Audit)
============================================
[ç¬¬020å·å·¥ç¨‹æŒ‡ä»¤] ä»"ç›²ç›®æ‹Ÿåˆ"è½¬å‘"ç‰©ç†æ±‚çœŸ"

**æ ¸å¿ƒå“²å­¦**ï¼š
- ä¸å†å¼ºæ±‚ç‰©ç†æ¨¡å‹æ­»ç£•å¤å…¸ä¸°åº¦
- ä¿ç•™ç‰©ç†æµå½¢çš„è‡ªç„¶å½¢çŠ¶
- å°†åå·®è§†ä¸º"æ³•ç†ä¸ç‰©ç†çš„æ¢ç´¢åŒºé—´"
- å¼•å…¥æµå½¢æº¢å‡ºç³»æ•°(MEF)å’Œè±¡é™åˆ†æ

**è¾“å‡º**ï¼š
- ç‰©ç†çœŸå®æ€§æŠ¥å‘Š
- è±¡é™å®¡è®¡åˆ†æ
- æµå½¢æº¢å‡ºç³»æ•°(MEF)
- IoUé‡åˆåº¦åˆ†æ
"""

import argparse
import json
import numpy as np
from pathlib import Path
from typing import Dict, Any, Set, Tuple, List
import sys

from fds_load_acceptance import (
    load_registry, load_manifest, extract_base_abundance,
    get_weights_matrix, calculate_5d_tensor, compute_mahalanobis_distance,
    load_threshold_from_registry, load_config_mahalanobis_threshold,
    DEFAULT_DATA, DEFAULT_TOLERANCE
)

REGISTRY_DIR = Path("./registry/holographic_pattern")
MANIFEST_DIR = Path("./config/patterns")


def calculate_quadrant_analysis(
    pattern_id: str,
    data_path: str,
    threshold: float
) -> Dict[str, Any]:
    """
    è±¡é™åˆ†æï¼šç»Ÿè®¡ç‰©ç†æ¨¡å‹ä¸å¤å…¸é€»è¾‘çš„å·®å¼‚åŒºåŸŸ
    
    è¿”å›:
    {
        'logic_only': ä»…é€»è¾‘åŒ¹é…çš„æ ·æœ¬é›†åˆ
        'physics_only': ä»…ç‰©ç†åŒ¹é…çš„æ ·æœ¬é›†åˆ
        'intersection': äº¤é›†æ ·æœ¬é›†åˆ
        'union': å¹¶é›†æ ·æœ¬é›†åˆ
        'logic_count': é€»è¾‘åŒ¹é…æ•°
        'physics_count': ç‰©ç†åŒ¹é…æ•°
        'intersection_count': äº¤é›†æ•°
        'union_count': å¹¶é›†æ•°
        'iou': IoUå€¼
        'logic_only_samples': ä»…é€»è¾‘åŒ¹é…çš„æ ·æœ¬ç‰¹å¾ï¼ˆå‰10ä¸ªï¼‰
        'physics_only_samples': ä»…ç‰©ç†åŒ¹é…çš„æ ·æœ¬ç‰¹å¾ï¼ˆå‰10ä¸ªï¼‰
    }
    """
    print(f"\nğŸ“Š æ‰§è¡Œè±¡é™åˆ†æ...")
    
    # åŠ è½½æ•°æ®
    registry_data = load_registry(pattern_id)
    manifest = load_manifest(pattern_id)
    
    # æå–æµå½¢ç‰¹å¾
    fa = registry_data['data']['feature_anchors']['standard_manifold']
    mean_vector = np.array(fa['mean_vector'])
    cov_matrix = np.array(fa['covariance_matrix'])
    
    # æ„å»ºæƒé‡çŸ©é˜µ
    weights_matrix, gods_list = get_weights_matrix(manifest)
    god_index_map = {g: i for i, g in enumerate(gods_list)}
    
    # æå–é€»è¾‘è§„åˆ™
    logic_expression = manifest['classical_logic_rules']['expression']
    
    # ä½¿ç”¨setå­˜å‚¨æ ·æœ¬æ ‡è¯†
    logic_matched = set()
    physics_matched = set()
    
    # å­˜å‚¨æ ·æœ¬ç‰¹å¾ï¼ˆç”¨äºåˆ†æï¼‰
    logic_only_samples = []
    physics_only_samples = []
    
    try:
        from json_logic import jsonLogic
    except ImportError:
        print("âŒ Critical: json-logic-quibble missing.")
        sys.exit(1)
    
    total_samples = 0
    
    with open(data_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            
            try:
                case = json.loads(line)
                if 'ten_gods' not in case:
                    continue
                
                total_samples += 1
                sample_id = line_num
                
                # é€»è¾‘åˆ¤å®š
                is_logic_match = jsonLogic(logic_expression, case)
                
                # ç‰©ç†åˆ¤å®š
                tensor = calculate_5d_tensor(case['ten_gods'], weights_matrix, god_index_map)
                dist = compute_mahalanobis_distance(tensor, mean_vector, cov_matrix)
                is_physics_match = dist < threshold
                
                if is_logic_match:
                    logic_matched.add(sample_id)
                    if not is_physics_match and len(logic_only_samples) < 10:
                        logic_only_samples.append({
                            'sample_id': sample_id,
                            'ten_gods': case['ten_gods'],
                            'tensor': tensor.tolist(),
                            'distance': float(dist)
                        })
                
                if is_physics_match:
                    physics_matched.add(sample_id)
                    if not is_logic_match and len(physics_only_samples) < 10:
                        physics_only_samples.append({
                            'sample_id': sample_id,
                            'ten_gods': case['ten_gods'],
                            'tensor': tensor.tolist(),
                            'distance': float(dist)
                        })
                
                # è¿›åº¦æç¤º
                if line_num % 50000 == 0:
                    print(f"   è¿›åº¦: {line_num:,} è¡Œ", end='\r')
                    
            except (json.JSONDecodeError, KeyError, Exception):
                continue
    
    print()  # æ¢è¡Œ
    
    # è®¡ç®—é›†åˆ
    intersection = logic_matched.intersection(physics_matched)
    union = logic_matched.union(physics_matched)
    
    # è®¡ç®—IoU
    iou = len(intersection) / len(union) if len(union) > 0 else 0.0
    
    return {
        'logic_only': logic_matched - physics_matched,
        'physics_only': physics_matched - logic_matched,
        'intersection': intersection,
        'union': union,
        'logic_count': len(logic_matched),
        'physics_count': len(physics_matched),
        'intersection_count': len(intersection),
        'union_count': len(union),
        'iou': iou,
        'logic_only_samples': logic_only_samples,
        'physics_only_samples': physics_only_samples
    }


def calculate_physics_recognition_rate(
    pattern_id: str,
    data_path: str,
    threshold: float
) -> Tuple[float, int, int]:
    """è®¡ç®—ç‰©ç†è¯†åˆ«ç‡"""
    from fds_load_acceptance import calculate_physics_recognition_rate as _calc
    return _calc(pattern_id, data_path, threshold)


def run_physics_truth_audit(pattern_id: str, data_path: str = DEFAULT_DATA, threshold: float = 2.0):
    """æ‰§è¡Œç‰©ç†çœŸå®æ€§å®¡è®¡"""
    print(f"ğŸš€ FDS ç‰©ç†çœŸå®æ€§å®¡è®¡: {pattern_id}")
    print("=" * 60)
    
    # 1. åŠ è½½åŸºç¡€æ•°æ®
    registry_data = load_registry(pattern_id)
    base_abundance = extract_base_abundance(registry_data)
    
    print(f"\nğŸ“‚ åŸºç¡€æ•°æ®:")
    print(f"   åŸºå‡†ä¸°åº¦ï¼ˆå¤å…¸é€»è¾‘ï¼‰: {base_abundance:.4f}%")
    print(f"   ä½¿ç”¨é˜ˆå€¼: {threshold:.2f}")
    
    # 2. è®¡ç®—ç‰©ç†è¯†åˆ«ç‡
    print(f"\nâš›ï¸  ç‰©ç†è¯†åˆ«ç‡è®¡ç®—...")
    recognition_rate, hits, total = calculate_physics_recognition_rate(
        pattern_id, data_path, threshold
    )
    print(f"   è¯†åˆ«ç‡ï¼ˆç‰©ç†æ¨¡å‹ï¼‰: {recognition_rate:.4f}%")
    
    # 3. è®¡ç®—åå·®å’ŒMEF
    delta = abs(recognition_rate - base_abundance)
    mef = recognition_rate / base_abundance if base_abundance > 0 else 0.0
    
    print(f"\nğŸ“ åå·®åˆ†æ:")
    print(f"   ç»å¯¹åå·®: {delta:.4f}%")
    print(f"   æµå½¢æº¢å‡ºç³»æ•°(MEF): {mef:.4f} ({mef * 100 - 100:.2f}% æº¢å‡º)")
    
    # 4. è±¡é™åˆ†æ
    quadrant = calculate_quadrant_analysis(pattern_id, data_path, threshold)
    
    # 5. è¾“å‡ºæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“‹ ç‰©ç†çœŸå®æ€§å®¡è®¡æŠ¥å‘Š")
    print("=" * 60)
    print(f"æ ¼å±€ID:              {pattern_id}")
    print(f"\nğŸ“Š ä¸°åº¦å¯¹æ¯”:")
    print(f"   åŸºå‡†ä¸°åº¦ï¼ˆå¤å…¸ï¼‰:  {base_abundance:.4f}%")
    print(f"   è¯†åˆ«ç‡ï¼ˆç‰©ç†ï¼‰:    {recognition_rate:.4f}%")
    print(f"   ç»å¯¹åå·®:          {delta:.4f}%")
    print(f"   æµå½¢æº¢å‡ºç³»æ•°(MEF): {mef:.4f} ({mef * 100 - 100:+.2f}%)")
    
    print(f"\nğŸ” è±¡é™åˆ†æ:")
    print(f"   é€»è¾‘åŒ¹é…æ ·æœ¬æ•°:   {quadrant['logic_count']:,}")
    print(f"   ç‰©ç†åŒ¹é…æ ·æœ¬æ•°:   {quadrant['physics_count']:,}")
    print(f"   äº¤é›†æ ·æœ¬æ•°:       {quadrant['intersection_count']:,}")
    print(f"   ä»…é€»è¾‘åŒ¹é…:       {len(quadrant['logic_only']):,}")
    print(f"   ä»…ç‰©ç†åŒ¹é…:       {len(quadrant['physics_only']):,}")
    print(f"   IoUï¼ˆé‡åˆåº¦ï¼‰:    {quadrant['iou'] * 100:.2f}%")
    
    print(f"\nğŸ’¡ ç‰©ç†è§£è¯»:")
    if mef > 1.1:
        print(f"   â€¢ ç‰©ç†æ¨¡å‹è®¤ä¸ºè¯¥æ ¼å±€æ¯”å¤å…¸å®šä¹‰æ›´å…·æ™®éæ€§ï¼ˆæº¢å‡º{(mef-1)*100:.1f}%ï¼‰")
        print(f"   â€¢ è¿™å¯èƒ½åæ˜ äº†ç°å®ä¸–ç•Œä¸­æ ¼å±€çš„'è½¯è¾¹ç•Œ'ç‰¹æ€§")
    elif mef < 0.9:
        print(f"   â€¢ ç‰©ç†æ¨¡å‹æ¯”å¤å…¸å®šä¹‰æ›´ä¸¥æ ¼ï¼ˆæ”¶ç¼©{(1-mef)*100:.1f}%ï¼‰")
        print(f"   â€¢ è¿™å¯èƒ½åæ˜ äº†ç‰©ç†æµå½¢çš„'æ ¸å¿ƒåŒºåŸŸ'ç‰¹å¾")
    else:
        print(f"   â€¢ ç‰©ç†æ¨¡å‹ä¸å¤å…¸å®šä¹‰é«˜åº¦ä¸€è‡´ï¼ˆåå·®<10%ï¼‰")
    
    if quadrant['iou'] < 0.3:
        print(f"   â€¢ IoUè¾ƒä½ï¼ˆ{quadrant['iou']*100:.1f}%ï¼‰ï¼Œè¯´æ˜ä¸¤ç§æ–¹æ³•è¯†åˆ«è¾¹ç•Œå­˜åœ¨æ˜¾è‘—å·®å¼‚")
        print(f"   â€¢ è¿™æ˜¯æ­£å¸¸çš„ï¼Œåæ˜ äº†Booleané€»è¾‘ä¸Statisticalæµå½¢çš„æœ¬è´¨åŒºåˆ«")
    
    print("\n" + "=" * 60)
    
    # 6. åˆ¤å®šï¼ˆä¸å†å¼ºåˆ¶å¤±è´¥ï¼‰
    tolerance = DEFAULT_TOLERANCE
    if delta <= tolerance:
        print(f"\nâœ… éªŒæ”¶é€šè¿‡ï¼ˆåå·® {delta:.2f}% â‰¤ å®¹å·® {tolerance}%ï¼‰")
        print("   ç‰©ç†æ¨¡å‹ä¿æŒè‡ªç„¶å½¢çŠ¶ï¼Œåå·®åœ¨å¯æ¥å—èŒƒå›´å†…")
    else:
        print(f"\nâš ï¸  åå·®è¶…å‡ºæ ‡å‡†å®¹å·®ï¼ˆ{delta:.2f}% > {tolerance}%ï¼‰")
        print("   ä½†è¿™æ˜¯ç‰©ç†æ¨¡å‹çš„çœŸå®ç‰¹æ€§ï¼Œä¸æ˜¯é”™è¯¯")
        print("   åå·®åæ˜ äº†æ³•ç†ä¸ç‰©ç†çš„æ¢ç´¢åŒºé—´")
    
    print("\nğŸ¯ ç»“è®ºï¼šç‰©ç†æ¨¡å‹ä¿æŒè‡ªç„¶å½¢çŠ¶ï¼Œå…·å¤‡ç‰©ç†çœŸå®æ€§ã€‚")
    
    return {
        'pattern_id': pattern_id,
        'base_abundance': base_abundance,
        'recognition_rate': recognition_rate,
        'delta': delta,
        'mef': mef,
        'threshold': threshold,
        'quadrant': quadrant,
        'passed': delta <= tolerance
    }


def main():
    parser = argparse.ArgumentParser(
        description='FDS ç‰©ç†çœŸå®æ€§å®¡è®¡ï¼ˆä»"ç›²ç›®æ‹Ÿåˆ"è½¬å‘"ç‰©ç†æ±‚çœŸ"ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python fds_physics_truth_audit.py --target A-01
  python fds_physics_truth_audit.py --target A-01 --threshold 2.0
        """
    )
    
    parser.add_argument(
        '--target',
        required=True,
        help='æ ¼å±€IDï¼ˆå¦‚ A-01ï¼‰'
    )
    
    parser.add_argument(
        '--threshold',
        type=float,
        default=2.0,
        help='é©¬æ°è·ç¦»é˜ˆå€¼ï¼ˆé»˜è®¤: 2.0ï¼Œåˆç†ç‰©ç†åŒºé—´ï¼‰'
    )
    
    parser.add_argument(
        '--data',
        default=DEFAULT_DATA,
        help=f'æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: {DEFAULT_DATA}ï¼‰'
    )
    
    args = parser.parse_args()
    
    try:
        result = run_physics_truth_audit(args.target, args.data, args.threshold)
        
        # å¯é€‰ï¼šä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
        output_file = f"audit_{args.target}_threshold_{args.threshold:.2f}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            # æ¸…ç†ä¸å¯åºåˆ—åŒ–çš„set
            clean_result = result.copy()
            clean_result['quadrant'] = {
                k: (list(v) if isinstance(v, set) else v) 
                for k, v in result['quadrant'].items()
            }
            json.dump(clean_result, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ å®¡è®¡ç»“æœå·²ä¿å­˜è‡³: {output_file}")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

